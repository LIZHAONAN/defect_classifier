{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from PIL import ImageOps\n",
    "import PIL\n",
    "import torch, torchvision\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset import *\n",
    "import random\n",
    "import math\n",
    "import seaborn\n",
    "from  matplotlib import pyplot\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 10       # The image size = 28 x 28 = 784\n",
    "hidden_size = 100      # The number of nodes at the hidden layer\n",
    "num_classes = 5       # The number of output classes. In this case, from 0 to 9\n",
    "num_epochs = 10         # The number of times entire dataset is trained\n",
    "batch_size = 64       # The size of input data took for one iteration\n",
    "learning_rate = 0.001  # The speed of convergence\n",
    "non_pos_ratio = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transform = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(200, scale=(1, 1), ratio=(1, 1)),\n",
    "        transforms.RandomRotation((-90,90)),\n",
    "        torchvision.transforms.RandomVerticalFlip(p=0.5),\n",
    "        torchvision.transforms.RandomHorizontalFlip(p=0.5),\n",
    "#         torchvision.transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0, hue=0),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.3019],\n",
    "                             std=[0.1909])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(Net, self).__init__()                    # Inherited from the parent class nn.Module\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)  # 1st Full-Connected Layer: 10 (input data) -> 500 (hidden node)\n",
    "        self.relu = nn.ReLU()                          # Non-Linear ReLU Layer: max(0,x)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size) # 2nd Full-Connected Layer: 500 (hidden node) -> 5 (output class)\n",
    "#         self.relu = nn.ReLU()                          # Non-Linear ReLU Layer: max(0,x)\n",
    "#         self.fc3 = nn.Linear(hidden_size, num_classes) # 3rd Full-Connected Layer: 500 (hidden node) -> 5 (output class)\n",
    "    \n",
    "    def forward(self, x):                              # Forward pass: stacking each layer together\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "#         out = self.relu(out)\n",
    "#         out = self.fc3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net(input_size, hidden_size, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU in use\n"
     ]
    }
   ],
   "source": [
    "use_gpu = torch.cuda.is_available()\n",
    "\n",
    "if use_gpu:\n",
    "    print(\"GPU in use\")\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "classes = [\"pos\",\"neg\",\"pos_o\",\"nuc\",\"non\"]\n",
    "num_of_classes = len(classes)\n",
    "\n",
    "model_uniform = torch.load('/home/rliu/defect_classifier/models/python/res34_600epo_uniform_01-07-18.model')\n",
    "model_uniform.eval()\n",
    "model_hard = torch.load('/home/rliu/defect_classifier/models/python/res34_600epo_hard_01-07-18.model')\n",
    "model_hard.eval()\n",
    "\n",
    "\n",
    "if use_gpu:\n",
    "#     model_uniform = torch.nn.DataParallel(model_uniform)\n",
    "    model_uniform.to(device)\n",
    "#     model_hard = torch.nn.DataParallel(model_hard)\n",
    "    model_hard.to(device)\n",
    "    net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = [1.0, 1.0, 1.0, 1.0, 1.0/non_pos_ratio]\n",
    "class_weights = torch.FloatTensor(weights).to(device)\n",
    "criterion = nn.NLLLoss(weight = class_weights)\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=learning_rate, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainloader ready!\n",
      "testloader ready!\n",
      "Epoch 0/9\n",
      "----------\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "weight tensor should be defined either for all 100 classes or no classes but got weight tensor of shape: [5] at /pytorch/aten/src/THCUNN/generic/ClassNLLCriterion.cu:43",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-56a7ff073873>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0moutputs_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m                             \u001b[0;31m# Intialize the hidden weight to all zeros\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mweak_script_method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   1788\u001b[0m                          .format(input.size(0), target.size(0)))\n\u001b[1;32m   1789\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1790\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1791\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1792\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: weight tensor should be defined either for all 100 classes or no classes but got weight tensor of shape: [5] at /pytorch/aten/src/THCUNN/generic/ClassNLLCriterion.cu:43"
     ]
    }
   ],
   "source": [
    "since = time.time()\n",
    "best_model_wts = net.state_dict()\n",
    "best_acc = 0.0\n",
    "for epoch in range(num_epochs):\n",
    "    trainset = defectDataset_df(df = split_and_sample(method = 'yolo',n_samples = 1995, non_pos_ratio=non_pos_ratio), window_size = window_size,\n",
    "                                             transforms=data_transform)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset,\n",
    "                                                 batch_size=batch_size, shuffle=True,\n",
    "                                                 num_workers=8, drop_last=True)\n",
    "    print(\"trainloader ready!\")\n",
    "\n",
    "    testset = defectDataset_df(df = split_and_sample(df_labels = pd.read_csv('/home/rliu/yolo2/v2_pytorch_yolo2/data/an_data/VOCdevkit/VOC2007/csv_labels/test.csv', sep=\" \"),\n",
    "                                                          method = 'yolo',n_samples = 800), window_size = window_size, transforms=data_transform)\n",
    "    testloader = torch.utils.data.DataLoader(testset,\n",
    "                                                 batch_size=batch_size, shuffle=True,\n",
    "                                                 num_workers=8)\n",
    "    print(\"testloader ready!\")\n",
    "    print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "    print('-' * 10)\n",
    "    model_uniform.train(True)\n",
    "    model_hard.train(True)\n",
    "    net.train(True)\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    for data in trainloader:\n",
    "        \n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs_uniform = model_uniform(inputs)\n",
    "            outputs_hard = model_hard(inputs)\n",
    "        outputs_in = torch.cat((outputs_uniform, outputs_hard), dim=1)\n",
    "        outputs_out = net(outputs_in)\n",
    "        _, preds = torch.max(outputs_out.data, 1)\n",
    "        loss = criterion(outputs_out, labels)\n",
    "\n",
    "        optimizer.zero_grad()                             # Intialize the hidden weight to all zeros\n",
    "        loss.backward()                                   # Backward pass: compute the weight\n",
    "        optimizer.step()                                  # Optimizer: update the weights of hidden nodes\n",
    "\n",
    "#         if (i+1) % 100 == 0:                              # Logging\n",
    "#             print('Epoch [%d/%d], Step [%d/%d], Loss: %.4f'\n",
    "#                  %(epoch+1, num_epochs, i+1, len(train_dataset)//batch_size, loss.item()))\n",
    "\n",
    "        \n",
    "        # statistics\n",
    "        iter_loss = loss.item()\n",
    "        correct = torch.sum(preds == labels.data).item()\n",
    "        batch_accuracy = correct / batch_size\n",
    "        running_loss += loss.item()\n",
    "        running_corrects_tensor = torch.sum(preds == labels.data)\n",
    "        running_corrects += running_corrects_tensor.item()        \n",
    "        epoch_loss = running_loss / len(trainset)\n",
    "        epoch_acc = running_corrects / len(trainset)\n",
    "\n",
    "        print('{} Loss: {:.4f} Acc: {:.4f} batch_loss: {:.4f} correct: {:d} batch_accuracy: {:.4f}'.format(\n",
    "            \"train\", epoch_loss, epoch_acc, iter_loss, correct, batch_accuracy))\n",
    "        \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    class_correct = list(0. for i in range(5))\n",
    "    class_total = list(0. for i in range(5))    \n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs_uniform = model_uniform(inputs)\n",
    "            outputs_hard = model_hard(inputs)\n",
    "            outputs_in = torch.cat((outputs_uniform, outputs_hard), dim=1)\n",
    "            outputs_out = net(outputs_in)\n",
    "            _, predicted = torch.max(outputs_out.data, 1)\n",
    "            c = (predicted == labels).squeeze()\n",
    "            for i in range(batch_size):\n",
    "                if len(labels) == batch_size:\n",
    "                    label = labels[i]\n",
    "                    class_correct[label] += c[i].item()\n",
    "                    class_total[label] += 1\n",
    "                    correct += c[i].item()\n",
    "                    total += 1\n",
    "#             if len(labels) == batch_size:\n",
    "#                 total += labels.size(0)\n",
    "#                 correct += (predicted == labels).sum().item()\n",
    "    #         print(predicted)\n",
    "    #         print(labels)\n",
    "    #       print('processed: %d' % total)\n",
    "    #       print('correct: %d' % correct)\n",
    "        print('Accuracy of the network on the test images: %.5f %%' % (100 * correct / total))\n",
    "        for i in range(5):\n",
    "            print('Accuracy of %5s : %2d %%' % (classes[i], 100 * class_correct[i] / class_total[i]))\n",
    "        print('class total: ',class_total)\n",
    "        print('class correct: ',class_correct)\n",
    "        print('total: ', total)\n",
    "        print('correct: ', correct)\n",
    "time_elapsed = time.time() - since\n",
    "print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "    time_elapsed // 60, time_elapsed % 60))\n",
    "print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "# load best model weights\n",
    "net.load_state_dict(best_model_wts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 1, 200, 200])\n",
      "torch.Size([256, 5])\n",
      "torch.Size([256, 10])\n",
      "torch.Size([256, 5])\n"
     ]
    }
   ],
   "source": [
    "print(inputs.shape)\n",
    "print(outputs_uniform.shape)\n",
    "print(outputs_in.shape)\n",
    "print(outputs_out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU in use\n"
     ]
    }
   ],
   "source": [
    "use_gpu = torch.cuda.is_available()\n",
    "\n",
    "if use_gpu:\n",
    "    print(\"GPU in use\")\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "classes = [\"pos\",\"neg\",\"pos_o\",\"nuc\",\"non\"]\n",
    "num_of_classes = len(classes)\n",
    "\n",
    "model_uniform = torch.load('/home/rliu/defect_classifier/models/python/res34_600epo_uniform_01-07-18.model')\n",
    "model_uniform.eval()\n",
    "model_hard = torch.load('/home/rliu/defect_classifier/models/python/res34_600epo_hard_01-07-18.model')\n",
    "model_hard.eval()\n",
    "if use_gpu:\n",
    "#     model_uniform = torch.nn.DataParallel(model_uniform)\n",
    "    model_uniform.to(device)\n",
    "#     model_hard = torch.nn.DataParallel(model_hard)\n",
    "    model_hard.to(device)\n",
    "    \n",
    "    \n",
    "batch_size = 5\n",
    "testset = defectDataset_df(df = split_and_sample(df_train = pd.read_csv('/home/rliu/yolo2/v2_pytorch_yolo2/data/an_data/VOCdevkit/VOC2007/csv_labels/train.csv', sep=\" \"),\n",
    "                                                      method = 'hard',n_samples = 500), window_size = window_size, transforms=data_transform)\n",
    "testloader = torch.utils.data.DataLoader(testset,\n",
    "                                             batch_size=batch_size, shuffle=True,\n",
    "                                             num_workers=8)\n",
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# print images\n",
    "images, labels = images.to(device), labels.to(device)\n",
    "outputs_uniform = model_uniform(images)\n",
    "outputs_hard = model_hard(images)\n",
    "outputs = torch.cat((outputs_uniform, outputs_hard), dim=1)\n",
    "_, preds = torch.max(outputs.data, 1)\n",
    "loss = criterion(outputs, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-12.3108,   3.8134, -12.1610,  -8.9865, -18.6308],\n",
      "        [  4.1426, -12.6464, -16.8836, -13.2110, -13.5861],\n",
      "        [ -9.9046, -12.1545,  -9.0868,   2.3950, -12.2668],\n",
      "        [ -5.9917,   3.7852,  -9.3418, -10.6862, -11.3693],\n",
      "        [  4.1033,  -7.9563,  -6.8923, -13.0635,  -7.5087]], device='cuda:0',\n",
      "       grad_fn=<GatherBackward>)\n",
      "tensor([[-10.9020,   2.6503, -13.7712, -12.7975, -13.3193],\n",
      "        [  3.1850, -11.8032, -13.6199, -11.8008, -12.5677],\n",
      "        [-13.4012, -12.1915, -14.3676,   1.9575, -15.2399],\n",
      "        [ -7.2337,   2.6256, -18.3268, -10.4256,  -9.0024],\n",
      "        [  3.2153, -10.9220, -13.6908, -12.3731, -11.7074]], device='cuda:0',\n",
      "       grad_fn=<GatherBackward>)\n",
      "tensor(0.3425, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(outputs_uniform)\n",
    "print(outputs_hard)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 0, 0, 3, 1])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.MNIST(root='./data',\n",
    "                           train=True,\n",
    "                           transform=transforms.ToTensor(),\n",
    "                           download=True)\n",
    "\n",
    "test_dataset = datasets.MNIST(root='./data',\n",
    "                           train=False,\n",
    "                           transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(Net, self).__init__()                    # Inherited from the parent class nn.Module\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)  # 1st Full-Connected Layer: 784 (input data) -> 500 (hidden node)\n",
    "        self.relu = nn.ReLU()                          # Non-Linear ReLU Layer: max(0,x)\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes) # 2nd Full-Connected Layer: 500 (hidden node) -> 10 (output class)\n",
    "    \n",
    "    def forward(self, x):                              # Forward pass: stacking each layer together\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net(input_size, hidden_size, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (fc1): Linear(in_features=784, out_features=500, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (fc2): Linear(in_features=500, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [100/600], Loss: 0.2542\n",
      "Epoch [1/5], Step [200/600], Loss: 0.1384\n",
      "Epoch [1/5], Step [300/600], Loss: 0.1731\n",
      "Epoch [1/5], Step [400/600], Loss: 0.1142\n",
      "Epoch [1/5], Step [500/600], Loss: 0.0950\n",
      "Epoch [1/5], Step [600/600], Loss: 0.1930\n",
      "Epoch [2/5], Step [100/600], Loss: 0.1513\n",
      "Epoch [2/5], Step [200/600], Loss: 0.1833\n",
      "Epoch [2/5], Step [300/600], Loss: 0.1233\n",
      "Epoch [2/5], Step [400/600], Loss: 0.1183\n",
      "Epoch [2/5], Step [500/600], Loss: 0.0871\n",
      "Epoch [2/5], Step [600/600], Loss: 0.0677\n",
      "Epoch [3/5], Step [100/600], Loss: 0.0196\n",
      "Epoch [3/5], Step [200/600], Loss: 0.0825\n",
      "Epoch [3/5], Step [300/600], Loss: 0.0880\n",
      "Epoch [3/5], Step [400/600], Loss: 0.0757\n",
      "Epoch [3/5], Step [500/600], Loss: 0.0220\n",
      "Epoch [3/5], Step [600/600], Loss: 0.0282\n",
      "Epoch [4/5], Step [100/600], Loss: 0.0166\n",
      "Epoch [4/5], Step [200/600], Loss: 0.0539\n",
      "Epoch [4/5], Step [300/600], Loss: 0.0231\n",
      "Epoch [4/5], Step [400/600], Loss: 0.0305\n",
      "Epoch [4/5], Step [500/600], Loss: 0.0996\n",
      "Epoch [4/5], Step [600/600], Loss: 0.0352\n",
      "Epoch [5/5], Step [100/600], Loss: 0.0392\n",
      "Epoch [5/5], Step [200/600], Loss: 0.0510\n",
      "Epoch [5/5], Step [300/600], Loss: 0.0487\n",
      "Epoch [5/5], Step [400/600], Loss: 0.0199\n",
      "Epoch [5/5], Step [500/600], Loss: 0.0501\n",
      "Epoch [5/5], Step [600/600], Loss: 0.0229\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):   # Load a batch of images with its (index, data, class)\n",
    "        images = Variable(images.view(-1, 28*28))         # Convert torch tensor to Variable: change image from a vector of size 784 to a matrix of 28 x 28\n",
    "        labels = Variable(labels)\n",
    "        \n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()                             # Intialize the hidden weight to all zeros\n",
    "        outputs = net(images)                             # Forward pass: compute the output class given a image\n",
    "        loss = criterion(outputs, labels)                 # Compute the loss: difference between the output class and the pre-given label\n",
    "        loss.backward()                                   # Backward pass: compute the weight\n",
    "        optimizer.step()                                  # Optimizer: update the weights of hidden nodes\n",
    "        \n",
    "        if (i+1) % 100 == 0:                              # Logging\n",
    "            print('Epoch [%d/%d], Step [%d/%d], Loss: %.4f'\n",
    "                 %(epoch+1, num_epochs, i+1, len(train_dataset)//batch_size, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22127796709537506"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    use_gpu = torch.cuda.is_available()\n",
    "\n",
    "    if use_gpu:\n",
    "        print(\"GPU in use\")\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    classes = [\"pos\",\"neg\",\"pos_o\",\"nuc\",\"non\"]\n",
    "    num_of_classes = len(classes)\n",
    "\n",
    "    model_uniform = torch.load('/home/rliu/defect_classifier/models/python/res34_600epo_uniform_01-07-18.model')\n",
    "    model_uniform.eval()\n",
    "    model_hard = torch.load('/home/rliu/defect_classifier/models/python/res34_600epo_uniform_01-07-18.model')\n",
    "    model_hard.eval()\n",
    "    if use_gpu:\n",
    "        model_uniform = torch.nn.DataParallel(uniform)\n",
    "        model_uniform.to(device)\n",
    "        model_uniform = torch.nn.DataParallel(uniform)\n",
    "        model_uniform.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10K test images: 97 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "for images, labels in test_loader:\n",
    "    images = Variable(images.view(-1, 28*28))\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    outputs = net(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)  # Choose the best class from the output: The class with the best score\n",
    "    total += labels.size(0)                    # Increment the total count\n",
    "    correct += (predicted == labels).sum()     # Increment the correct count\n",
    "    \n",
    "print('Accuracy of the network on the 10K test images: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
