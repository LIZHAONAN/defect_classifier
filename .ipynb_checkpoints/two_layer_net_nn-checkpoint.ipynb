{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from PIL import ImageOps\n",
    "import PIL\n",
    "import torch, torchvision\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset import *\n",
    "import random\n",
    "import math\n",
    "import seaborn\n",
    "from  matplotlib import pyplot\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import time\n",
    "from torch.optim import lr_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 10       # The image size = 28 x 28 = 784\n",
    "hidden_size = 100      # The number of nodes at the hidden layer\n",
    "num_classes = 5       # The number of output classes. In this case, from 0 to 9\n",
    "num_epochs = 10         # The number of times entire dataset is trained\n",
    "batch_size = 256       # The size of input data took for one iteration\n",
    "learning_rate = 0.001  # The speed of convergence\n",
    "non_pos_ratio = 10\n",
    "weight_decay=5e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(200, scale=(1, 1), ratio=(1, 1)),\n",
    "        transforms.RandomRotation((-90,90)),\n",
    "        torchvision.transforms.RandomVerticalFlip(p=0.5),\n",
    "        torchvision.transforms.RandomHorizontalFlip(p=0.5),\n",
    "#         torchvision.transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0, hue=0),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.3019],\n",
    "                             std=[0.1909])\n",
    "    ])\n",
    "test_transform = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(200, scale=(1, 1), ratio=(1, 1)),\n",
    "#         transforms.RandomRotation((-90,90)),\n",
    "#         torchvision.transforms.RandomVerticalFlip(p=0.5),\n",
    "#         torchvision.transforms.RandomHorizontalFlip(p=0.5),\n",
    "#         torchvision.transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0, hue=0),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.3019],\n",
    "                             std=[0.1909])\n",
    "    ])\n",
    "scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(Net, self).__init__()                    # Inherited from the parent class nn.Module\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)  # 1st Full-Connected Layer: 10 (input data) -> 500 (hidden node)\n",
    "        self.relu = nn.ReLU()                          # Non-Linear ReLU Layer: max(0,x)\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes) # 2nd Full-Connected Layer: 500 (hidden node) -> 5 (output class)\n",
    "#         self.relu = nn.ReLU()                          # Non-Linear ReLU Layer: max(0,x)\n",
    "#         self.fc3 = nn.Linear(hidden_size, num_classes) # 3rd Full-Connected Layer: 500 (hidden node) -> 5 (output class)\n",
    "    \n",
    "    def forward(self, x):                              # Forward pass: stacking each layer together\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "#         out = self.relu(out)\n",
    "#         out = self.fc3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net(input_size, hidden_size, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU in use\n"
     ]
    }
   ],
   "source": [
    "use_gpu = torch.cuda.is_available()\n",
    "\n",
    "if use_gpu:\n",
    "    print(\"GPU in use\")\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "classes = [\"pos\",\"neg\",\"pos_o\",\"nuc\",\"non\"]\n",
    "num_of_classes = len(classes)\n",
    "\n",
    "model_uniform = torch.load('/home/rliu/defect_classifier/models/python/res34_600epo_uniform_01-07-18.model')\n",
    "model_uniform.eval()\n",
    "model_hard = torch.load('/home/rliu/defect_classifier/models/python/res34_600epo_hard_01-07-18.model')\n",
    "model_hard.eval()\n",
    "\n",
    "\n",
    "if use_gpu:\n",
    "#     model_uniform = torch.nn.DataParallel(model_uniform)\n",
    "    model_uniform.to(device)\n",
    "#     model_hard = torch.nn.DataParallel(model_hard)\n",
    "    model_hard.to(device)\n",
    "    net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = [1.0, 1.0, 1.0, 1.0, 1.0/non_pos_ratio]\n",
    "class_weights = torch.FloatTensor(weights).to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight = class_weights)\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=learning_rate, weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainloader ready!\n",
      "testloader ready!\n",
      "Epoch 0/9\n",
      "----------\n",
      "train Loss: 0.0023 Acc: 0.0013 batch_loss: 62.9729 correct: 35 batch_accuracy: 0.1367\n",
      "train Loss: 0.0031 Acc: 0.0035 batch_loss: 23.7339 correct: 62 batch_accuracy: 0.2422\n",
      "train Loss: 0.0038 Acc: 0.0053 batch_loss: 20.1028 correct: 52 batch_accuracy: 0.2031\n",
      "train Loss: 0.0042 Acc: 0.0071 batch_loss: 10.4136 correct: 50 batch_accuracy: 0.1953\n",
      "train Loss: 0.0043 Acc: 0.0149 batch_loss: 2.2140 correct: 216 batch_accuracy: 0.8438\n",
      "train Loss: 0.0043 Acc: 0.0234 batch_loss: 1.2745 correct: 238 batch_accuracy: 0.9297\n",
      "train Loss: 0.0044 Acc: 0.0317 batch_loss: 1.8381 correct: 233 batch_accuracy: 0.9102\n",
      "train Loss: 0.0044 Acc: 0.0404 batch_loss: 0.5784 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0045 Acc: 0.0488 batch_loss: 1.4153 correct: 236 batch_accuracy: 0.9219\n",
      "train Loss: 0.0045 Acc: 0.0572 batch_loss: 0.7897 correct: 234 batch_accuracy: 0.9141\n",
      "train Loss: 0.0045 Acc: 0.0658 batch_loss: 0.5452 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0045 Acc: 0.0745 batch_loss: 0.9395 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0045 Acc: 0.0832 batch_loss: 0.2596 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0046 Acc: 0.0921 batch_loss: 0.1507 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0046 Acc: 0.1008 batch_loss: 1.3535 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0046 Acc: 0.1095 batch_loss: 0.6068 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0047 Acc: 0.1179 batch_loss: 0.8941 correct: 236 batch_accuracy: 0.9219\n",
      "train Loss: 0.0047 Acc: 0.1264 batch_loss: 1.1750 correct: 236 batch_accuracy: 0.9219\n",
      "train Loss: 0.0047 Acc: 0.1351 batch_loss: 0.5870 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0047 Acc: 0.1436 batch_loss: 0.7175 correct: 240 batch_accuracy: 0.9375\n",
      "train Loss: 0.0048 Acc: 0.1522 batch_loss: 0.7226 correct: 240 batch_accuracy: 0.9375\n",
      "train Loss: 0.0048 Acc: 0.1610 batch_loss: 0.5598 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0048 Acc: 0.1697 batch_loss: 0.6018 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0048 Acc: 0.1786 batch_loss: 0.5066 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0048 Acc: 0.1875 batch_loss: 0.2276 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0049 Acc: 0.1962 batch_loss: 0.9435 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0049 Acc: 0.2051 batch_loss: 0.6841 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0049 Acc: 0.2139 batch_loss: 0.3954 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0049 Acc: 0.2227 batch_loss: 0.2624 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0049 Acc: 0.2314 batch_loss: 0.5528 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0050 Acc: 0.2402 batch_loss: 0.9802 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0050 Acc: 0.2491 batch_loss: 0.7278 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0050 Acc: 0.2579 batch_loss: 0.3820 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0050 Acc: 0.2667 batch_loss: 0.2742 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0050 Acc: 0.2755 batch_loss: 0.4110 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0050 Acc: 0.2844 batch_loss: 0.1389 correct: 250 batch_accuracy: 0.9766\n",
      "train Loss: 0.0051 Acc: 0.2933 batch_loss: 0.5374 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0051 Acc: 0.3021 batch_loss: 0.5763 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0051 Acc: 0.3108 batch_loss: 0.8222 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0051 Acc: 0.3197 batch_loss: 0.2884 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0052 Acc: 0.3285 batch_loss: 1.1384 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0052 Acc: 0.3374 batch_loss: 0.8569 correct: 250 batch_accuracy: 0.9766\n",
      "train Loss: 0.0052 Acc: 0.3462 batch_loss: 0.5633 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0052 Acc: 0.3551 batch_loss: 0.1318 correct: 250 batch_accuracy: 0.9766\n",
      "train Loss: 0.0052 Acc: 0.3638 batch_loss: 0.1384 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0052 Acc: 0.3727 batch_loss: 0.3296 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0053 Acc: 0.3816 batch_loss: 0.8245 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0053 Acc: 0.3905 batch_loss: 0.3071 correct: 250 batch_accuracy: 0.9766\n",
      "train Loss: 0.0053 Acc: 0.3994 batch_loss: 0.3836 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0053 Acc: 0.4081 batch_loss: 0.7009 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0054 Acc: 0.4169 batch_loss: 1.0184 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0054 Acc: 0.4259 batch_loss: 0.2020 correct: 251 batch_accuracy: 0.9805\n",
      "train Loss: 0.0054 Acc: 0.4347 batch_loss: 0.1310 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0054 Acc: 0.4436 batch_loss: 0.9381 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0054 Acc: 0.4523 batch_loss: 0.4461 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0054 Acc: 0.4611 batch_loss: 0.2538 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0055 Acc: 0.4697 batch_loss: 0.9789 correct: 240 batch_accuracy: 0.9375\n",
      "train Loss: 0.0055 Acc: 0.4785 batch_loss: 0.3144 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0055 Acc: 0.4873 batch_loss: 0.6188 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0055 Acc: 0.4961 batch_loss: 0.4630 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0055 Acc: 0.5048 batch_loss: 0.5729 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0055 Acc: 0.5137 batch_loss: 0.3040 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0056 Acc: 0.5226 batch_loss: 0.2584 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0056 Acc: 0.5315 batch_loss: 0.5254 correct: 251 batch_accuracy: 0.9805\n",
      "train Loss: 0.0056 Acc: 0.5404 batch_loss: 1.2056 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0056 Acc: 0.5492 batch_loss: 0.3214 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0056 Acc: 0.5581 batch_loss: 0.4741 correct: 251 batch_accuracy: 0.9805\n",
      "train Loss: 0.0056 Acc: 0.5671 batch_loss: 0.2189 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0057 Acc: 0.5761 batch_loss: 0.2206 correct: 252 batch_accuracy: 0.9844\n",
      "train Loss: 0.0057 Acc: 0.5847 batch_loss: 0.3993 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0057 Acc: 0.5937 batch_loss: 0.1218 correct: 250 batch_accuracy: 0.9766\n",
      "train Loss: 0.0057 Acc: 0.6027 batch_loss: 0.0521 correct: 252 batch_accuracy: 0.9844\n",
      "train Loss: 0.0057 Acc: 0.6116 batch_loss: 0.3970 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0057 Acc: 0.6206 batch_loss: 0.3199 correct: 250 batch_accuracy: 0.9766\n",
      "train Loss: 0.0057 Acc: 0.6292 batch_loss: 0.5809 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0058 Acc: 0.6380 batch_loss: 1.1463 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0058 Acc: 0.6467 batch_loss: 0.2713 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0058 Acc: 0.6557 batch_loss: 0.2174 correct: 250 batch_accuracy: 0.9766\n",
      "train Loss: 0.0058 Acc: 0.6646 batch_loss: 0.1231 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0058 Acc: 0.6734 batch_loss: 0.2080 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0058 Acc: 0.6821 batch_loss: 0.4727 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0058 Acc: 0.6910 batch_loss: 1.0310 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0059 Acc: 0.6999 batch_loss: 0.4679 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0059 Acc: 0.7086 batch_loss: 0.3652 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0059 Acc: 0.7175 batch_loss: 0.8444 correct: 250 batch_accuracy: 0.9766\n",
      "train Loss: 0.0059 Acc: 0.7264 batch_loss: 0.6060 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0060 Acc: 0.7352 batch_loss: 0.7951 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0060 Acc: 0.7440 batch_loss: 1.0500 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0060 Acc: 0.7529 batch_loss: 0.0798 correct: 250 batch_accuracy: 0.9766\n",
      "train Loss: 0.0060 Acc: 0.7615 batch_loss: 0.7633 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0061 Acc: 0.7705 batch_loss: 1.7198 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0061 Acc: 0.7792 batch_loss: 0.6367 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0061 Acc: 0.7879 batch_loss: 0.2382 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0062 Acc: 0.7965 batch_loss: 1.4318 correct: 240 batch_accuracy: 0.9375\n",
      "train Loss: 0.0062 Acc: 0.8053 batch_loss: 0.2904 correct: 247 batch_accuracy: 0.9648\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0062 Acc: 0.8141 batch_loss: 0.3452 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0062 Acc: 0.8228 batch_loss: 0.6813 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0062 Acc: 0.8315 batch_loss: 0.2517 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0062 Acc: 0.8404 batch_loss: 0.3065 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0063 Acc: 0.8492 batch_loss: 0.8277 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0063 Acc: 0.8581 batch_loss: 0.2584 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0063 Acc: 0.8669 batch_loss: 1.1204 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0064 Acc: 0.8757 batch_loss: 1.2548 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0064 Acc: 0.8845 batch_loss: 0.4245 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0064 Acc: 0.8933 batch_loss: 0.3302 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0064 Acc: 0.9023 batch_loss: 0.1879 correct: 251 batch_accuracy: 0.9805\n",
      "train Loss: 0.0064 Acc: 0.9111 batch_loss: 0.4186 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0064 Acc: 0.9201 batch_loss: 0.0783 correct: 252 batch_accuracy: 0.9844\n",
      "train Loss: 0.0064 Acc: 0.9290 batch_loss: 0.1880 correct: 248 batch_accuracy: 0.9688\n",
      "Accuracy of the network on the test images: 81.64062 %\n",
      "Accuracy of   pos : 82 %\n",
      "Accuracy of   neg : 84 %\n",
      "Accuracy of pos_o : 75 %\n",
      "Accuracy of   nuc : 70 %\n",
      "Accuracy of   non : 95 %\n",
      "class total:  [765.0, 765.0, 774.0, 766.0, 770.0]\n",
      "class correct:  [633.0, 646.0, 582.0, 538.0, 736.0]\n",
      "total:  3840\n",
      "correct:  3135\n",
      "trainloader ready!\n",
      "testloader ready!\n",
      "Epoch 1/9\n",
      "----------\n",
      "train Loss: 0.0000 Acc: 0.0087 batch_loss: 0.4487 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0000 Acc: 0.0175 batch_loss: 0.1591 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0000 Acc: 0.0264 batch_loss: 0.1725 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0000 Acc: 0.0352 batch_loss: 0.3328 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0000 Acc: 0.0440 batch_loss: 0.2578 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0001 Acc: 0.0529 batch_loss: 0.7590 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0001 Acc: 0.0615 batch_loss: 1.2612 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0002 Acc: 0.0703 batch_loss: 1.0705 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0002 Acc: 0.0791 batch_loss: 0.4004 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0002 Acc: 0.0878 batch_loss: 0.7744 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0002 Acc: 0.0968 batch_loss: 0.1070 correct: 252 batch_accuracy: 0.9844\n",
      "train Loss: 0.0002 Acc: 0.1056 batch_loss: 0.7400 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0002 Acc: 0.1145 batch_loss: 0.2838 correct: 250 batch_accuracy: 0.9766\n",
      "train Loss: 0.0003 Acc: 0.1235 batch_loss: 0.2201 correct: 250 batch_accuracy: 0.9766\n",
      "train Loss: 0.0003 Acc: 0.1323 batch_loss: 0.3343 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0003 Acc: 0.1412 batch_loss: 0.2285 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0003 Acc: 0.1502 batch_loss: 0.3468 correct: 251 batch_accuracy: 0.9805\n",
      "train Loss: 0.0003 Acc: 0.1590 batch_loss: 0.1399 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0003 Acc: 0.1679 batch_loss: 0.1243 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0003 Acc: 0.1769 batch_loss: 0.0118 correct: 253 batch_accuracy: 0.9883\n",
      "train Loss: 0.0003 Acc: 0.1859 batch_loss: 0.4540 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0003 Acc: 0.1948 batch_loss: 0.1505 correct: 250 batch_accuracy: 0.9766\n",
      "train Loss: 0.0003 Acc: 0.2036 batch_loss: 0.8887 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0004 Acc: 0.2124 batch_loss: 0.5048 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0004 Acc: 0.2212 batch_loss: 1.4356 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0004 Acc: 0.2300 batch_loss: 0.6875 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0005 Acc: 0.2387 batch_loss: 0.2970 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0005 Acc: 0.2477 batch_loss: 0.6817 correct: 250 batch_accuracy: 0.9766\n",
      "train Loss: 0.0005 Acc: 0.2565 batch_loss: 0.6818 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0005 Acc: 0.2651 batch_loss: 1.3508 correct: 239 batch_accuracy: 0.9336\n",
      "train Loss: 0.0006 Acc: 0.2739 batch_loss: 0.3910 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0006 Acc: 0.2828 batch_loss: 0.5620 correct: 250 batch_accuracy: 0.9766\n",
      "train Loss: 0.0006 Acc: 0.2918 batch_loss: 0.1840 correct: 252 batch_accuracy: 0.9844\n",
      "train Loss: 0.0006 Acc: 0.3006 batch_loss: 0.2664 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0006 Acc: 0.3095 batch_loss: 0.5073 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0006 Acc: 0.3184 batch_loss: 0.2639 correct: 251 batch_accuracy: 0.9805\n",
      "train Loss: 0.0006 Acc: 0.3274 batch_loss: 0.3942 correct: 251 batch_accuracy: 0.9805\n",
      "train Loss: 0.0007 Acc: 0.3362 batch_loss: 0.3121 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0007 Acc: 0.3450 batch_loss: 0.4921 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0007 Acc: 0.3540 batch_loss: 0.3395 correct: 252 batch_accuracy: 0.9844\n",
      "train Loss: 0.0007 Acc: 0.3629 batch_loss: 0.9238 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0007 Acc: 0.3715 batch_loss: 0.7979 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0007 Acc: 0.3805 batch_loss: 0.1218 correct: 250 batch_accuracy: 0.9766\n",
      "train Loss: 0.0008 Acc: 0.3893 batch_loss: 0.5582 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0008 Acc: 0.3981 batch_loss: 0.5444 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0008 Acc: 0.4069 batch_loss: 0.5715 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0008 Acc: 0.4158 batch_loss: 0.2771 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0008 Acc: 0.4247 batch_loss: 0.4860 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0008 Acc: 0.4335 batch_loss: 0.4317 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0009 Acc: 0.4424 batch_loss: 0.6345 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0009 Acc: 0.4512 batch_loss: 1.1655 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0009 Acc: 0.4602 batch_loss: 0.1043 correct: 250 batch_accuracy: 0.9766\n",
      "train Loss: 0.0009 Acc: 0.4691 batch_loss: 0.0855 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0009 Acc: 0.4779 batch_loss: 0.4310 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0010 Acc: 0.4866 batch_loss: 0.5187 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0010 Acc: 0.4955 batch_loss: 0.7903 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0010 Acc: 0.5042 batch_loss: 0.3954 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0010 Acc: 0.5131 batch_loss: 0.6983 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0010 Acc: 0.5221 batch_loss: 0.0619 correct: 252 batch_accuracy: 0.9844\n",
      "train Loss: 0.0010 Acc: 0.5310 batch_loss: 0.3701 correct: 250 batch_accuracy: 0.9766\n",
      "train Loss: 0.0011 Acc: 0.5398 batch_loss: 0.6947 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0011 Acc: 0.5487 batch_loss: 0.1872 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0011 Acc: 0.5575 batch_loss: 0.3230 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0011 Acc: 0.5665 batch_loss: 0.5385 correct: 250 batch_accuracy: 0.9766\n",
      "train Loss: 0.0011 Acc: 0.5753 batch_loss: 0.2955 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0011 Acc: 0.5841 batch_loss: 0.4288 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0011 Acc: 0.5929 batch_loss: 0.2705 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0011 Acc: 0.6020 batch_loss: 0.0415 correct: 252 batch_accuracy: 0.9844\n",
      "train Loss: 0.0011 Acc: 0.6108 batch_loss: 0.2600 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0012 Acc: 0.6196 batch_loss: 0.9670 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0012 Acc: 0.6286 batch_loss: 0.4805 correct: 251 batch_accuracy: 0.9805\n",
      "train Loss: 0.0012 Acc: 0.6375 batch_loss: 0.1983 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0012 Acc: 0.6464 batch_loss: 0.0743 correct: 250 batch_accuracy: 0.9766\n",
      "train Loss: 0.0012 Acc: 0.6554 batch_loss: 0.3945 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0013 Acc: 0.6643 batch_loss: 0.8253 correct: 251 batch_accuracy: 0.9805\n",
      "train Loss: 0.0013 Acc: 0.6731 batch_loss: 0.6464 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0013 Acc: 0.6821 batch_loss: 0.2633 correct: 252 batch_accuracy: 0.9844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0013 Acc: 0.6909 batch_loss: 0.5912 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0013 Acc: 0.6995 batch_loss: 0.4731 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0013 Acc: 0.7083 batch_loss: 0.3368 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0013 Acc: 0.7171 batch_loss: 0.3762 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0014 Acc: 0.7259 batch_loss: 0.4032 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0014 Acc: 0.7348 batch_loss: 0.2213 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0014 Acc: 0.7438 batch_loss: 0.9640 correct: 250 batch_accuracy: 0.9766\n",
      "train Loss: 0.0014 Acc: 0.7522 batch_loss: 1.0005 correct: 237 batch_accuracy: 0.9258\n",
      "train Loss: 0.0015 Acc: 0.7611 batch_loss: 1.1050 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0015 Acc: 0.7700 batch_loss: 0.0925 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0015 Acc: 0.7788 batch_loss: 1.1936 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0015 Acc: 0.7875 batch_loss: 0.1253 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0015 Acc: 0.7962 batch_loss: 0.3370 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0015 Acc: 0.8052 batch_loss: 0.1464 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0016 Acc: 0.8140 batch_loss: 0.9483 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0016 Acc: 0.8229 batch_loss: 0.4083 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0016 Acc: 0.8317 batch_loss: 0.3452 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0016 Acc: 0.8406 batch_loss: 0.3432 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0016 Acc: 0.8495 batch_loss: 0.1229 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0016 Acc: 0.8584 batch_loss: 0.4748 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0017 Acc: 0.8674 batch_loss: 0.5419 correct: 252 batch_accuracy: 0.9844\n",
      "train Loss: 0.0017 Acc: 0.8763 batch_loss: 0.3259 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0017 Acc: 0.8851 batch_loss: 0.3705 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0017 Acc: 0.8938 batch_loss: 0.7317 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0017 Acc: 0.9026 batch_loss: 0.2469 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0017 Acc: 0.9113 batch_loss: 0.6685 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0018 Acc: 0.9202 batch_loss: 0.1778 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0018 Acc: 0.9289 batch_loss: 0.9131 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0018 Acc: 0.9379 batch_loss: 0.2361 correct: 251 batch_accuracy: 0.9805\n",
      "train Loss: 0.0018 Acc: 0.9467 batch_loss: 0.7540 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0018 Acc: 0.9555 batch_loss: 0.3808 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0018 Acc: 0.9644 batch_loss: 0.4172 correct: 247 batch_accuracy: 0.9648\n",
      "Accuracy of the network on the test images: 82.52604 %\n",
      "Accuracy of   pos : 81 %\n",
      "Accuracy of   neg : 88 %\n",
      "Accuracy of pos_o : 76 %\n",
      "Accuracy of   nuc : 68 %\n",
      "Accuracy of   non : 96 %\n",
      "class total:  [770.0, 771.0, 767.0, 767.0, 765.0]\n",
      "class correct:  [630.0, 682.0, 588.0, 528.0, 741.0]\n",
      "total:  3840\n",
      "correct:  3169\n",
      "trainloader ready!\n",
      "testloader ready!\n",
      "Epoch 2/9\n",
      "----------\n",
      "train Loss: 0.0000 Acc: 0.0088 batch_loss: 0.3389 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0000 Acc: 0.0177 batch_loss: 0.6086 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0000 Acc: 0.0265 batch_loss: 0.2375 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0001 Acc: 0.0354 batch_loss: 0.6768 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0001 Acc: 0.0441 batch_loss: 0.9658 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0001 Acc: 0.0530 batch_loss: 0.1447 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0001 Acc: 0.0618 batch_loss: 0.3294 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0001 Acc: 0.0707 batch_loss: 0.2968 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0001 Acc: 0.0796 batch_loss: 0.5368 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0002 Acc: 0.0883 batch_loss: 0.3059 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0002 Acc: 0.0972 batch_loss: 0.3815 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0002 Acc: 0.1059 batch_loss: 0.7476 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0002 Acc: 0.1145 batch_loss: 1.2918 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0003 Acc: 0.1231 batch_loss: 0.7166 correct: 239 batch_accuracy: 0.9336\n",
      "train Loss: 0.0003 Acc: 0.1318 batch_loss: 0.3491 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0003 Acc: 0.1404 batch_loss: 0.3404 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0003 Acc: 0.1494 batch_loss: 0.7519 correct: 251 batch_accuracy: 0.9805\n",
      "train Loss: 0.0003 Acc: 0.1582 batch_loss: 0.6374 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0004 Acc: 0.1671 batch_loss: 0.3076 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0004 Acc: 0.1757 batch_loss: 0.3021 correct: 240 batch_accuracy: 0.9375\n",
      "train Loss: 0.0004 Acc: 0.1844 batch_loss: 0.7202 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0004 Acc: 0.1930 batch_loss: 0.7927 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0004 Acc: 0.2019 batch_loss: 0.5953 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0005 Acc: 0.2110 batch_loss: 0.2567 correct: 252 batch_accuracy: 0.9844\n",
      "train Loss: 0.0005 Acc: 0.2198 batch_loss: 0.4073 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0005 Acc: 0.2285 batch_loss: 0.2664 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0005 Acc: 0.2373 batch_loss: 1.3793 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0005 Acc: 0.2461 batch_loss: 0.4719 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0006 Acc: 0.2549 batch_loss: 1.1362 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0006 Acc: 0.2638 batch_loss: 0.4869 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0006 Acc: 0.2726 batch_loss: 0.7093 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0006 Acc: 0.2815 batch_loss: 0.1433 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0006 Acc: 0.2903 batch_loss: 0.1604 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0007 Acc: 0.2992 batch_loss: 0.7006 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0007 Acc: 0.3078 batch_loss: 1.0645 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0007 Acc: 0.3165 batch_loss: 0.3903 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0007 Acc: 0.3252 batch_loss: 0.5022 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0007 Acc: 0.3339 batch_loss: 0.4731 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0008 Acc: 0.3426 batch_loss: 0.4535 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0008 Acc: 0.3515 batch_loss: 0.1446 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0008 Acc: 0.3603 batch_loss: 0.6145 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0008 Acc: 0.3690 batch_loss: 0.5057 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0008 Acc: 0.3779 batch_loss: 0.3228 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0008 Acc: 0.3866 batch_loss: 0.7332 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0009 Acc: 0.3955 batch_loss: 0.6385 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0009 Acc: 0.4044 batch_loss: 0.1414 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0009 Acc: 0.4131 batch_loss: 0.3123 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0009 Acc: 0.4218 batch_loss: 0.4036 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0009 Acc: 0.4306 batch_loss: 0.7705 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0009 Acc: 0.4394 batch_loss: 0.1824 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0010 Acc: 0.4483 batch_loss: 0.9146 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0010 Acc: 0.4571 batch_loss: 0.2213 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0010 Acc: 0.4660 batch_loss: 0.3162 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0010 Acc: 0.4749 batch_loss: 0.1211 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0010 Acc: 0.4837 batch_loss: 0.3715 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0010 Acc: 0.4925 batch_loss: 0.2533 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0010 Acc: 0.5015 batch_loss: 0.0822 correct: 251 batch_accuracy: 0.9805\n",
      "train Loss: 0.0010 Acc: 0.5103 batch_loss: 0.4862 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0011 Acc: 0.5191 batch_loss: 0.9962 correct: 245 batch_accuracy: 0.9570\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0011 Acc: 0.5278 batch_loss: 0.8732 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0011 Acc: 0.5367 batch_loss: 0.7595 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0011 Acc: 0.5455 batch_loss: 0.1406 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0011 Acc: 0.5543 batch_loss: 0.3641 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0012 Acc: 0.5633 batch_loss: 0.5074 correct: 252 batch_accuracy: 0.9844\n",
      "train Loss: 0.0012 Acc: 0.5723 batch_loss: 0.6609 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0012 Acc: 0.5812 batch_loss: 0.2892 correct: 250 batch_accuracy: 0.9766\n",
      "train Loss: 0.0012 Acc: 0.5901 batch_loss: 0.4419 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0012 Acc: 0.5990 batch_loss: 0.3747 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0012 Acc: 0.6079 batch_loss: 0.5058 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0013 Acc: 0.6169 batch_loss: 0.1254 correct: 250 batch_accuracy: 0.9766\n",
      "train Loss: 0.0013 Acc: 0.6259 batch_loss: 0.0816 correct: 251 batch_accuracy: 0.9805\n",
      "train Loss: 0.0013 Acc: 0.6346 batch_loss: 0.2377 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0013 Acc: 0.6432 batch_loss: 0.4864 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0013 Acc: 0.6519 batch_loss: 0.8711 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0013 Acc: 0.6608 batch_loss: 0.0676 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0013 Acc: 0.6696 batch_loss: 0.1517 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0013 Acc: 0.6786 batch_loss: 0.2870 correct: 250 batch_accuracy: 0.9766\n",
      "train Loss: 0.0013 Acc: 0.6874 batch_loss: 0.0955 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0013 Acc: 0.6962 batch_loss: 0.1828 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0014 Acc: 0.7052 batch_loss: 0.7094 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0014 Acc: 0.7140 batch_loss: 0.3968 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0014 Acc: 0.7227 batch_loss: 1.3756 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0015 Acc: 0.7316 batch_loss: 0.6647 correct: 250 batch_accuracy: 0.9766\n",
      "train Loss: 0.0015 Acc: 0.7405 batch_loss: 0.1348 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0015 Acc: 0.7492 batch_loss: 0.7641 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0015 Acc: 0.7581 batch_loss: 0.0673 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0015 Acc: 0.7670 batch_loss: 0.2460 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0015 Acc: 0.7758 batch_loss: 0.9713 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0015 Acc: 0.7846 batch_loss: 0.1448 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0016 Acc: 0.7933 batch_loss: 0.8912 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0016 Acc: 0.8022 batch_loss: 0.2088 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0016 Acc: 0.8110 batch_loss: 0.1841 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0016 Acc: 0.8195 batch_loss: 0.4527 correct: 240 batch_accuracy: 0.9375\n",
      "train Loss: 0.0016 Acc: 0.8281 batch_loss: 0.8149 correct: 239 batch_accuracy: 0.9336\n",
      "train Loss: 0.0016 Acc: 0.8371 batch_loss: 0.1779 correct: 250 batch_accuracy: 0.9766\n",
      "train Loss: 0.0017 Acc: 0.8459 batch_loss: 1.3083 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0017 Acc: 0.8545 batch_loss: 1.2051 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0018 Acc: 0.8633 batch_loss: 1.3997 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0018 Acc: 0.8719 batch_loss: 0.7045 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0018 Acc: 0.8808 batch_loss: 0.2012 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0018 Acc: 0.8896 batch_loss: 0.3527 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0018 Acc: 0.8985 batch_loss: 0.6211 correct: 250 batch_accuracy: 0.9766\n",
      "train Loss: 0.0019 Acc: 0.9071 batch_loss: 0.3260 correct: 240 batch_accuracy: 0.9375\n",
      "train Loss: 0.0019 Acc: 0.9159 batch_loss: 0.2078 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0019 Acc: 0.9248 batch_loss: 0.3348 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0019 Acc: 0.9335 batch_loss: 0.6358 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0019 Acc: 0.9424 batch_loss: 0.2269 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0019 Acc: 0.9511 batch_loss: 0.6017 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0019 Acc: 0.9598 batch_loss: 0.3815 correct: 243 batch_accuracy: 0.9492\n",
      "Accuracy of the network on the test images: 82.21354 %\n",
      "Accuracy of   pos : 84 %\n",
      "Accuracy of   neg : 87 %\n",
      "Accuracy of pos_o : 74 %\n",
      "Accuracy of   nuc : 69 %\n",
      "Accuracy of   non : 95 %\n",
      "class total:  [763.0, 775.0, 767.0, 764.0, 771.0]\n",
      "class correct:  [648.0, 678.0, 568.0, 528.0, 735.0]\n",
      "total:  3840\n",
      "correct:  3157\n",
      "trainloader ready!\n",
      "testloader ready!\n",
      "Epoch 3/9\n",
      "----------\n",
      "train Loss: 0.0000 Acc: 0.0088 batch_loss: 0.2534 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0000 Acc: 0.0176 batch_loss: 0.4861 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0000 Acc: 0.0266 batch_loss: 0.1705 correct: 251 batch_accuracy: 0.9805\n",
      "train Loss: 0.0000 Acc: 0.0353 batch_loss: 0.3464 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0001 Acc: 0.0441 batch_loss: 0.1706 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0001 Acc: 0.0531 batch_loss: 0.0966 correct: 251 batch_accuracy: 0.9805\n",
      "train Loss: 0.0001 Acc: 0.0620 batch_loss: 0.6373 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0001 Acc: 0.0711 batch_loss: 0.2874 correct: 253 batch_accuracy: 0.9883\n",
      "train Loss: 0.0001 Acc: 0.0799 batch_loss: 0.2447 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0001 Acc: 0.0887 batch_loss: 0.5727 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0001 Acc: 0.0975 batch_loss: 0.4028 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0001 Acc: 0.1061 batch_loss: 0.2916 correct: 239 batch_accuracy: 0.9336\n",
      "train Loss: 0.0002 Acc: 0.1150 batch_loss: 0.3335 correct: 250 batch_accuracy: 0.9766\n",
      "train Loss: 0.0002 Acc: 0.1236 batch_loss: 0.9907 correct: 239 batch_accuracy: 0.9336\n",
      "train Loss: 0.0002 Acc: 0.1323 batch_loss: 0.6008 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0002 Acc: 0.1410 batch_loss: 0.3474 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0002 Acc: 0.1498 batch_loss: 0.4816 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0003 Acc: 0.1585 batch_loss: 0.8268 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0003 Acc: 0.1675 batch_loss: 0.3070 correct: 250 batch_accuracy: 0.9766\n",
      "train Loss: 0.0003 Acc: 0.1763 batch_loss: 0.5407 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0003 Acc: 0.1851 batch_loss: 0.4268 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0003 Acc: 0.1939 batch_loss: 0.7079 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0003 Acc: 0.2028 batch_loss: 0.1886 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0004 Acc: 0.2116 batch_loss: 0.3017 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0004 Acc: 0.2201 batch_loss: 1.3873 correct: 236 batch_accuracy: 0.9219\n",
      "train Loss: 0.0004 Acc: 0.2289 batch_loss: 0.3199 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0004 Acc: 0.2376 batch_loss: 0.7686 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0005 Acc: 0.2464 batch_loss: 0.7154 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0005 Acc: 0.2552 batch_loss: 0.5846 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0005 Acc: 0.2639 batch_loss: 0.8351 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0005 Acc: 0.2729 batch_loss: 0.1522 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0005 Acc: 0.2816 batch_loss: 0.2161 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0006 Acc: 0.2904 batch_loss: 0.5493 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0006 Acc: 0.2993 batch_loss: 0.4423 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0006 Acc: 0.3083 batch_loss: 0.1463 correct: 251 batch_accuracy: 0.9805\n",
      "train Loss: 0.0006 Acc: 0.3171 batch_loss: 0.6553 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0006 Acc: 0.3259 batch_loss: 0.2056 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0006 Acc: 0.3347 batch_loss: 0.6714 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0007 Acc: 0.3436 batch_loss: 0.5563 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0007 Acc: 0.3523 batch_loss: 1.1557 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0007 Acc: 0.3611 batch_loss: 0.7695 correct: 245 batch_accuracy: 0.9570\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0007 Acc: 0.3699 batch_loss: 0.4243 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0007 Acc: 0.3787 batch_loss: 0.2437 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0008 Acc: 0.3876 batch_loss: 0.3320 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0008 Acc: 0.3964 batch_loss: 0.8823 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0008 Acc: 0.4052 batch_loss: 0.3121 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0008 Acc: 0.4139 batch_loss: 0.8688 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0008 Acc: 0.4227 batch_loss: 0.1383 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0008 Acc: 0.4316 batch_loss: 0.2176 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0009 Acc: 0.4402 batch_loss: 0.8553 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0009 Acc: 0.4488 batch_loss: 1.0331 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0009 Acc: 0.4576 batch_loss: 0.8891 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0010 Acc: 0.4664 batch_loss: 0.6530 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0010 Acc: 0.4753 batch_loss: 0.3391 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0010 Acc: 0.4841 batch_loss: 0.2076 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0010 Acc: 0.4928 batch_loss: 0.3540 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0010 Acc: 0.5015 batch_loss: 0.9619 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0010 Acc: 0.5105 batch_loss: 0.1401 correct: 250 batch_accuracy: 0.9766\n",
      "train Loss: 0.0011 Acc: 0.5193 batch_loss: 0.7972 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0011 Acc: 0.5281 batch_loss: 0.7966 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0011 Acc: 0.5369 batch_loss: 0.7393 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0011 Acc: 0.5459 batch_loss: 0.2235 correct: 250 batch_accuracy: 0.9766\n",
      "train Loss: 0.0011 Acc: 0.5547 batch_loss: 0.5036 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0012 Acc: 0.5635 batch_loss: 0.2391 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0012 Acc: 0.5722 batch_loss: 1.1111 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0012 Acc: 0.5812 batch_loss: 0.0875 correct: 250 batch_accuracy: 0.9766\n",
      "train Loss: 0.0012 Acc: 0.5899 batch_loss: 0.9125 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0013 Acc: 0.5986 batch_loss: 0.5916 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0013 Acc: 0.6073 batch_loss: 0.1970 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0013 Acc: 0.6160 batch_loss: 1.0495 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0013 Acc: 0.6249 batch_loss: 0.1005 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0013 Acc: 0.6338 batch_loss: 0.2931 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0013 Acc: 0.6427 batch_loss: 0.6574 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0013 Acc: 0.6514 batch_loss: 0.2885 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0014 Acc: 0.6601 batch_loss: 0.7606 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0014 Acc: 0.6689 batch_loss: 0.7125 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0014 Acc: 0.6777 batch_loss: 0.8562 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0014 Acc: 0.6866 batch_loss: 0.2143 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0014 Acc: 0.6955 batch_loss: 0.1236 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0014 Acc: 0.7044 batch_loss: 0.0994 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0015 Acc: 0.7132 batch_loss: 0.3822 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0015 Acc: 0.7218 batch_loss: 1.0734 correct: 240 batch_accuracy: 0.9375\n",
      "train Loss: 0.0015 Acc: 0.7307 batch_loss: 0.2350 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0015 Acc: 0.7396 batch_loss: 0.2573 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0015 Acc: 0.7486 batch_loss: 0.4617 correct: 250 batch_accuracy: 0.9766\n",
      "train Loss: 0.0016 Acc: 0.7575 batch_loss: 0.5586 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0016 Acc: 0.7663 batch_loss: 0.5930 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0016 Acc: 0.7751 batch_loss: 0.4869 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0016 Acc: 0.7838 batch_loss: 0.3993 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0016 Acc: 0.7925 batch_loss: 1.1178 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0017 Acc: 0.8012 batch_loss: 0.7838 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0017 Acc: 0.8101 batch_loss: 0.1387 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0017 Acc: 0.8187 batch_loss: 0.6769 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0017 Acc: 0.8274 batch_loss: 0.7591 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0018 Acc: 0.8360 batch_loss: 0.8279 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0018 Acc: 0.8448 batch_loss: 0.2430 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0018 Acc: 0.8535 batch_loss: 1.0094 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0018 Acc: 0.8624 batch_loss: 0.1316 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0018 Acc: 0.8712 batch_loss: 0.5011 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0018 Acc: 0.8801 batch_loss: 0.2551 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0019 Acc: 0.8889 batch_loss: 0.8658 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0019 Acc: 0.8977 batch_loss: 0.2976 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0019 Acc: 0.9066 batch_loss: 0.7368 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0019 Acc: 0.9154 batch_loss: 0.6371 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0019 Acc: 0.9244 batch_loss: 0.0711 correct: 252 batch_accuracy: 0.9844\n",
      "train Loss: 0.0019 Acc: 0.9332 batch_loss: 0.4635 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0020 Acc: 0.9420 batch_loss: 0.3071 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0020 Acc: 0.9508 batch_loss: 0.1850 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0020 Acc: 0.9596 batch_loss: 1.3667 correct: 246 batch_accuracy: 0.9609\n",
      "Accuracy of the network on the test images: 83.02083 %\n",
      "Accuracy of   pos : 85 %\n",
      "Accuracy of   neg : 88 %\n",
      "Accuracy of pos_o : 76 %\n",
      "Accuracy of   nuc : 67 %\n",
      "Accuracy of   non : 96 %\n",
      "class total:  [764.0, 769.0, 765.0, 764.0, 778.0]\n",
      "class correct:  [650.0, 681.0, 589.0, 516.0, 752.0]\n",
      "total:  3840\n",
      "correct:  3188\n",
      "trainloader ready!\n",
      "testloader ready!\n",
      "Epoch 4/9\n",
      "----------\n",
      "train Loss: 0.0000 Acc: 0.0088 batch_loss: 0.3603 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0000 Acc: 0.0178 batch_loss: 0.4568 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0000 Acc: 0.0265 batch_loss: 0.4627 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0001 Acc: 0.0352 batch_loss: 0.5317 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0001 Acc: 0.0441 batch_loss: 0.0592 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0001 Acc: 0.0529 batch_loss: 0.6112 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0001 Acc: 0.0617 batch_loss: 0.2432 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0001 Acc: 0.0705 batch_loss: 0.4864 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0001 Acc: 0.0794 batch_loss: 0.1572 correct: 251 batch_accuracy: 0.9805\n",
      "train Loss: 0.0002 Acc: 0.0882 batch_loss: 1.0016 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0002 Acc: 0.0971 batch_loss: 0.3927 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0002 Acc: 0.1058 batch_loss: 0.8515 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0002 Acc: 0.1145 batch_loss: 0.6027 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0003 Acc: 0.1233 batch_loss: 0.7724 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0003 Acc: 0.1321 batch_loss: 0.5958 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0003 Acc: 0.1410 batch_loss: 0.3005 correct: 250 batch_accuracy: 0.9766\n",
      "train Loss: 0.0004 Acc: 0.1496 batch_loss: 2.0124 correct: 240 batch_accuracy: 0.9375\n",
      "train Loss: 0.0004 Acc: 0.1583 batch_loss: 0.2918 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0004 Acc: 0.1670 batch_loss: 0.4719 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0004 Acc: 0.1758 batch_loss: 1.0278 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0004 Acc: 0.1846 batch_loss: 0.4757 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0005 Acc: 0.1933 batch_loss: 0.4825 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0005 Acc: 0.2023 batch_loss: 0.1404 correct: 253 batch_accuracy: 0.9883\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0005 Acc: 0.2111 batch_loss: 0.9099 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0005 Acc: 0.2199 batch_loss: 0.2776 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0005 Acc: 0.2289 batch_loss: 0.0807 correct: 251 batch_accuracy: 0.9805\n",
      "train Loss: 0.0005 Acc: 0.2378 batch_loss: 0.2835 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0005 Acc: 0.2464 batch_loss: 0.7156 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0006 Acc: 0.2552 batch_loss: 0.4805 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0006 Acc: 0.2641 batch_loss: 0.1694 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0006 Acc: 0.2730 batch_loss: 0.0911 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0006 Acc: 0.2818 batch_loss: 0.4479 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0006 Acc: 0.2904 batch_loss: 0.5042 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0006 Acc: 0.2994 batch_loss: 0.0655 correct: 250 batch_accuracy: 0.9766\n",
      "train Loss: 0.0006 Acc: 0.3082 batch_loss: 0.3838 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0006 Acc: 0.3170 batch_loss: 0.4385 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0006 Acc: 0.3258 batch_loss: 0.3457 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0007 Acc: 0.3348 batch_loss: 0.7530 correct: 250 batch_accuracy: 0.9766\n",
      "train Loss: 0.0007 Acc: 0.3435 batch_loss: 0.5032 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0007 Acc: 0.3523 batch_loss: 0.7008 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0007 Acc: 0.3611 batch_loss: 0.6646 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0007 Acc: 0.3699 batch_loss: 0.1962 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0007 Acc: 0.3788 batch_loss: 0.1323 correct: 251 batch_accuracy: 0.9805\n",
      "train Loss: 0.0008 Acc: 0.3877 batch_loss: 0.6658 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0008 Acc: 0.3964 batch_loss: 0.2597 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0008 Acc: 0.4051 batch_loss: 0.2820 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0008 Acc: 0.4141 batch_loss: 0.0319 correct: 252 batch_accuracy: 0.9844\n",
      "train Loss: 0.0008 Acc: 0.4230 batch_loss: 0.5366 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0008 Acc: 0.4319 batch_loss: 0.6027 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0009 Acc: 0.4407 batch_loss: 0.5242 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0009 Acc: 0.4494 batch_loss: 0.8451 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0009 Acc: 0.4582 batch_loss: 0.2971 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0009 Acc: 0.4669 batch_loss: 0.2790 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0009 Acc: 0.4758 batch_loss: 0.4207 correct: 250 batch_accuracy: 0.9766\n",
      "train Loss: 0.0009 Acc: 0.4847 batch_loss: 0.1143 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0009 Acc: 0.4934 batch_loss: 0.5629 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0010 Acc: 0.5020 batch_loss: 0.5584 correct: 240 batch_accuracy: 0.9375\n",
      "train Loss: 0.0010 Acc: 0.5109 batch_loss: 0.3643 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0010 Acc: 0.5198 batch_loss: 0.8375 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0010 Acc: 0.5285 batch_loss: 0.5189 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0010 Acc: 0.5373 batch_loss: 0.1949 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0010 Acc: 0.5462 batch_loss: 0.2133 correct: 250 batch_accuracy: 0.9766\n",
      "train Loss: 0.0011 Acc: 0.5550 batch_loss: 0.7415 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0011 Acc: 0.5639 batch_loss: 0.4805 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0011 Acc: 0.5725 batch_loss: 0.8824 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0011 Acc: 0.5813 batch_loss: 0.2648 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0011 Acc: 0.5901 batch_loss: 0.4305 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0011 Acc: 0.5991 batch_loss: 0.1525 correct: 250 batch_accuracy: 0.9766\n",
      "train Loss: 0.0012 Acc: 0.6079 batch_loss: 0.4597 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0012 Acc: 0.6165 batch_loss: 0.2294 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0012 Acc: 0.6253 batch_loss: 0.9490 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0012 Acc: 0.6343 batch_loss: 0.2795 correct: 250 batch_accuracy: 0.9766\n",
      "train Loss: 0.0012 Acc: 0.6430 batch_loss: 0.7844 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0013 Acc: 0.6517 batch_loss: 0.4414 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0013 Acc: 0.6606 batch_loss: 0.0732 correct: 250 batch_accuracy: 0.9766\n",
      "train Loss: 0.0013 Acc: 0.6695 batch_loss: 0.5827 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0013 Acc: 0.6784 batch_loss: 0.2915 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0013 Acc: 0.6873 batch_loss: 0.3486 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0013 Acc: 0.6961 batch_loss: 0.3353 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0013 Acc: 0.7046 batch_loss: 0.3159 correct: 238 batch_accuracy: 0.9297\n",
      "train Loss: 0.0014 Acc: 0.7134 batch_loss: 1.0585 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0014 Acc: 0.7220 batch_loss: 2.0847 correct: 240 batch_accuracy: 0.9375\n",
      "train Loss: 0.0015 Acc: 0.7307 batch_loss: 0.5999 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0015 Acc: 0.7396 batch_loss: 0.1236 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0015 Acc: 0.7484 batch_loss: 0.1947 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0015 Acc: 0.7571 batch_loss: 0.7126 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0015 Acc: 0.7658 batch_loss: 0.3398 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0016 Acc: 0.7746 batch_loss: 1.3266 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0016 Acc: 0.7834 batch_loss: 0.4023 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0016 Acc: 0.7922 batch_loss: 0.4521 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0016 Acc: 0.8011 batch_loss: 0.3759 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0016 Acc: 0.8100 batch_loss: 0.0820 correct: 250 batch_accuracy: 0.9766\n",
      "train Loss: 0.0016 Acc: 0.8188 batch_loss: 0.3339 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0016 Acc: 0.8276 batch_loss: 0.4759 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0017 Acc: 0.8363 batch_loss: 1.0258 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0017 Acc: 0.8451 batch_loss: 0.6262 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0017 Acc: 0.8539 batch_loss: 0.2385 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0017 Acc: 0.8627 batch_loss: 0.2969 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0017 Acc: 0.8714 batch_loss: 0.9060 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0018 Acc: 0.8803 batch_loss: 0.1685 correct: 250 batch_accuracy: 0.9766\n",
      "train Loss: 0.0018 Acc: 0.8893 batch_loss: 0.1118 correct: 250 batch_accuracy: 0.9766\n",
      "train Loss: 0.0018 Acc: 0.8980 batch_loss: 1.1117 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0018 Acc: 0.9071 batch_loss: 0.5553 correct: 253 batch_accuracy: 0.9883\n",
      "train Loss: 0.0018 Acc: 0.9159 batch_loss: 0.3551 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0018 Acc: 0.9248 batch_loss: 0.1968 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0019 Acc: 0.9337 batch_loss: 0.6018 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0019 Acc: 0.9425 batch_loss: 0.6795 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0019 Acc: 0.9514 batch_loss: 0.7410 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0019 Acc: 0.9602 batch_loss: 0.7599 correct: 246 batch_accuracy: 0.9609\n",
      "Accuracy of the network on the test images: 82.73438 %\n",
      "Accuracy of   pos : 82 %\n",
      "Accuracy of   neg : 89 %\n",
      "Accuracy of pos_o : 76 %\n",
      "Accuracy of   nuc : 70 %\n",
      "Accuracy of   non : 95 %\n",
      "class total:  [750.0, 766.0, 771.0, 771.0, 782.0]\n",
      "class correct:  [616.0, 687.0, 586.0, 545.0, 743.0]\n",
      "total:  3840\n",
      "correct:  3177\n",
      "trainloader ready!\n",
      "testloader ready!\n",
      "Epoch 5/9\n",
      "----------\n",
      "train Loss: 0.0000 Acc: 0.0087 batch_loss: 0.3226 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0000 Acc: 0.0177 batch_loss: 0.1845 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0000 Acc: 0.0265 batch_loss: 0.4861 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0001 Acc: 0.0351 batch_loss: 1.1898 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0001 Acc: 0.0438 batch_loss: 1.0892 correct: 243 batch_accuracy: 0.9492\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0001 Acc: 0.0528 batch_loss: 0.1617 correct: 250 batch_accuracy: 0.9766\n",
      "train Loss: 0.0001 Acc: 0.0615 batch_loss: 0.6070 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0002 Acc: 0.0703 batch_loss: 0.6922 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0002 Acc: 0.0790 batch_loss: 1.3177 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0002 Acc: 0.0878 batch_loss: 0.6094 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0003 Acc: 0.0965 batch_loss: 0.6242 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0003 Acc: 0.1053 batch_loss: 0.3773 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0003 Acc: 0.1142 batch_loss: 0.7201 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0003 Acc: 0.1229 batch_loss: 0.3714 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0003 Acc: 0.1319 batch_loss: 0.1625 correct: 252 batch_accuracy: 0.9844\n",
      "train Loss: 0.0003 Acc: 0.1407 batch_loss: 0.4863 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0004 Acc: 0.1496 batch_loss: 1.1447 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0004 Acc: 0.1584 batch_loss: 0.2930 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0004 Acc: 0.1672 batch_loss: 0.5674 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0004 Acc: 0.1760 batch_loss: 0.6963 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0004 Acc: 0.1849 batch_loss: 0.1997 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0004 Acc: 0.1937 batch_loss: 0.1460 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0005 Acc: 0.2026 batch_loss: 0.6516 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0005 Acc: 0.2115 batch_loss: 0.1662 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0005 Acc: 0.2203 batch_loss: 0.5702 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0005 Acc: 0.2292 batch_loss: 0.3187 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0005 Acc: 0.2379 batch_loss: 0.6178 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0005 Acc: 0.2468 batch_loss: 0.1701 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0006 Acc: 0.2556 batch_loss: 0.6053 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0006 Acc: 0.2644 batch_loss: 0.3735 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0006 Acc: 0.2730 batch_loss: 0.4934 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0006 Acc: 0.2818 batch_loss: 0.3439 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0006 Acc: 0.2906 batch_loss: 0.6658 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0006 Acc: 0.2995 batch_loss: 0.1037 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0006 Acc: 0.3083 batch_loss: 0.3889 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0006 Acc: 0.3173 batch_loss: 0.1379 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0007 Acc: 0.3261 batch_loss: 0.2791 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0007 Acc: 0.3350 batch_loss: 0.5797 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0007 Acc: 0.3440 batch_loss: 0.5457 correct: 251 batch_accuracy: 0.9805\n",
      "train Loss: 0.0007 Acc: 0.3527 batch_loss: 0.3858 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0007 Acc: 0.3617 batch_loss: 0.1855 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0007 Acc: 0.3704 batch_loss: 0.1648 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0007 Acc: 0.3794 batch_loss: 0.1866 correct: 251 batch_accuracy: 0.9805\n",
      "train Loss: 0.0008 Acc: 0.3882 batch_loss: 0.8888 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0008 Acc: 0.3971 batch_loss: 0.2406 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0008 Acc: 0.4060 batch_loss: 0.2703 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0008 Acc: 0.4150 batch_loss: 0.3976 correct: 251 batch_accuracy: 0.9805\n",
      "train Loss: 0.0008 Acc: 0.4236 batch_loss: 0.4263 correct: 240 batch_accuracy: 0.9375\n",
      "train Loss: 0.0008 Acc: 0.4323 batch_loss: 0.8335 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0009 Acc: 0.4409 batch_loss: 0.7575 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0009 Acc: 0.4497 batch_loss: 0.4110 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0009 Acc: 0.4586 batch_loss: 0.4893 correct: 250 batch_accuracy: 0.9766\n",
      "train Loss: 0.0009 Acc: 0.4672 batch_loss: 0.7056 correct: 240 batch_accuracy: 0.9375\n",
      "train Loss: 0.0009 Acc: 0.4762 batch_loss: 0.5696 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0009 Acc: 0.4851 batch_loss: 0.1131 correct: 250 batch_accuracy: 0.9766\n",
      "train Loss: 0.0010 Acc: 0.4940 batch_loss: 0.2412 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0010 Acc: 0.5029 batch_loss: 0.1565 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0010 Acc: 0.5115 batch_loss: 0.7595 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0010 Acc: 0.5202 batch_loss: 0.6945 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0010 Acc: 0.5291 batch_loss: 0.5444 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0011 Acc: 0.5377 batch_loss: 0.7618 correct: 240 batch_accuracy: 0.9375\n",
      "train Loss: 0.0011 Acc: 0.5465 batch_loss: 0.3585 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0011 Acc: 0.5554 batch_loss: 0.1530 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0011 Acc: 0.5641 batch_loss: 0.6657 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0011 Acc: 0.5729 batch_loss: 0.5437 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0011 Acc: 0.5818 batch_loss: 0.2838 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0012 Acc: 0.5905 batch_loss: 0.6997 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0012 Acc: 0.5995 batch_loss: 0.3450 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0012 Acc: 0.6083 batch_loss: 0.1073 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0012 Acc: 0.6173 batch_loss: 0.3253 correct: 253 batch_accuracy: 0.9883\n",
      "train Loss: 0.0012 Acc: 0.6262 batch_loss: 0.3362 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0012 Acc: 0.6348 batch_loss: 0.6408 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0013 Acc: 0.6434 batch_loss: 0.8784 correct: 240 batch_accuracy: 0.9375\n",
      "train Loss: 0.0013 Acc: 0.6523 batch_loss: 0.6718 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0013 Acc: 0.6612 batch_loss: 0.2297 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0013 Acc: 0.6699 batch_loss: 1.1336 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0013 Acc: 0.6787 batch_loss: 0.2188 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0013 Acc: 0.6873 batch_loss: 0.4148 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0014 Acc: 0.6962 batch_loss: 0.2542 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0014 Acc: 0.7052 batch_loss: 0.1179 correct: 250 batch_accuracy: 0.9766\n",
      "train Loss: 0.0014 Acc: 0.7141 batch_loss: 0.5963 correct: 250 batch_accuracy: 0.9766\n",
      "train Loss: 0.0014 Acc: 0.7228 batch_loss: 1.1599 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0014 Acc: 0.7315 batch_loss: 0.2322 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0015 Acc: 0.7402 batch_loss: 1.3582 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0015 Acc: 0.7489 batch_loss: 0.7835 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0015 Acc: 0.7577 batch_loss: 0.2946 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0015 Acc: 0.7666 batch_loss: 0.3498 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0015 Acc: 0.7755 batch_loss: 0.2204 correct: 251 batch_accuracy: 0.9805\n",
      "train Loss: 0.0016 Acc: 0.7844 batch_loss: 0.8552 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0016 Acc: 0.7932 batch_loss: 0.2372 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0016 Acc: 0.8018 batch_loss: 1.0583 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0016 Acc: 0.8106 batch_loss: 0.3839 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0016 Acc: 0.8193 batch_loss: 0.1372 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0017 Acc: 0.8281 batch_loss: 0.5115 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0017 Acc: 0.8371 batch_loss: 0.0741 correct: 251 batch_accuracy: 0.9805\n",
      "train Loss: 0.0017 Acc: 0.8459 batch_loss: 0.4520 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0017 Acc: 0.8547 batch_loss: 0.5864 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0017 Acc: 0.8634 batch_loss: 0.5121 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0017 Acc: 0.8722 batch_loss: 0.5857 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0017 Acc: 0.8812 batch_loss: 0.2615 correct: 250 batch_accuracy: 0.9766\n",
      "train Loss: 0.0018 Acc: 0.8900 batch_loss: 0.5219 correct: 246 batch_accuracy: 0.9609\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0018 Acc: 0.8987 batch_loss: 0.7356 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0018 Acc: 0.9075 batch_loss: 0.3657 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0018 Acc: 0.9164 batch_loss: 0.2532 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0018 Acc: 0.9251 batch_loss: 0.8235 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0019 Acc: 0.9338 batch_loss: 0.5972 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0019 Acc: 0.9427 batch_loss: 0.1037 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0019 Acc: 0.9515 batch_loss: 0.5825 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0019 Acc: 0.9601 batch_loss: 0.4617 correct: 241 batch_accuracy: 0.9414\n",
      "Accuracy of the network on the test images: 82.03125 %\n",
      "Accuracy of   pos : 85 %\n",
      "Accuracy of   neg : 87 %\n",
      "Accuracy of pos_o : 74 %\n",
      "Accuracy of   nuc : 67 %\n",
      "Accuracy of   non : 95 %\n",
      "class total:  [769.0, 763.0, 753.0, 779.0, 776.0]\n",
      "class correct:  [656.0, 665.0, 564.0, 525.0, 740.0]\n",
      "total:  3840\n",
      "correct:  3150\n",
      "trainloader ready!\n",
      "testloader ready!\n",
      "Epoch 6/9\n",
      "----------\n",
      "train Loss: 0.0000 Acc: 0.0089 batch_loss: 0.1708 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0000 Acc: 0.0178 batch_loss: 0.1876 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0000 Acc: 0.0266 batch_loss: 0.4156 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0000 Acc: 0.0353 batch_loss: 0.2788 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0000 Acc: 0.0443 batch_loss: 0.2489 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0001 Acc: 0.0530 batch_loss: 0.6414 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0001 Acc: 0.0618 batch_loss: 1.0440 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0001 Acc: 0.0706 batch_loss: 0.3201 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0001 Acc: 0.0794 batch_loss: 0.2305 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0001 Acc: 0.0884 batch_loss: 0.1287 correct: 251 batch_accuracy: 0.9805\n",
      "train Loss: 0.0001 Acc: 0.0973 batch_loss: 0.3582 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0002 Acc: 0.1061 batch_loss: 0.5469 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0002 Acc: 0.1150 batch_loss: 0.1737 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0002 Acc: 0.1237 batch_loss: 0.6577 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0002 Acc: 0.1324 batch_loss: 0.5880 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0002 Acc: 0.1411 batch_loss: 0.8472 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0003 Acc: 0.1496 batch_loss: 1.4284 correct: 239 batch_accuracy: 0.9336\n",
      "train Loss: 0.0003 Acc: 0.1584 batch_loss: 0.7024 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0004 Acc: 0.1670 batch_loss: 1.1355 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0004 Acc: 0.1756 batch_loss: 1.1402 correct: 240 batch_accuracy: 0.9375\n",
      "train Loss: 0.0004 Acc: 0.1846 batch_loss: 0.0924 correct: 250 batch_accuracy: 0.9766\n",
      "train Loss: 0.0004 Acc: 0.1933 batch_loss: 0.3948 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0004 Acc: 0.2021 batch_loss: 0.4167 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0005 Acc: 0.2110 batch_loss: 0.4970 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0005 Acc: 0.2199 batch_loss: 0.0870 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0005 Acc: 0.2287 batch_loss: 0.5036 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0005 Acc: 0.2376 batch_loss: 0.3098 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0005 Acc: 0.2465 batch_loss: 0.6822 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0005 Acc: 0.2555 batch_loss: 0.3299 correct: 251 batch_accuracy: 0.9805\n",
      "train Loss: 0.0005 Acc: 0.2644 batch_loss: 0.4913 correct: 250 batch_accuracy: 0.9766\n",
      "train Loss: 0.0006 Acc: 0.2733 batch_loss: 0.5894 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0006 Acc: 0.2820 batch_loss: 0.8036 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0006 Acc: 0.2908 batch_loss: 0.1765 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0006 Acc: 0.2995 batch_loss: 1.2852 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0007 Acc: 0.3081 batch_loss: 1.4441 correct: 240 batch_accuracy: 0.9375\n",
      "train Loss: 0.0007 Acc: 0.3169 batch_loss: 0.7112 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0007 Acc: 0.3256 batch_loss: 0.3853 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0007 Acc: 0.3344 batch_loss: 0.1656 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0008 Acc: 0.3433 batch_loss: 0.5435 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0008 Acc: 0.3521 batch_loss: 0.4063 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0008 Acc: 0.3609 batch_loss: 0.2175 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0008 Acc: 0.3696 batch_loss: 0.7688 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0008 Acc: 0.3783 batch_loss: 0.7145 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0008 Acc: 0.3871 batch_loss: 0.1927 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0008 Acc: 0.3961 batch_loss: 0.1338 correct: 251 batch_accuracy: 0.9805\n",
      "train Loss: 0.0008 Acc: 0.4050 batch_loss: 0.0911 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0009 Acc: 0.4136 batch_loss: 1.2050 correct: 238 batch_accuracy: 0.9297\n",
      "train Loss: 0.0009 Acc: 0.4223 batch_loss: 0.8658 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0009 Acc: 0.4312 batch_loss: 0.1599 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0009 Acc: 0.4400 batch_loss: 0.6049 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0010 Acc: 0.4488 batch_loss: 0.3398 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0010 Acc: 0.4574 batch_loss: 0.8172 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0010 Acc: 0.4662 batch_loss: 0.8420 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0011 Acc: 0.4749 batch_loss: 0.9967 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0011 Acc: 0.4837 batch_loss: 0.7951 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0011 Acc: 0.4922 batch_loss: 0.7944 correct: 238 batch_accuracy: 0.9297\n",
      "train Loss: 0.0011 Acc: 0.5009 batch_loss: 0.9209 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0012 Acc: 0.5097 batch_loss: 0.4875 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0012 Acc: 0.5185 batch_loss: 0.6736 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0012 Acc: 0.5273 batch_loss: 0.4189 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0012 Acc: 0.5363 batch_loss: 0.3354 correct: 252 batch_accuracy: 0.9844\n",
      "train Loss: 0.0013 Acc: 0.5452 batch_loss: 1.0668 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0013 Acc: 0.5539 batch_loss: 0.3780 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0013 Acc: 0.5627 batch_loss: 0.1931 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0013 Acc: 0.5714 batch_loss: 0.4963 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0013 Acc: 0.5802 batch_loss: 0.6336 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0013 Acc: 0.5890 batch_loss: 0.1394 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0013 Acc: 0.5977 batch_loss: 0.5051 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0014 Acc: 0.6064 batch_loss: 0.6539 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0014 Acc: 0.6153 batch_loss: 0.1076 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0014 Acc: 0.6241 batch_loss: 0.4078 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0014 Acc: 0.6329 batch_loss: 0.3893 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0014 Acc: 0.6417 batch_loss: 0.7256 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0015 Acc: 0.6504 batch_loss: 1.2285 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0015 Acc: 0.6592 batch_loss: 0.6361 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0015 Acc: 0.6681 batch_loss: 0.6371 correct: 250 batch_accuracy: 0.9766\n",
      "train Loss: 0.0015 Acc: 0.6771 batch_loss: 0.0895 correct: 250 batch_accuracy: 0.9766\n",
      "train Loss: 0.0015 Acc: 0.6860 batch_loss: 0.6548 correct: 250 batch_accuracy: 0.9766\n",
      "train Loss: 0.0016 Acc: 0.6948 batch_loss: 0.9094 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0016 Acc: 0.7036 batch_loss: 0.4200 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0016 Acc: 0.7123 batch_loss: 0.3953 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0016 Acc: 0.7211 batch_loss: 0.1394 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0016 Acc: 0.7300 batch_loss: 0.1578 correct: 249 batch_accuracy: 0.9727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0016 Acc: 0.7388 batch_loss: 0.8316 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0016 Acc: 0.7477 batch_loss: 0.1316 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0016 Acc: 0.7567 batch_loss: 0.0958 correct: 252 batch_accuracy: 0.9844\n",
      "train Loss: 0.0017 Acc: 0.7656 batch_loss: 0.3396 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0017 Acc: 0.7743 batch_loss: 1.4435 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0017 Acc: 0.7831 batch_loss: 0.2521 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0018 Acc: 0.7919 batch_loss: 1.5036 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0018 Acc: 0.8008 batch_loss: 0.0573 correct: 250 batch_accuracy: 0.9766\n",
      "train Loss: 0.0018 Acc: 0.8096 batch_loss: 0.3918 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0018 Acc: 0.8184 batch_loss: 0.5760 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0018 Acc: 0.8269 batch_loss: 0.9423 correct: 237 batch_accuracy: 0.9258\n",
      "train Loss: 0.0019 Acc: 0.8357 batch_loss: 0.3612 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0019 Acc: 0.8443 batch_loss: 0.4669 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0019 Acc: 0.8531 batch_loss: 0.6729 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0019 Acc: 0.8620 batch_loss: 0.5389 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0019 Acc: 0.8707 batch_loss: 0.2794 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0019 Acc: 0.8797 batch_loss: 0.3736 correct: 250 batch_accuracy: 0.9766\n",
      "train Loss: 0.0020 Acc: 0.8886 batch_loss: 0.4121 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0020 Acc: 0.8974 batch_loss: 0.6679 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0020 Acc: 0.9062 batch_loss: 0.6678 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0020 Acc: 0.9150 batch_loss: 1.0597 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0020 Acc: 0.9239 batch_loss: 0.1505 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0021 Acc: 0.9328 batch_loss: 0.3254 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0021 Acc: 0.9415 batch_loss: 1.0121 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0021 Acc: 0.9503 batch_loss: 0.4567 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0021 Acc: 0.9593 batch_loss: 0.3387 correct: 249 batch_accuracy: 0.9727\n",
      "Accuracy of the network on the test images: 83.56771 %\n",
      "Accuracy of   pos : 85 %\n",
      "Accuracy of   neg : 89 %\n",
      "Accuracy of pos_o : 78 %\n",
      "Accuracy of   nuc : 68 %\n",
      "Accuracy of   non : 95 %\n",
      "class total:  [758.0, 772.0, 761.0, 770.0, 779.0]\n",
      "class correct:  [646.0, 691.0, 595.0, 530.0, 747.0]\n",
      "total:  3840\n",
      "correct:  3209\n",
      "trainloader ready!\n",
      "testloader ready!\n",
      "Epoch 7/9\n",
      "----------\n",
      "train Loss: 0.0000 Acc: 0.0088 batch_loss: 0.2787 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0000 Acc: 0.0177 batch_loss: 0.4999 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0000 Acc: 0.0262 batch_loss: 0.3389 correct: 238 batch_accuracy: 0.9297\n",
      "train Loss: 0.0001 Acc: 0.0349 batch_loss: 1.1525 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0001 Acc: 0.0438 batch_loss: 0.3396 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0001 Acc: 0.0527 batch_loss: 0.0566 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0001 Acc: 0.0614 batch_loss: 0.6259 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0001 Acc: 0.0702 batch_loss: 0.5934 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0001 Acc: 0.0791 batch_loss: 0.2317 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0002 Acc: 0.0879 batch_loss: 0.1762 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0002 Acc: 0.0967 batch_loss: 0.2792 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0002 Acc: 0.1055 batch_loss: 0.4500 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0002 Acc: 0.1142 batch_loss: 0.2869 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0002 Acc: 0.1232 batch_loss: 0.1159 correct: 250 batch_accuracy: 0.9766\n",
      "train Loss: 0.0002 Acc: 0.1322 batch_loss: 0.2456 correct: 252 batch_accuracy: 0.9844\n",
      "train Loss: 0.0002 Acc: 0.1409 batch_loss: 0.4640 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0002 Acc: 0.1496 batch_loss: 0.3452 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0002 Acc: 0.1585 batch_loss: 0.0581 correct: 250 batch_accuracy: 0.9766\n",
      "train Loss: 0.0003 Acc: 0.1674 batch_loss: 0.5505 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0003 Acc: 0.1761 batch_loss: 0.3489 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0003 Acc: 0.1849 batch_loss: 0.9895 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0003 Acc: 0.1938 batch_loss: 0.4287 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0003 Acc: 0.2029 batch_loss: 0.0113 correct: 255 batch_accuracy: 0.9961\n",
      "train Loss: 0.0003 Acc: 0.2116 batch_loss: 0.3824 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0003 Acc: 0.2205 batch_loss: 0.1555 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0003 Acc: 0.2292 batch_loss: 0.2051 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0003 Acc: 0.2380 batch_loss: 0.1072 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0004 Acc: 0.2469 batch_loss: 0.6284 correct: 250 batch_accuracy: 0.9766\n",
      "train Loss: 0.0004 Acc: 0.2557 batch_loss: 0.4487 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0004 Acc: 0.2644 batch_loss: 0.3861 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0004 Acc: 0.2733 batch_loss: 0.2102 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0005 Acc: 0.2818 batch_loss: 1.4926 correct: 238 batch_accuracy: 0.9297\n",
      "train Loss: 0.0005 Acc: 0.2905 batch_loss: 1.6549 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0006 Acc: 0.2994 batch_loss: 1.4820 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0006 Acc: 0.3081 batch_loss: 0.6184 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0006 Acc: 0.3170 batch_loss: 0.3240 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0006 Acc: 0.3259 batch_loss: 0.0986 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0006 Acc: 0.3347 batch_loss: 0.1445 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0006 Acc: 0.3437 batch_loss: 0.7876 correct: 250 batch_accuracy: 0.9766\n",
      "train Loss: 0.0007 Acc: 0.3525 batch_loss: 0.2621 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0007 Acc: 0.3612 batch_loss: 0.8324 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0007 Acc: 0.3702 batch_loss: 0.0476 correct: 252 batch_accuracy: 0.9844\n",
      "train Loss: 0.0007 Acc: 0.3789 batch_loss: 0.8666 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0007 Acc: 0.3878 batch_loss: 0.2343 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0007 Acc: 0.3967 batch_loss: 0.4606 correct: 251 batch_accuracy: 0.9805\n",
      "train Loss: 0.0008 Acc: 0.4057 batch_loss: 0.3623 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0008 Acc: 0.4146 batch_loss: 0.6695 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0008 Acc: 0.4235 batch_loss: 0.4251 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0008 Acc: 0.4323 batch_loss: 0.7490 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0008 Acc: 0.4410 batch_loss: 0.4676 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0009 Acc: 0.4498 batch_loss: 0.6596 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0009 Acc: 0.4585 batch_loss: 0.5374 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0009 Acc: 0.4672 batch_loss: 1.6326 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0009 Acc: 0.4762 batch_loss: 0.0993 correct: 250 batch_accuracy: 0.9766\n",
      "train Loss: 0.0009 Acc: 0.4851 batch_loss: 0.1338 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0010 Acc: 0.4937 batch_loss: 0.5705 correct: 240 batch_accuracy: 0.9375\n",
      "train Loss: 0.0010 Acc: 0.5023 batch_loss: 1.0906 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0010 Acc: 0.5112 batch_loss: 0.6828 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0010 Acc: 0.5199 batch_loss: 0.2342 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0010 Acc: 0.5289 batch_loss: 0.2167 correct: 252 batch_accuracy: 0.9844\n",
      "train Loss: 0.0011 Acc: 0.5377 batch_loss: 0.8251 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0011 Acc: 0.5466 batch_loss: 0.1499 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0011 Acc: 0.5552 batch_loss: 0.3594 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0011 Acc: 0.5639 batch_loss: 0.1682 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0011 Acc: 0.5728 batch_loss: 0.1749 correct: 247 batch_accuracy: 0.9648\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0011 Acc: 0.5817 batch_loss: 0.0725 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0011 Acc: 0.5903 batch_loss: 0.5614 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0012 Acc: 0.5990 batch_loss: 0.5919 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0012 Acc: 0.6079 batch_loss: 0.4272 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0012 Acc: 0.6168 batch_loss: 1.0560 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0012 Acc: 0.6257 batch_loss: 0.0812 correct: 250 batch_accuracy: 0.9766\n",
      "train Loss: 0.0012 Acc: 0.6348 batch_loss: 0.0437 correct: 252 batch_accuracy: 0.9844\n",
      "train Loss: 0.0012 Acc: 0.6435 batch_loss: 0.4826 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0012 Acc: 0.6525 batch_loss: 0.2888 correct: 250 batch_accuracy: 0.9766\n",
      "train Loss: 0.0012 Acc: 0.6613 batch_loss: 0.0944 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0013 Acc: 0.6702 batch_loss: 0.6313 correct: 250 batch_accuracy: 0.9766\n",
      "train Loss: 0.0013 Acc: 0.6791 batch_loss: 0.2205 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0013 Acc: 0.6878 batch_loss: 0.0909 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0013 Acc: 0.6967 batch_loss: 1.0008 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0013 Acc: 0.7057 batch_loss: 0.0461 correct: 251 batch_accuracy: 0.9805\n",
      "train Loss: 0.0013 Acc: 0.7145 batch_loss: 0.3533 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0013 Acc: 0.7233 batch_loss: 0.4911 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0014 Acc: 0.7322 batch_loss: 1.2464 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0014 Acc: 0.7409 batch_loss: 0.7359 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0014 Acc: 0.7496 batch_loss: 0.6830 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0014 Acc: 0.7585 batch_loss: 0.0898 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0014 Acc: 0.7675 batch_loss: 0.2719 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0015 Acc: 0.7762 batch_loss: 0.6705 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0015 Acc: 0.7850 batch_loss: 0.2428 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0015 Acc: 0.7938 batch_loss: 0.2257 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0015 Acc: 0.8026 batch_loss: 0.3272 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0015 Acc: 0.8114 batch_loss: 0.8945 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0016 Acc: 0.8201 batch_loss: 0.9507 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0016 Acc: 0.8289 batch_loss: 0.7993 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0016 Acc: 0.8376 batch_loss: 0.4761 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0016 Acc: 0.8464 batch_loss: 0.4677 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0016 Acc: 0.8553 batch_loss: 0.0986 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0017 Acc: 0.8642 batch_loss: 0.6716 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0017 Acc: 0.8729 batch_loss: 0.5453 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0017 Acc: 0.8818 batch_loss: 0.4462 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0018 Acc: 0.8905 batch_loss: 1.6749 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0018 Acc: 0.8993 batch_loss: 0.4499 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0018 Acc: 0.9082 batch_loss: 0.1258 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0018 Acc: 0.9169 batch_loss: 0.5161 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0018 Acc: 0.9257 batch_loss: 0.1693 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0018 Acc: 0.9343 batch_loss: 0.9319 correct: 239 batch_accuracy: 0.9336\n",
      "train Loss: 0.0019 Acc: 0.9431 batch_loss: 0.5225 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0019 Acc: 0.9518 batch_loss: 0.4854 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0019 Acc: 0.9605 batch_loss: 0.4863 correct: 243 batch_accuracy: 0.9492\n",
      "Accuracy of the network on the test images: 81.04167 %\n",
      "Accuracy of   pos : 80 %\n",
      "Accuracy of   neg : 85 %\n",
      "Accuracy of pos_o : 75 %\n",
      "Accuracy of   nuc : 67 %\n",
      "Accuracy of   non : 96 %\n",
      "class total:  [773.0, 772.0, 764.0, 757.0, 774.0]\n",
      "class correct:  [621.0, 661.0, 573.0, 510.0, 747.0]\n",
      "total:  3840\n",
      "correct:  3112\n",
      "trainloader ready!\n",
      "testloader ready!\n",
      "Epoch 8/9\n",
      "----------\n",
      "train Loss: 0.0000 Acc: 0.0091 batch_loss: 0.0428 correct: 253 batch_accuracy: 0.9883\n",
      "train Loss: 0.0000 Acc: 0.0180 batch_loss: 0.0981 correct: 250 batch_accuracy: 0.9766\n",
      "train Loss: 0.0000 Acc: 0.0268 batch_loss: 0.1635 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0000 Acc: 0.0356 batch_loss: 0.3869 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0000 Acc: 0.0445 batch_loss: 0.3495 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0001 Acc: 0.0531 batch_loss: 1.2859 correct: 240 batch_accuracy: 0.9375\n",
      "train Loss: 0.0001 Acc: 0.0618 batch_loss: 0.7184 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0001 Acc: 0.0704 batch_loss: 0.5910 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0002 Acc: 0.0792 batch_loss: 0.7929 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0002 Acc: 0.0880 batch_loss: 0.2950 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0002 Acc: 0.0970 batch_loss: 0.0825 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0002 Acc: 0.1057 batch_loss: 0.6436 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0002 Acc: 0.1144 batch_loss: 0.6207 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0002 Acc: 0.1231 batch_loss: 0.8305 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0003 Acc: 0.1319 batch_loss: 0.8682 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0003 Acc: 0.1407 batch_loss: 0.4324 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0003 Acc: 0.1497 batch_loss: 0.5094 correct: 252 batch_accuracy: 0.9844\n",
      "train Loss: 0.0003 Acc: 0.1583 batch_loss: 0.9675 correct: 240 batch_accuracy: 0.9375\n",
      "train Loss: 0.0004 Acc: 0.1671 batch_loss: 0.1631 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0004 Acc: 0.1758 batch_loss: 0.5417 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0004 Acc: 0.1848 batch_loss: 0.0741 correct: 250 batch_accuracy: 0.9766\n",
      "train Loss: 0.0004 Acc: 0.1936 batch_loss: 0.1868 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0004 Acc: 0.2024 batch_loss: 0.0883 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0004 Acc: 0.2111 batch_loss: 0.3627 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0004 Acc: 0.2201 batch_loss: 0.1156 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0004 Acc: 0.2288 batch_loss: 0.5179 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0004 Acc: 0.2376 batch_loss: 0.6194 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0005 Acc: 0.2465 batch_loss: 0.2648 correct: 250 batch_accuracy: 0.9766\n",
      "train Loss: 0.0005 Acc: 0.2552 batch_loss: 0.4145 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0005 Acc: 0.2639 batch_loss: 0.2639 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0005 Acc: 0.2728 batch_loss: 0.7244 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0005 Acc: 0.2817 batch_loss: 0.6305 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0005 Acc: 0.2904 batch_loss: 0.4776 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0006 Acc: 0.2993 batch_loss: 0.2479 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0006 Acc: 0.3082 batch_loss: 0.2302 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0006 Acc: 0.3170 batch_loss: 0.2465 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0006 Acc: 0.3258 batch_loss: 1.0169 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0006 Acc: 0.3348 batch_loss: 0.1163 correct: 250 batch_accuracy: 0.9766\n",
      "train Loss: 0.0006 Acc: 0.3438 batch_loss: 0.1029 correct: 251 batch_accuracy: 0.9805\n",
      "train Loss: 0.0006 Acc: 0.3525 batch_loss: 0.3849 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0006 Acc: 0.3612 batch_loss: 0.2592 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0007 Acc: 0.3699 batch_loss: 1.0303 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0007 Acc: 0.3788 batch_loss: 0.3262 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0007 Acc: 0.3878 batch_loss: 0.1229 correct: 250 batch_accuracy: 0.9766\n",
      "train Loss: 0.0007 Acc: 0.3965 batch_loss: 0.4521 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0007 Acc: 0.4054 batch_loss: 0.2157 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0007 Acc: 0.4140 batch_loss: 0.7468 correct: 240 batch_accuracy: 0.9375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0007 Acc: 0.4229 batch_loss: 0.1118 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0008 Acc: 0.4317 batch_loss: 0.9198 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0008 Acc: 0.4405 batch_loss: 0.3185 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0008 Acc: 0.4493 batch_loss: 0.2257 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0008 Acc: 0.4581 batch_loss: 0.2453 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0008 Acc: 0.4670 batch_loss: 0.4523 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0009 Acc: 0.4758 batch_loss: 1.0300 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0009 Acc: 0.4847 batch_loss: 0.4743 correct: 250 batch_accuracy: 0.9766\n",
      "train Loss: 0.0009 Acc: 0.4937 batch_loss: 0.0810 correct: 251 batch_accuracy: 0.9805\n",
      "train Loss: 0.0009 Acc: 0.5026 batch_loss: 0.0960 correct: 250 batch_accuracy: 0.9766\n",
      "train Loss: 0.0009 Acc: 0.5116 batch_loss: 0.2739 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0009 Acc: 0.5204 batch_loss: 0.3334 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0009 Acc: 0.5293 batch_loss: 0.4986 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0009 Acc: 0.5383 batch_loss: 0.2490 correct: 250 batch_accuracy: 0.9766\n",
      "train Loss: 0.0010 Acc: 0.5468 batch_loss: 0.7826 correct: 239 batch_accuracy: 0.9336\n",
      "train Loss: 0.0010 Acc: 0.5557 batch_loss: 0.2256 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0010 Acc: 0.5646 batch_loss: 0.3531 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0010 Acc: 0.5733 batch_loss: 0.5686 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0010 Acc: 0.5821 batch_loss: 0.3649 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0010 Acc: 0.5909 batch_loss: 0.2661 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0010 Acc: 0.5999 batch_loss: 0.3399 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0010 Acc: 0.6087 batch_loss: 0.0792 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0010 Acc: 0.6175 batch_loss: 0.2569 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0011 Acc: 0.6264 batch_loss: 0.7517 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0011 Acc: 0.6352 batch_loss: 0.9470 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0011 Acc: 0.6438 batch_loss: 0.6966 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0011 Acc: 0.6526 batch_loss: 0.1479 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0012 Acc: 0.6614 batch_loss: 0.6351 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0012 Acc: 0.6702 batch_loss: 0.7634 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0012 Acc: 0.6791 batch_loss: 0.7226 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0012 Acc: 0.6879 batch_loss: 0.9029 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0012 Acc: 0.6969 batch_loss: 0.1657 correct: 250 batch_accuracy: 0.9766\n",
      "train Loss: 0.0013 Acc: 0.7057 batch_loss: 0.7559 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0013 Acc: 0.7146 batch_loss: 0.1439 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0013 Acc: 0.7233 batch_loss: 0.8040 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0013 Acc: 0.7322 batch_loss: 0.2044 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0013 Acc: 0.7410 batch_loss: 0.5814 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0013 Acc: 0.7501 batch_loss: 0.1934 correct: 252 batch_accuracy: 0.9844\n",
      "train Loss: 0.0014 Acc: 0.7589 batch_loss: 0.3893 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0014 Acc: 0.7676 batch_loss: 0.4472 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0014 Acc: 0.7764 batch_loss: 0.0486 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0014 Acc: 0.7851 batch_loss: 0.2069 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0014 Acc: 0.7940 batch_loss: 0.7752 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0014 Acc: 0.8028 batch_loss: 1.0120 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0015 Acc: 0.8116 batch_loss: 1.2791 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0015 Acc: 0.8203 batch_loss: 0.5549 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0015 Acc: 0.8289 batch_loss: 0.5308 correct: 240 batch_accuracy: 0.9375\n",
      "train Loss: 0.0015 Acc: 0.8377 batch_loss: 0.1765 correct: 248 batch_accuracy: 0.9688\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-f48f1c95f180>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;31m# statistics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0miter_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0mcorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0mbatch_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorrect\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "since = time.time()\n",
    "best_model_wts = net.state_dict()\n",
    "best_acc = 0.0\n",
    "for epoch in range(num_epochs):\n",
    "    trainset = defectDataset_df(df = split_and_sample(method = 'yolo',n_samples = 1995, non_pos_ratio=non_pos_ratio), window_size = window_size,\n",
    "                                             transforms=train_transform)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset,\n",
    "                                                 batch_size=batch_size, shuffle=True,\n",
    "                                                 num_workers=8, drop_last=True)\n",
    "    print(\"trainloader ready!\")\n",
    "\n",
    "    testset = defectDataset_df(df = split_and_sample(df_labels = pd.read_csv('/home/rliu/yolo2/v2_pytorch_yolo2/data/an_data/VOCdevkit/VOC2007/csv_labels/test.csv', sep=\" \"),\n",
    "                                            method = 'yolo',n_samples = 800), window_size = window_size, transforms=test_transform)\n",
    "    testloader = torch.utils.data.DataLoader(testset,\n",
    "                                                 batch_size=batch_size, shuffle=True,\n",
    "                                                 num_workers=8)\n",
    "    print(\"testloader ready!\")\n",
    "    print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "    print('-' * 10)\n",
    "    scheduler.step()\n",
    "    model_uniform.train(False)\n",
    "    model_hard.train(False)\n",
    "    net.train(True)\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    for data in trainloader:\n",
    "        \n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs_uniform = model_uniform(inputs)\n",
    "            outputs_hard = model_hard(inputs)\n",
    "        outputs_in = torch.cat((outputs_uniform, outputs_hard), dim=1)\n",
    "        outputs_out = net(outputs_in)\n",
    "        _, preds = torch.max(outputs_out.data, 1)\n",
    "        loss = criterion(outputs_out, labels)\n",
    "\n",
    "        optimizer.zero_grad()                             # Intialize the hidden weight to all zeros\n",
    "        loss.backward()                                   # Backward pass: compute the weight\n",
    "        optimizer.step()                                  # Optimizer: update the weights of hidden nodes\n",
    "\n",
    "#         if (i+1) % 100 == 0:                              # Logging\n",
    "#             print('Epoch [%d/%d], Step [%d/%d], Loss: %.4f'\n",
    "#                  %(epoch+1, num_epochs, i+1, len(train_dataset)//batch_size, loss.item()))\n",
    "\n",
    "        \n",
    "        # statistics\n",
    "        iter_loss = loss.item()\n",
    "        correct = torch.sum(preds == labels.data).item()\n",
    "        batch_accuracy = correct / batch_size\n",
    "        running_loss += loss.item()\n",
    "        running_corrects_tensor = torch.sum(preds == labels.data)\n",
    "        running_corrects += running_corrects_tensor.item()        \n",
    "        epoch_loss = running_loss / len(trainset)\n",
    "        epoch_acc = running_corrects / len(trainset)\n",
    "\n",
    "        print('{} Loss: {:.4f} Acc: {:.4f} batch_loss: {:.4f} correct: {:d} batch_accuracy: {:.4f}'.format(\n",
    "            \"train\", epoch_loss, epoch_acc, iter_loss, correct, batch_accuracy))\n",
    "        \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    class_correct = list(0. for i in range(5))\n",
    "    class_total = list(0. for i in range(5))    \n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs_uniform = model_uniform(inputs)\n",
    "            outputs_hard = model_hard(inputs)\n",
    "            outputs_in = torch.cat((outputs_uniform, outputs_hard), dim=1)\n",
    "            outputs_out = net(outputs_in)\n",
    "            _, predicted = torch.max(outputs_out.data, 1)\n",
    "            c = (predicted == labels).squeeze()\n",
    "            for i in range(batch_size):\n",
    "                if len(labels) == batch_size:\n",
    "                    label = labels[i]\n",
    "                    class_correct[label] += c[i].item()\n",
    "                    class_total[label] += 1\n",
    "                    correct += c[i].item()\n",
    "                    total += 1\n",
    "#             if len(labels) == batch_size:\n",
    "#                 total += labels.size(0)\n",
    "#                 correct += (predicted == labels).sum().item()\n",
    "    #         print(predicted)\n",
    "    #         print(labels)\n",
    "    #       print('processed: %d' % total)\n",
    "    #       print('correct: %d' % correct)\n",
    "        print('Accuracy of the network on the test images: %.5f %%' % (100 * correct / total))\n",
    "        for i in range(5):\n",
    "            print('Accuracy of %5s : %2d %%' % (classes[i], 100 * class_correct[i] / class_total[i]))\n",
    "        print('class total: ',class_total)\n",
    "        print('class correct: ',class_correct)\n",
    "        print('total: ', total)\n",
    "        print('correct: ', correct)\n",
    "time_elapsed = time.time() - since\n",
    "print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "    time_elapsed // 60, time_elapsed % 60))\n",
    "print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "# load best model weights\n",
    "net.load_state_dict(best_model_wts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 1, 200, 200])\n",
      "torch.Size([256, 5])\n",
      "torch.Size([256, 10])\n",
      "torch.Size([256, 5])\n"
     ]
    }
   ],
   "source": [
    "print(inputs.shape)\n",
    "print(outputs_uniform.shape)\n",
    "print(outputs_in.shape)\n",
    "print(outputs_out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU in use\n"
     ]
    }
   ],
   "source": [
    "use_gpu = torch.cuda.is_available()\n",
    "\n",
    "if use_gpu:\n",
    "    print(\"GPU in use\")\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "classes = [\"pos\",\"neg\",\"pos_o\",\"nuc\",\"non\"]\n",
    "num_of_classes = len(classes)\n",
    "\n",
    "model_uniform = torch.load('/home/rliu/defect_classifier/models/python/res34_600epo_uniform_01-07-18.model')\n",
    "model_uniform.eval()\n",
    "model_hard = torch.load('/home/rliu/defect_classifier/models/python/res34_600epo_hard_01-07-18.model')\n",
    "model_hard.eval()\n",
    "if use_gpu:\n",
    "#     model_uniform = torch.nn.DataParallel(model_uniform)\n",
    "    model_uniform.to(device)\n",
    "#     model_hard = torch.nn.DataParallel(model_hard)\n",
    "    model_hard.to(device)\n",
    "    \n",
    "    \n",
    "batch_size = 5\n",
    "trainset = defectDataset_df(df = split_and_sample(method = 'yolo',n_samples = 1995, non_pos_ratio = non_pos_ratio), window_size = window_size, transforms=data_transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset,\n",
    "                                     batch_size=batch_size, shuffle=True,\n",
    "                                     num_workers=4, drop_last=True)\n",
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# print images\n",
    "images, labels = images.to(device), labels.to(device)\n",
    "outputs_uniform = model_uniform(images)\n",
    "outputs_hard = model_hard(images)\n",
    "outputs = torch.cat((outputs_uniform, outputs_hard), dim=1)\n",
    "_, preds = torch.max(outputs.data, 1)\n",
    "loss = criterion(outputs, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-12.3108,   3.8134, -12.1610,  -8.9865, -18.6308],\n",
      "        [  4.1426, -12.6464, -16.8836, -13.2110, -13.5861],\n",
      "        [ -9.9046, -12.1545,  -9.0868,   2.3950, -12.2668],\n",
      "        [ -5.9917,   3.7852,  -9.3418, -10.6862, -11.3693],\n",
      "        [  4.1033,  -7.9563,  -6.8923, -13.0635,  -7.5087]], device='cuda:0',\n",
      "       grad_fn=<GatherBackward>)\n",
      "tensor([[-10.9020,   2.6503, -13.7712, -12.7975, -13.3193],\n",
      "        [  3.1850, -11.8032, -13.6199, -11.8008, -12.5677],\n",
      "        [-13.4012, -12.1915, -14.3676,   1.9575, -15.2399],\n",
      "        [ -7.2337,   2.6256, -18.3268, -10.4256,  -9.0024],\n",
      "        [  3.2153, -10.9220, -13.6908, -12.3731, -11.7074]], device='cuda:0',\n",
      "       grad_fn=<GatherBackward>)\n",
      "tensor(0.3425, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(outputs_uniform)\n",
    "print(outputs_hard)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 0, 0, 3, 1])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.MNIST(root='./data',\n",
    "                           train=True,\n",
    "                           transform=transforms.ToTensor(),\n",
    "                           download=True)\n",
    "\n",
    "test_dataset = datasets.MNIST(root='./data',\n",
    "                           train=False,\n",
    "                           transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(Net, self).__init__()                    # Inherited from the parent class nn.Module\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)  # 1st Full-Connected Layer: 784 (input data) -> 500 (hidden node)\n",
    "        self.relu = nn.ReLU()                          # Non-Linear ReLU Layer: max(0,x)\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes) # 2nd Full-Connected Layer: 500 (hidden node) -> 10 (output class)\n",
    "    \n",
    "    def forward(self, x):                              # Forward pass: stacking each layer together\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net(input_size, hidden_size, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (fc1): Linear(in_features=784, out_features=500, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (fc2): Linear(in_features=500, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [100/600], Loss: 0.2542\n",
      "Epoch [1/5], Step [200/600], Loss: 0.1384\n",
      "Epoch [1/5], Step [300/600], Loss: 0.1731\n",
      "Epoch [1/5], Step [400/600], Loss: 0.1142\n",
      "Epoch [1/5], Step [500/600], Loss: 0.0950\n",
      "Epoch [1/5], Step [600/600], Loss: 0.1930\n",
      "Epoch [2/5], Step [100/600], Loss: 0.1513\n",
      "Epoch [2/5], Step [200/600], Loss: 0.1833\n",
      "Epoch [2/5], Step [300/600], Loss: 0.1233\n",
      "Epoch [2/5], Step [400/600], Loss: 0.1183\n",
      "Epoch [2/5], Step [500/600], Loss: 0.0871\n",
      "Epoch [2/5], Step [600/600], Loss: 0.0677\n",
      "Epoch [3/5], Step [100/600], Loss: 0.0196\n",
      "Epoch [3/5], Step [200/600], Loss: 0.0825\n",
      "Epoch [3/5], Step [300/600], Loss: 0.0880\n",
      "Epoch [3/5], Step [400/600], Loss: 0.0757\n",
      "Epoch [3/5], Step [500/600], Loss: 0.0220\n",
      "Epoch [3/5], Step [600/600], Loss: 0.0282\n",
      "Epoch [4/5], Step [100/600], Loss: 0.0166\n",
      "Epoch [4/5], Step [200/600], Loss: 0.0539\n",
      "Epoch [4/5], Step [300/600], Loss: 0.0231\n",
      "Epoch [4/5], Step [400/600], Loss: 0.0305\n",
      "Epoch [4/5], Step [500/600], Loss: 0.0996\n",
      "Epoch [4/5], Step [600/600], Loss: 0.0352\n",
      "Epoch [5/5], Step [100/600], Loss: 0.0392\n",
      "Epoch [5/5], Step [200/600], Loss: 0.0510\n",
      "Epoch [5/5], Step [300/600], Loss: 0.0487\n",
      "Epoch [5/5], Step [400/600], Loss: 0.0199\n",
      "Epoch [5/5], Step [500/600], Loss: 0.0501\n",
      "Epoch [5/5], Step [600/600], Loss: 0.0229\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):   # Load a batch of images with its (index, data, class)\n",
    "        images = Variable(images.view(-1, 28*28))         # Convert torch tensor to Variable: change image from a vector of size 784 to a matrix of 28 x 28\n",
    "        labels = Variable(labels)\n",
    "        \n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()                             # Intialize the hidden weight to all zeros\n",
    "        outputs = net(images)                             # Forward pass: compute the output class given a image\n",
    "        loss = criterion(outputs, labels)                 # Compute the loss: difference between the output class and the pre-given label\n",
    "        loss.backward()                                   # Backward pass: compute the weight\n",
    "        optimizer.step()                                  # Optimizer: update the weights of hidden nodes\n",
    "        \n",
    "        if (i+1) % 100 == 0:                              # Logging\n",
    "            print('Epoch [%d/%d], Step [%d/%d], Loss: %.4f'\n",
    "                 %(epoch+1, num_epochs, i+1, len(train_dataset)//batch_size, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22127796709537506"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    use_gpu = torch.cuda.is_available()\n",
    "\n",
    "    if use_gpu:\n",
    "        print(\"GPU in use\")\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    classes = [\"pos\",\"neg\",\"pos_o\",\"nuc\",\"non\"]\n",
    "    num_of_classes = len(classes)\n",
    "\n",
    "    model_uniform = torch.load('/home/rliu/defect_classifier/models/python/res34_600epo_uniform_01-07-18.model')\n",
    "    model_uniform.eval()\n",
    "    model_hard = torch.load('/home/rliu/defect_classifier/models/python/res34_600epo_uniform_01-07-18.model')\n",
    "    model_hard.eval()\n",
    "    if use_gpu:\n",
    "        model_uniform = torch.nn.DataParallel(uniform)\n",
    "        model_uniform.to(device)\n",
    "        model_uniform = torch.nn.DataParallel(uniform)\n",
    "        model_uniform.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10K test images: 97 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "for images, labels in test_loader:\n",
    "    images = Variable(images.view(-1, 28*28))\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    outputs = net(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)  # Choose the best class from the output: The class with the best score\n",
    "    total += labels.size(0)                    # Increment the total count\n",
    "    correct += (predicted == labels).sum()     # Increment the correct count\n",
    "    \n",
    "print('Accuracy of the network on the 10K test images: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
