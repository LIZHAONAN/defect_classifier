{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from PIL import ImageOps\n",
    "import PIL\n",
    "import torch, torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset import defectDataset_df, create_circular_mask, split_and_sample\n",
    "import random\n",
    "import math\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, models, transforms\n",
    "import time\n",
    "import os\n",
    "from grayscale_resnet import resnet18\n",
    "from torchvision.models.resnet import BasicBlock, conv3x3, Bottleneck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_size = 80\n",
    "pad_size = window_size\n",
    "classes = [\"pos\",\"neg\",\"pos_o\",\"nuc\",\"non\"]\n",
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transform = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(200, scale=(1, 1), ratio=(1, 1)),\n",
    "        transforms.RandomRotation((-90,90)),\n",
    "        torchvision.transforms.RandomVerticalFlip(p=0.5),\n",
    "        torchvision.transforms.RandomHorizontalFlip(p=0.5),\n",
    "        torchvision.transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0, hue=0),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.3019],\n",
    "                             std=[0.1909])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainloader ready!\n",
      "testloader ready!\n"
     ]
    }
   ],
   "source": [
    "trainset = defectDataset_df(df = split_and_sample(method = 'hard',n_samples = 1995), window_size = window_size, transforms=data_transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset,\n",
    "                                             batch_size=batch_size, shuffle=True,\n",
    "                                             num_workers=4)\n",
    "print(\"trainloader ready!\")\n",
    "\n",
    "testset = defectDataset_df(df = split_and_sample(df_train = pd.read_csv('/home/rliu/yolo2/v2_pytorch_yolo2/data/an_data/VOCdevkit/VOC2007/csv_labels/test.csv', sep=\" \"),\n",
    "                                                      method = 'hard',n_samples = 500), window_size = window_size, transforms=data_transform)\n",
    "testloader = torch.utils.data.DataLoader(testset,\n",
    "                                             batch_size=batch_size, shuffle=True,\n",
    "                                             num_workers=4)\n",
    "print(\"testloader ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU in use\n"
     ]
    }
   ],
   "source": [
    "use_gpu = torch.cuda.is_available()\n",
    "if use_gpu:\n",
    "    print(\"GPU in use\")\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "classes = [\"pos\",\"neg\",\"pos_o\",\"nuc\",\"non\"]\n",
    "num_of_classes = len(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    img = img * 0.1909 + 0.3019     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GroundTruth:    pos   neg   neg   nuc   pos   non   non   pos\n",
      "tensor([0, 1, 1, 3, 0, 4, 4, 0])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "classes = [\"pos\",\"neg\",\"pos_o\",\"nuc\",\"non\"]\n",
    "print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(8)))\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = model.state_dict()\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training phase\n",
    "        scheduler.step()\n",
    "        model.train(True)  # Set model to training mode\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "\n",
    "        # Iterate over data.\n",
    "        for data in trainloader:\n",
    "            # get the inputs\n",
    "            inputs, labels = data\n",
    "#            print(inputs)\n",
    "            # wrap them in Variable\n",
    "            if use_gpu:\n",
    "#                inputs = Variable(inputs.cuda())\n",
    "#                labels = Variable(labels.cuda())\n",
    "#                inputs = torch.nn.DataParallel(inputs, device_ids=[0, 1]).cuda()\n",
    "#                labels = torch.nn.DataParallel(labels, device_ids=[0, 1]).cuda()\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "#                print(inputs)\n",
    "            else:\n",
    "                inputs, labels = Variable(inputs), Variable(labels)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "\n",
    "            m = nn.LogSoftmax(dim=0)\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "            loss = criterion(m(outputs), labels)\n",
    "            # forward\n",
    "#            outputs = model(inputs)\n",
    "#            _, preds = torch.max(outputs.data, 1)\n",
    "#            loss = criterion(outputs, labels)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # statistics\n",
    "            iter_loss = loss.item()\n",
    "            correct = torch.sum(preds == labels.data).item()\n",
    "            batch_accuracy = correct / batch_size\n",
    "            running_loss += loss.item()\n",
    "            running_corrects_tensor = torch.sum(preds == labels.data)\n",
    "            running_corrects += running_corrects_tensor.item()        \n",
    "            epoch_loss = running_loss / len(trainset)\n",
    "            epoch_acc = running_corrects / len(trainset)\n",
    "            \n",
    "            print('{} Loss: {:.4f} Acc: {:.4f} batch_loss: {:.4f} correct: {:d} batch_accuracy: {:.4f}'.format(\n",
    "                \"train\", epoch_loss, epoch_acc, iter_loss, correct, batch_accuracy))\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for data in testloader:\n",
    "                images, labels = data\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "#                print('processed: %d' % total)\n",
    "#                print('correct: %d' % correct)\n",
    "        print('Accuracy of the network on the test images: %.5f %%' % (\n",
    "            100 * correct / total))\n",
    "        \n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/4\n",
      "----------\n",
      "train Loss: 0.0005 Acc: 0.0027 batch_loss: 4.8634 correct: 27 batch_accuracy: 0.2109\n",
      "train Loss: 0.0010 Acc: 0.0050 batch_loss: 4.8852 correct: 23 batch_accuracy: 0.1797\n",
      "train Loss: 0.0015 Acc: 0.0079 batch_loss: 4.8780 correct: 29 batch_accuracy: 0.2266\n",
      "train Loss: 0.0020 Acc: 0.0100 batch_loss: 4.8742 correct: 21 batch_accuracy: 0.1641\n",
      "train Loss: 0.0024 Acc: 0.0124 batch_loss: 4.8604 correct: 24 batch_accuracy: 0.1875\n",
      "train Loss: 0.0029 Acc: 0.0150 batch_loss: 4.8617 correct: 26 batch_accuracy: 0.2031\n",
      "train Loss: 0.0034 Acc: 0.0171 batch_loss: 4.8577 correct: 21 batch_accuracy: 0.1641\n",
      "train Loss: 0.0039 Acc: 0.0206 batch_loss: 4.8479 correct: 34 batch_accuracy: 0.2656\n",
      "train Loss: 0.0044 Acc: 0.0231 batch_loss: 4.8426 correct: 25 batch_accuracy: 0.1953\n",
      "train Loss: 0.0049 Acc: 0.0258 batch_loss: 4.8424 correct: 27 batch_accuracy: 0.2109\n",
      "train Loss: 0.0054 Acc: 0.0280 batch_loss: 4.8379 correct: 22 batch_accuracy: 0.1719\n",
      "train Loss: 0.0058 Acc: 0.0302 batch_loss: 4.8421 correct: 22 batch_accuracy: 0.1719\n",
      "train Loss: 0.0063 Acc: 0.0329 batch_loss: 4.8225 correct: 27 batch_accuracy: 0.2109\n",
      "train Loss: 0.0068 Acc: 0.0347 batch_loss: 4.8146 correct: 18 batch_accuracy: 0.1406\n",
      "train Loss: 0.0073 Acc: 0.0372 batch_loss: 4.8112 correct: 25 batch_accuracy: 0.1953\n",
      "train Loss: 0.0078 Acc: 0.0407 batch_loss: 4.8127 correct: 35 batch_accuracy: 0.2734\n",
      "train Loss: 0.0083 Acc: 0.0429 batch_loss: 4.8042 correct: 22 batch_accuracy: 0.1719\n",
      "train Loss: 0.0087 Acc: 0.0453 batch_loss: 4.8259 correct: 24 batch_accuracy: 0.1875\n",
      "train Loss: 0.0092 Acc: 0.0474 batch_loss: 4.8047 correct: 21 batch_accuracy: 0.1641\n",
      "train Loss: 0.0097 Acc: 0.0498 batch_loss: 4.8104 correct: 24 batch_accuracy: 0.1875\n",
      "train Loss: 0.0102 Acc: 0.0526 batch_loss: 4.8162 correct: 28 batch_accuracy: 0.2188\n",
      "train Loss: 0.0107 Acc: 0.0550 batch_loss: 4.7935 correct: 24 batch_accuracy: 0.1875\n",
      "train Loss: 0.0111 Acc: 0.0574 batch_loss: 4.8003 correct: 24 batch_accuracy: 0.1875\n",
      "train Loss: 0.0116 Acc: 0.0604 batch_loss: 4.8219 correct: 29 batch_accuracy: 0.2266\n",
      "train Loss: 0.0121 Acc: 0.0632 batch_loss: 4.8040 correct: 28 batch_accuracy: 0.2188\n",
      "train Loss: 0.0126 Acc: 0.0659 batch_loss: 4.8046 correct: 27 batch_accuracy: 0.2109\n",
      "train Loss: 0.0131 Acc: 0.0684 batch_loss: 4.8197 correct: 25 batch_accuracy: 0.1953\n",
      "train Loss: 0.0136 Acc: 0.0713 batch_loss: 4.8162 correct: 29 batch_accuracy: 0.2266\n",
      "train Loss: 0.0140 Acc: 0.0738 batch_loss: 4.8097 correct: 25 batch_accuracy: 0.1953\n",
      "train Loss: 0.0145 Acc: 0.0759 batch_loss: 4.7745 correct: 21 batch_accuracy: 0.1641\n",
      "train Loss: 0.0150 Acc: 0.0787 batch_loss: 4.7855 correct: 28 batch_accuracy: 0.2188\n",
      "train Loss: 0.0155 Acc: 0.0813 batch_loss: 4.7839 correct: 26 batch_accuracy: 0.2031\n",
      "train Loss: 0.0160 Acc: 0.0831 batch_loss: 4.7541 correct: 18 batch_accuracy: 0.1406\n",
      "train Loss: 0.0164 Acc: 0.0857 batch_loss: 4.7726 correct: 26 batch_accuracy: 0.2031\n",
      "train Loss: 0.0169 Acc: 0.0881 batch_loss: 4.7540 correct: 24 batch_accuracy: 0.1875\n",
      "train Loss: 0.0174 Acc: 0.0909 batch_loss: 4.7904 correct: 28 batch_accuracy: 0.2188\n",
      "train Loss: 0.0179 Acc: 0.0938 batch_loss: 4.7791 correct: 29 batch_accuracy: 0.2266\n",
      "train Loss: 0.0184 Acc: 0.0962 batch_loss: 4.8303 correct: 24 batch_accuracy: 0.1875\n",
      "train Loss: 0.0188 Acc: 0.0981 batch_loss: 4.7387 correct: 19 batch_accuracy: 0.1484\n",
      "train Loss: 0.0193 Acc: 0.1008 batch_loss: 4.7779 correct: 26 batch_accuracy: 0.2031\n",
      "train Loss: 0.0198 Acc: 0.1035 batch_loss: 4.7748 correct: 27 batch_accuracy: 0.2109\n",
      "train Loss: 0.0203 Acc: 0.1062 batch_loss: 4.7583 correct: 27 batch_accuracy: 0.2109\n",
      "train Loss: 0.0207 Acc: 0.1088 batch_loss: 4.7512 correct: 26 batch_accuracy: 0.2031\n",
      "train Loss: 0.0212 Acc: 0.1111 batch_loss: 4.7310 correct: 23 batch_accuracy: 0.1797\n",
      "train Loss: 0.0217 Acc: 0.1151 batch_loss: 4.7408 correct: 40 batch_accuracy: 0.3125\n",
      "train Loss: 0.0222 Acc: 0.1172 batch_loss: 4.7247 correct: 21 batch_accuracy: 0.1641\n",
      "train Loss: 0.0226 Acc: 0.1201 batch_loss: 4.8023 correct: 29 batch_accuracy: 0.2266\n",
      "train Loss: 0.0231 Acc: 0.1233 batch_loss: 4.7733 correct: 32 batch_accuracy: 0.2500\n",
      "train Loss: 0.0236 Acc: 0.1265 batch_loss: 4.7367 correct: 32 batch_accuracy: 0.2500\n",
      "train Loss: 0.0241 Acc: 0.1288 batch_loss: 4.7048 correct: 23 batch_accuracy: 0.1797\n",
      "train Loss: 0.0245 Acc: 0.1312 batch_loss: 4.7552 correct: 24 batch_accuracy: 0.1875\n",
      "train Loss: 0.0250 Acc: 0.1343 batch_loss: 4.7250 correct: 31 batch_accuracy: 0.2422\n",
      "train Loss: 0.0255 Acc: 0.1364 batch_loss: 4.8030 correct: 21 batch_accuracy: 0.1641\n",
      "train Loss: 0.0260 Acc: 0.1395 batch_loss: 4.7295 correct: 31 batch_accuracy: 0.2422\n",
      "train Loss: 0.0265 Acc: 0.1420 batch_loss: 4.7127 correct: 24 batch_accuracy: 0.1875\n",
      "train Loss: 0.0269 Acc: 0.1440 batch_loss: 4.7285 correct: 20 batch_accuracy: 0.1562\n",
      "train Loss: 0.0274 Acc: 0.1480 batch_loss: 4.7289 correct: 40 batch_accuracy: 0.3125\n",
      "train Loss: 0.0279 Acc: 0.1506 batch_loss: 4.7048 correct: 26 batch_accuracy: 0.2031\n",
      "train Loss: 0.0283 Acc: 0.1536 batch_loss: 4.7108 correct: 30 batch_accuracy: 0.2344\n",
      "train Loss: 0.0288 Acc: 0.1564 batch_loss: 4.7508 correct: 28 batch_accuracy: 0.2188\n",
      "train Loss: 0.0293 Acc: 0.1600 batch_loss: 4.6995 correct: 36 batch_accuracy: 0.2812\n",
      "train Loss: 0.0298 Acc: 0.1634 batch_loss: 4.7005 correct: 34 batch_accuracy: 0.2656\n",
      "train Loss: 0.0302 Acc: 0.1672 batch_loss: 4.7155 correct: 38 batch_accuracy: 0.2969\n",
      "train Loss: 0.0307 Acc: 0.1708 batch_loss: 4.7211 correct: 36 batch_accuracy: 0.2812\n",
      "train Loss: 0.0312 Acc: 0.1743 batch_loss: 4.6808 correct: 35 batch_accuracy: 0.2734\n",
      "train Loss: 0.0316 Acc: 0.1780 batch_loss: 4.6722 correct: 37 batch_accuracy: 0.2891\n",
      "train Loss: 0.0321 Acc: 0.1815 batch_loss: 4.6767 correct: 34 batch_accuracy: 0.2656\n",
      "train Loss: 0.0326 Acc: 0.1849 batch_loss: 4.7582 correct: 34 batch_accuracy: 0.2656\n",
      "train Loss: 0.0331 Acc: 0.1874 batch_loss: 4.7122 correct: 25 batch_accuracy: 0.1953\n",
      "train Loss: 0.0335 Acc: 0.1907 batch_loss: 4.7254 correct: 33 batch_accuracy: 0.2578\n",
      "train Loss: 0.0340 Acc: 0.1949 batch_loss: 4.6491 correct: 42 batch_accuracy: 0.3281\n",
      "train Loss: 0.0345 Acc: 0.1983 batch_loss: 4.6873 correct: 34 batch_accuracy: 0.2656\n",
      "train Loss: 0.0349 Acc: 0.2018 batch_loss: 4.6669 correct: 35 batch_accuracy: 0.2734\n",
      "train Loss: 0.0354 Acc: 0.2058 batch_loss: 4.6949 correct: 40 batch_accuracy: 0.3125\n",
      "train Loss: 0.0359 Acc: 0.2095 batch_loss: 4.6817 correct: 37 batch_accuracy: 0.2891\n",
      "train Loss: 0.0364 Acc: 0.2123 batch_loss: 4.7036 correct: 28 batch_accuracy: 0.2188\n",
      "train Loss: 0.0368 Acc: 0.2158 batch_loss: 4.6403 correct: 35 batch_accuracy: 0.2734\n",
      "train Loss: 0.0373 Acc: 0.2201 batch_loss: 4.5910 correct: 42 batch_accuracy: 0.3281\n",
      "Accuracy of the network on the test images: 28.28000 %\n",
      "Epoch 1/4\n",
      "----------\n",
      "train Loss: 0.0005 Acc: 0.0052 batch_loss: 4.6682 correct: 52 batch_accuracy: 0.4062\n",
      "train Loss: 0.0009 Acc: 0.0091 batch_loss: 4.6487 correct: 39 batch_accuracy: 0.3047\n",
      "train Loss: 0.0014 Acc: 0.0122 batch_loss: 4.6389 correct: 31 batch_accuracy: 0.2422\n",
      "train Loss: 0.0019 Acc: 0.0158 batch_loss: 4.6856 correct: 36 batch_accuracy: 0.2812\n",
      "train Loss: 0.0023 Acc: 0.0196 batch_loss: 4.6385 correct: 38 batch_accuracy: 0.2969\n",
      "train Loss: 0.0028 Acc: 0.0238 batch_loss: 4.6617 correct: 41 batch_accuracy: 0.3203\n",
      "train Loss: 0.0033 Acc: 0.0267 batch_loss: 4.7068 correct: 29 batch_accuracy: 0.2266\n",
      "train Loss: 0.0037 Acc: 0.0311 batch_loss: 4.6567 correct: 44 batch_accuracy: 0.3438\n",
      "train Loss: 0.0042 Acc: 0.0340 batch_loss: 4.6357 correct: 29 batch_accuracy: 0.2266\n",
      "train Loss: 0.0047 Acc: 0.0380 batch_loss: 4.6282 correct: 40 batch_accuracy: 0.3125\n",
      "train Loss: 0.0051 Acc: 0.0424 batch_loss: 4.6311 correct: 44 batch_accuracy: 0.3438\n",
      "train Loss: 0.0056 Acc: 0.0465 batch_loss: 4.6969 correct: 41 batch_accuracy: 0.3203\n",
      "train Loss: 0.0061 Acc: 0.0501 batch_loss: 4.6343 correct: 36 batch_accuracy: 0.2812\n",
      "train Loss: 0.0065 Acc: 0.0546 batch_loss: 4.6321 correct: 45 batch_accuracy: 0.3516\n",
      "train Loss: 0.0070 Acc: 0.0585 batch_loss: 4.6812 correct: 39 batch_accuracy: 0.3047\n",
      "train Loss: 0.0075 Acc: 0.0621 batch_loss: 4.6593 correct: 35 batch_accuracy: 0.2734\n",
      "train Loss: 0.0079 Acc: 0.0671 batch_loss: 4.5927 correct: 50 batch_accuracy: 0.3906\n",
      "train Loss: 0.0084 Acc: 0.0710 batch_loss: 4.6333 correct: 39 batch_accuracy: 0.3047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0089 Acc: 0.0745 batch_loss: 4.6981 correct: 35 batch_accuracy: 0.2734\n",
      "train Loss: 0.0093 Acc: 0.0784 batch_loss: 4.6035 correct: 39 batch_accuracy: 0.3047\n",
      "train Loss: 0.0098 Acc: 0.0823 batch_loss: 4.6713 correct: 39 batch_accuracy: 0.3047\n",
      "train Loss: 0.0103 Acc: 0.0874 batch_loss: 4.6354 correct: 51 batch_accuracy: 0.3984\n",
      "train Loss: 0.0107 Acc: 0.0912 batch_loss: 4.6541 correct: 38 batch_accuracy: 0.2969\n",
      "train Loss: 0.0112 Acc: 0.0957 batch_loss: 4.5937 correct: 45 batch_accuracy: 0.3516\n",
      "train Loss: 0.0117 Acc: 0.1007 batch_loss: 4.6372 correct: 49 batch_accuracy: 0.3828\n",
      "train Loss: 0.0121 Acc: 0.1055 batch_loss: 4.6129 correct: 48 batch_accuracy: 0.3750\n",
      "train Loss: 0.0126 Acc: 0.1098 batch_loss: 4.6108 correct: 43 batch_accuracy: 0.3359\n",
      "train Loss: 0.0130 Acc: 0.1141 batch_loss: 4.6259 correct: 43 batch_accuracy: 0.3359\n",
      "train Loss: 0.0135 Acc: 0.1181 batch_loss: 4.6398 correct: 40 batch_accuracy: 0.3125\n",
      "train Loss: 0.0140 Acc: 0.1228 batch_loss: 4.6373 correct: 47 batch_accuracy: 0.3672\n",
      "train Loss: 0.0144 Acc: 0.1269 batch_loss: 4.6830 correct: 41 batch_accuracy: 0.3203\n",
      "train Loss: 0.0149 Acc: 0.1302 batch_loss: 4.6471 correct: 33 batch_accuracy: 0.2578\n",
      "train Loss: 0.0154 Acc: 0.1352 batch_loss: 4.6333 correct: 50 batch_accuracy: 0.3906\n",
      "train Loss: 0.0158 Acc: 0.1397 batch_loss: 4.6047 correct: 45 batch_accuracy: 0.3516\n",
      "train Loss: 0.0163 Acc: 0.1436 batch_loss: 4.6888 correct: 38 batch_accuracy: 0.2969\n",
      "train Loss: 0.0168 Acc: 0.1476 batch_loss: 4.6537 correct: 40 batch_accuracy: 0.3125\n",
      "train Loss: 0.0172 Acc: 0.1514 batch_loss: 4.6682 correct: 38 batch_accuracy: 0.2969\n",
      "train Loss: 0.0177 Acc: 0.1551 batch_loss: 4.6488 correct: 37 batch_accuracy: 0.2891\n",
      "train Loss: 0.0182 Acc: 0.1592 batch_loss: 4.6481 correct: 41 batch_accuracy: 0.3203\n",
      "train Loss: 0.0186 Acc: 0.1642 batch_loss: 4.5918 correct: 50 batch_accuracy: 0.3906\n",
      "train Loss: 0.0191 Acc: 0.1683 batch_loss: 4.6411 correct: 41 batch_accuracy: 0.3203\n",
      "train Loss: 0.0196 Acc: 0.1723 batch_loss: 4.6852 correct: 40 batch_accuracy: 0.3125\n",
      "train Loss: 0.0200 Acc: 0.1760 batch_loss: 4.6478 correct: 37 batch_accuracy: 0.2891\n",
      "train Loss: 0.0205 Acc: 0.1794 batch_loss: 4.6691 correct: 34 batch_accuracy: 0.2656\n",
      "train Loss: 0.0210 Acc: 0.1829 batch_loss: 4.6946 correct: 34 batch_accuracy: 0.2656\n",
      "train Loss: 0.0214 Acc: 0.1877 batch_loss: 4.6447 correct: 48 batch_accuracy: 0.3750\n",
      "train Loss: 0.0219 Acc: 0.1920 batch_loss: 4.6261 correct: 43 batch_accuracy: 0.3359\n",
      "train Loss: 0.0224 Acc: 0.1975 batch_loss: 4.6366 correct: 55 batch_accuracy: 0.4297\n",
      "train Loss: 0.0228 Acc: 0.2012 batch_loss: 4.6327 correct: 37 batch_accuracy: 0.2891\n",
      "train Loss: 0.0233 Acc: 0.2047 batch_loss: 4.6267 correct: 35 batch_accuracy: 0.2734\n",
      "train Loss: 0.0238 Acc: 0.2083 batch_loss: 4.6550 correct: 36 batch_accuracy: 0.2812\n",
      "train Loss: 0.0242 Acc: 0.2122 batch_loss: 4.6707 correct: 39 batch_accuracy: 0.3047\n",
      "train Loss: 0.0247 Acc: 0.2168 batch_loss: 4.5978 correct: 46 batch_accuracy: 0.3594\n",
      "train Loss: 0.0251 Acc: 0.2218 batch_loss: 4.6097 correct: 49 batch_accuracy: 0.3828\n",
      "train Loss: 0.0256 Acc: 0.2266 batch_loss: 4.6279 correct: 48 batch_accuracy: 0.3750\n",
      "train Loss: 0.0261 Acc: 0.2325 batch_loss: 4.6237 correct: 59 batch_accuracy: 0.4609\n",
      "train Loss: 0.0265 Acc: 0.2364 batch_loss: 4.6596 correct: 39 batch_accuracy: 0.3047\n",
      "train Loss: 0.0270 Acc: 0.2413 batch_loss: 4.6242 correct: 49 batch_accuracy: 0.3828\n",
      "train Loss: 0.0275 Acc: 0.2454 batch_loss: 4.6103 correct: 41 batch_accuracy: 0.3203\n",
      "train Loss: 0.0279 Acc: 0.2506 batch_loss: 4.5943 correct: 52 batch_accuracy: 0.4062\n",
      "train Loss: 0.0284 Acc: 0.2558 batch_loss: 4.6278 correct: 52 batch_accuracy: 0.4062\n",
      "train Loss: 0.0289 Acc: 0.2599 batch_loss: 4.6203 correct: 41 batch_accuracy: 0.3203\n",
      "train Loss: 0.0293 Acc: 0.2638 batch_loss: 4.6681 correct: 38 batch_accuracy: 0.2969\n",
      "train Loss: 0.0298 Acc: 0.2686 batch_loss: 4.6270 correct: 48 batch_accuracy: 0.3750\n",
      "train Loss: 0.0302 Acc: 0.2746 batch_loss: 4.5851 correct: 60 batch_accuracy: 0.4688\n",
      "train Loss: 0.0307 Acc: 0.2790 batch_loss: 4.6238 correct: 44 batch_accuracy: 0.3438\n",
      "train Loss: 0.0312 Acc: 0.2835 batch_loss: 4.6112 correct: 45 batch_accuracy: 0.3516\n",
      "train Loss: 0.0316 Acc: 0.2883 batch_loss: 4.6028 correct: 48 batch_accuracy: 0.3750\n",
      "train Loss: 0.0321 Acc: 0.2930 batch_loss: 4.6372 correct: 47 batch_accuracy: 0.3672\n",
      "train Loss: 0.0326 Acc: 0.2979 batch_loss: 4.6243 correct: 49 batch_accuracy: 0.3828\n",
      "train Loss: 0.0330 Acc: 0.3030 batch_loss: 4.6603 correct: 50 batch_accuracy: 0.3906\n",
      "train Loss: 0.0335 Acc: 0.3072 batch_loss: 4.6520 correct: 42 batch_accuracy: 0.3281\n",
      "train Loss: 0.0340 Acc: 0.3122 batch_loss: 4.6610 correct: 50 batch_accuracy: 0.3906\n",
      "train Loss: 0.0344 Acc: 0.3165 batch_loss: 4.5992 correct: 43 batch_accuracy: 0.3359\n",
      "train Loss: 0.0349 Acc: 0.3205 batch_loss: 4.6449 correct: 40 batch_accuracy: 0.3125\n",
      "train Loss: 0.0354 Acc: 0.3243 batch_loss: 4.6238 correct: 38 batch_accuracy: 0.2969\n",
      "train Loss: 0.0358 Acc: 0.3283 batch_loss: 4.6336 correct: 40 batch_accuracy: 0.3125\n",
      "train Loss: 0.0363 Acc: 0.3325 batch_loss: 4.5941 correct: 42 batch_accuracy: 0.3281\n",
      "Accuracy of the network on the test images: 34.00000 %\n",
      "Epoch 2/4\n",
      "----------\n",
      "train Loss: 0.0005 Acc: 0.0052 batch_loss: 4.5837 correct: 52 batch_accuracy: 0.4062\n",
      "train Loss: 0.0009 Acc: 0.0096 batch_loss: 4.6518 correct: 44 batch_accuracy: 0.3438\n",
      "train Loss: 0.0014 Acc: 0.0133 batch_loss: 4.6177 correct: 37 batch_accuracy: 0.2891\n",
      "train Loss: 0.0019 Acc: 0.0175 batch_loss: 4.6389 correct: 42 batch_accuracy: 0.3281\n",
      "train Loss: 0.0023 Acc: 0.0216 batch_loss: 4.7055 correct: 40 batch_accuracy: 0.3125\n",
      "train Loss: 0.0028 Acc: 0.0253 batch_loss: 4.6700 correct: 37 batch_accuracy: 0.2891\n",
      "train Loss: 0.0033 Acc: 0.0302 batch_loss: 4.6176 correct: 49 batch_accuracy: 0.3828\n",
      "train Loss: 0.0037 Acc: 0.0357 batch_loss: 4.6204 correct: 55 batch_accuracy: 0.4297\n",
      "train Loss: 0.0042 Acc: 0.0399 batch_loss: 4.6408 correct: 42 batch_accuracy: 0.3281\n",
      "train Loss: 0.0046 Acc: 0.0446 batch_loss: 4.6359 correct: 47 batch_accuracy: 0.3672\n",
      "train Loss: 0.0051 Acc: 0.0504 batch_loss: 4.5416 correct: 58 batch_accuracy: 0.4531\n",
      "train Loss: 0.0056 Acc: 0.0560 batch_loss: 4.5706 correct: 56 batch_accuracy: 0.4375\n",
      "train Loss: 0.0060 Acc: 0.0599 batch_loss: 4.6342 correct: 39 batch_accuracy: 0.3047\n",
      "train Loss: 0.0065 Acc: 0.0640 batch_loss: 4.6230 correct: 40 batch_accuracy: 0.3125\n",
      "train Loss: 0.0070 Acc: 0.0691 batch_loss: 4.6202 correct: 51 batch_accuracy: 0.3984\n",
      "train Loss: 0.0074 Acc: 0.0732 batch_loss: 4.6692 correct: 41 batch_accuracy: 0.3203\n",
      "train Loss: 0.0079 Acc: 0.0775 batch_loss: 4.6362 correct: 43 batch_accuracy: 0.3359\n",
      "train Loss: 0.0084 Acc: 0.0833 batch_loss: 4.6205 correct: 58 batch_accuracy: 0.4531\n",
      "train Loss: 0.0088 Acc: 0.0884 batch_loss: 4.6336 correct: 51 batch_accuracy: 0.3984\n",
      "train Loss: 0.0093 Acc: 0.0923 batch_loss: 4.6564 correct: 39 batch_accuracy: 0.3047\n",
      "train Loss: 0.0097 Acc: 0.0965 batch_loss: 4.5967 correct: 42 batch_accuracy: 0.3281\n",
      "train Loss: 0.0102 Acc: 0.1009 batch_loss: 4.6563 correct: 43 batch_accuracy: 0.3359\n",
      "train Loss: 0.0107 Acc: 0.1051 batch_loss: 4.6148 correct: 42 batch_accuracy: 0.3281\n",
      "train Loss: 0.0111 Acc: 0.1098 batch_loss: 4.6010 correct: 47 batch_accuracy: 0.3672\n",
      "train Loss: 0.0116 Acc: 0.1136 batch_loss: 4.6574 correct: 38 batch_accuracy: 0.2969\n",
      "train Loss: 0.0121 Acc: 0.1178 batch_loss: 4.5977 correct: 42 batch_accuracy: 0.3281\n",
      "train Loss: 0.0125 Acc: 0.1233 batch_loss: 4.6261 correct: 55 batch_accuracy: 0.4297\n",
      "train Loss: 0.0130 Acc: 0.1278 batch_loss: 4.5880 correct: 45 batch_accuracy: 0.3516\n",
      "train Loss: 0.0134 Acc: 0.1319 batch_loss: 4.6379 correct: 41 batch_accuracy: 0.3203\n",
      "train Loss: 0.0139 Acc: 0.1360 batch_loss: 4.6621 correct: 41 batch_accuracy: 0.3203\n",
      "train Loss: 0.0144 Acc: 0.1399 batch_loss: 4.6461 correct: 39 batch_accuracy: 0.3047\n",
      "train Loss: 0.0148 Acc: 0.1454 batch_loss: 4.6073 correct: 54 batch_accuracy: 0.4219\n",
      "train Loss: 0.0153 Acc: 0.1499 batch_loss: 4.6167 correct: 45 batch_accuracy: 0.3516\n",
      "train Loss: 0.0158 Acc: 0.1551 batch_loss: 4.5485 correct: 52 batch_accuracy: 0.4062\n",
      "train Loss: 0.0162 Acc: 0.1592 batch_loss: 4.6072 correct: 41 batch_accuracy: 0.3203\n",
      "train Loss: 0.0167 Acc: 0.1649 batch_loss: 4.5591 correct: 57 batch_accuracy: 0.4453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0171 Acc: 0.1702 batch_loss: 4.5974 correct: 53 batch_accuracy: 0.4141\n",
      "train Loss: 0.0176 Acc: 0.1741 batch_loss: 4.6754 correct: 39 batch_accuracy: 0.3047\n",
      "train Loss: 0.0181 Acc: 0.1794 batch_loss: 4.5876 correct: 53 batch_accuracy: 0.4141\n",
      "train Loss: 0.0185 Acc: 0.1842 batch_loss: 4.6015 correct: 47 batch_accuracy: 0.3672\n",
      "train Loss: 0.0190 Acc: 0.1894 batch_loss: 4.6142 correct: 52 batch_accuracy: 0.4062\n",
      "train Loss: 0.0195 Acc: 0.1942 batch_loss: 4.5625 correct: 48 batch_accuracy: 0.3750\n",
      "train Loss: 0.0199 Acc: 0.1987 batch_loss: 4.6344 correct: 45 batch_accuracy: 0.3516\n",
      "train Loss: 0.0204 Acc: 0.2033 batch_loss: 4.6556 correct: 46 batch_accuracy: 0.3594\n",
      "train Loss: 0.0208 Acc: 0.2084 batch_loss: 4.6270 correct: 51 batch_accuracy: 0.3984\n",
      "train Loss: 0.0213 Acc: 0.2131 batch_loss: 4.6501 correct: 47 batch_accuracy: 0.3672\n",
      "train Loss: 0.0218 Acc: 0.2175 batch_loss: 4.6170 correct: 44 batch_accuracy: 0.3438\n",
      "train Loss: 0.0222 Acc: 0.2225 batch_loss: 4.6275 correct: 49 batch_accuracy: 0.3828\n",
      "train Loss: 0.0227 Acc: 0.2273 batch_loss: 4.6111 correct: 48 batch_accuracy: 0.3750\n",
      "train Loss: 0.0232 Acc: 0.2320 batch_loss: 4.6085 correct: 47 batch_accuracy: 0.3672\n",
      "train Loss: 0.0236 Acc: 0.2366 batch_loss: 4.6342 correct: 46 batch_accuracy: 0.3594\n",
      "train Loss: 0.0241 Acc: 0.2411 batch_loss: 4.6391 correct: 45 batch_accuracy: 0.3516\n",
      "train Loss: 0.0246 Acc: 0.2454 batch_loss: 4.5963 correct: 43 batch_accuracy: 0.3359\n",
      "train Loss: 0.0250 Acc: 0.2497 batch_loss: 4.5860 correct: 43 batch_accuracy: 0.3359\n",
      "train Loss: 0.0255 Acc: 0.2551 batch_loss: 4.6681 correct: 54 batch_accuracy: 0.4219\n",
      "train Loss: 0.0259 Acc: 0.2599 batch_loss: 4.6097 correct: 48 batch_accuracy: 0.3750\n",
      "train Loss: 0.0264 Acc: 0.2646 batch_loss: 4.6295 correct: 46 batch_accuracy: 0.3594\n",
      "train Loss: 0.0269 Acc: 0.2689 batch_loss: 4.6314 correct: 43 batch_accuracy: 0.3359\n",
      "train Loss: 0.0273 Acc: 0.2736 batch_loss: 4.6557 correct: 47 batch_accuracy: 0.3672\n",
      "train Loss: 0.0278 Acc: 0.2790 batch_loss: 4.6701 correct: 54 batch_accuracy: 0.4219\n",
      "train Loss: 0.0283 Acc: 0.2841 batch_loss: 4.5958 correct: 51 batch_accuracy: 0.3984\n",
      "train Loss: 0.0287 Acc: 0.2887 batch_loss: 4.6564 correct: 46 batch_accuracy: 0.3594\n",
      "train Loss: 0.0292 Acc: 0.2928 batch_loss: 4.6508 correct: 41 batch_accuracy: 0.3203\n",
      "train Loss: 0.0297 Acc: 0.2975 batch_loss: 4.5969 correct: 47 batch_accuracy: 0.3672\n",
      "train Loss: 0.0301 Acc: 0.3019 batch_loss: 4.6467 correct: 43 batch_accuracy: 0.3359\n",
      "train Loss: 0.0306 Acc: 0.3063 batch_loss: 4.6892 correct: 44 batch_accuracy: 0.3438\n",
      "train Loss: 0.0311 Acc: 0.3101 batch_loss: 4.6193 correct: 38 batch_accuracy: 0.2969\n",
      "train Loss: 0.0315 Acc: 0.3139 batch_loss: 4.5925 correct: 38 batch_accuracy: 0.2969\n",
      "train Loss: 0.0320 Acc: 0.3193 batch_loss: 4.5557 correct: 54 batch_accuracy: 0.4219\n",
      "train Loss: 0.0324 Acc: 0.3239 batch_loss: 4.6182 correct: 46 batch_accuracy: 0.3594\n",
      "train Loss: 0.0329 Acc: 0.3287 batch_loss: 4.5925 correct: 48 batch_accuracy: 0.3750\n",
      "train Loss: 0.0334 Acc: 0.3337 batch_loss: 4.5778 correct: 50 batch_accuracy: 0.3906\n",
      "train Loss: 0.0338 Acc: 0.3374 batch_loss: 4.6510 correct: 37 batch_accuracy: 0.2891\n",
      "train Loss: 0.0343 Acc: 0.3428 batch_loss: 4.6276 correct: 53 batch_accuracy: 0.4141\n",
      "train Loss: 0.0348 Acc: 0.3465 batch_loss: 4.6381 correct: 37 batch_accuracy: 0.2891\n",
      "train Loss: 0.0352 Acc: 0.3509 batch_loss: 4.5992 correct: 44 batch_accuracy: 0.3438\n",
      "train Loss: 0.0357 Acc: 0.3559 batch_loss: 4.6706 correct: 50 batch_accuracy: 0.3906\n",
      "train Loss: 0.0361 Acc: 0.3603 batch_loss: 4.5513 correct: 44 batch_accuracy: 0.3438\n",
      "Accuracy of the network on the test images: 34.92000 %\n",
      "Epoch 3/4\n",
      "----------\n",
      "train Loss: 0.0005 Acc: 0.0041 batch_loss: 4.6214 correct: 41 batch_accuracy: 0.3203\n",
      "train Loss: 0.0009 Acc: 0.0082 batch_loss: 4.6477 correct: 41 batch_accuracy: 0.3203\n",
      "train Loss: 0.0014 Acc: 0.0132 batch_loss: 4.6325 correct: 50 batch_accuracy: 0.3906\n",
      "train Loss: 0.0019 Acc: 0.0176 batch_loss: 4.6145 correct: 44 batch_accuracy: 0.3438\n",
      "train Loss: 0.0023 Acc: 0.0233 batch_loss: 4.5900 correct: 56 batch_accuracy: 0.4375\n",
      "train Loss: 0.0028 Acc: 0.0281 batch_loss: 4.6134 correct: 48 batch_accuracy: 0.3750\n",
      "train Loss: 0.0032 Acc: 0.0319 batch_loss: 4.6268 correct: 38 batch_accuracy: 0.2969\n",
      "train Loss: 0.0037 Acc: 0.0363 batch_loss: 4.6284 correct: 44 batch_accuracy: 0.3438\n",
      "train Loss: 0.0042 Acc: 0.0403 batch_loss: 4.6042 correct: 40 batch_accuracy: 0.3125\n",
      "train Loss: 0.0046 Acc: 0.0438 batch_loss: 4.6679 correct: 35 batch_accuracy: 0.2734\n",
      "train Loss: 0.0051 Acc: 0.0482 batch_loss: 4.6354 correct: 44 batch_accuracy: 0.3438\n",
      "train Loss: 0.0056 Acc: 0.0533 batch_loss: 4.6113 correct: 51 batch_accuracy: 0.3984\n",
      "train Loss: 0.0060 Acc: 0.0574 batch_loss: 4.6268 correct: 41 batch_accuracy: 0.3203\n",
      "train Loss: 0.0065 Acc: 0.0617 batch_loss: 4.6289 correct: 42 batch_accuracy: 0.3281\n",
      "train Loss: 0.0070 Acc: 0.0647 batch_loss: 4.6612 correct: 30 batch_accuracy: 0.2344\n",
      "train Loss: 0.0074 Acc: 0.0691 batch_loss: 4.6230 correct: 44 batch_accuracy: 0.3438\n",
      "train Loss: 0.0079 Acc: 0.0742 batch_loss: 4.6546 correct: 51 batch_accuracy: 0.3984\n",
      "train Loss: 0.0084 Acc: 0.0794 batch_loss: 4.6042 correct: 52 batch_accuracy: 0.4062\n",
      "train Loss: 0.0088 Acc: 0.0838 batch_loss: 4.6111 correct: 44 batch_accuracy: 0.3438\n",
      "train Loss: 0.0093 Acc: 0.0881 batch_loss: 4.6434 correct: 43 batch_accuracy: 0.3359\n",
      "train Loss: 0.0097 Acc: 0.0944 batch_loss: 4.5310 correct: 63 batch_accuracy: 0.4922\n",
      "train Loss: 0.0102 Acc: 0.1001 batch_loss: 4.5979 correct: 56 batch_accuracy: 0.4375\n",
      "train Loss: 0.0107 Acc: 0.1048 batch_loss: 4.5841 correct: 47 batch_accuracy: 0.3672\n",
      "train Loss: 0.0111 Acc: 0.1086 batch_loss: 4.6441 correct: 38 batch_accuracy: 0.2969\n",
      "train Loss: 0.0116 Acc: 0.1127 batch_loss: 4.6191 correct: 41 batch_accuracy: 0.3203\n",
      "train Loss: 0.0120 Acc: 0.1177 batch_loss: 4.6505 correct: 50 batch_accuracy: 0.3906\n",
      "train Loss: 0.0125 Acc: 0.1231 batch_loss: 4.6107 correct: 54 batch_accuracy: 0.4219\n",
      "train Loss: 0.0130 Acc: 0.1278 batch_loss: 4.5934 correct: 47 batch_accuracy: 0.3672\n",
      "train Loss: 0.0134 Acc: 0.1318 batch_loss: 4.6364 correct: 40 batch_accuracy: 0.3125\n",
      "train Loss: 0.0139 Acc: 0.1360 batch_loss: 4.5810 correct: 42 batch_accuracy: 0.3281\n",
      "train Loss: 0.0144 Acc: 0.1416 batch_loss: 4.6150 correct: 55 batch_accuracy: 0.4297\n",
      "train Loss: 0.0148 Acc: 0.1470 batch_loss: 4.5675 correct: 54 batch_accuracy: 0.4219\n",
      "train Loss: 0.0153 Acc: 0.1521 batch_loss: 4.5856 correct: 51 batch_accuracy: 0.3984\n",
      "train Loss: 0.0157 Acc: 0.1567 batch_loss: 4.6107 correct: 46 batch_accuracy: 0.3594\n",
      "train Loss: 0.0162 Acc: 0.1613 batch_loss: 4.5893 correct: 46 batch_accuracy: 0.3594\n",
      "train Loss: 0.0167 Acc: 0.1666 batch_loss: 4.6280 correct: 53 batch_accuracy: 0.4141\n",
      "train Loss: 0.0171 Acc: 0.1714 batch_loss: 4.6293 correct: 48 batch_accuracy: 0.3750\n",
      "train Loss: 0.0176 Acc: 0.1760 batch_loss: 4.6541 correct: 46 batch_accuracy: 0.3594\n",
      "train Loss: 0.0181 Acc: 0.1812 batch_loss: 4.5920 correct: 51 batch_accuracy: 0.3984\n",
      "train Loss: 0.0185 Acc: 0.1859 batch_loss: 4.6134 correct: 47 batch_accuracy: 0.3672\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-9e104493f431>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n\u001b[0;32m---> 22\u001b[0;31m                        num_epochs=5)\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_ft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-01ae65e8fcb5>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, scheduler, num_epochs)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0;31m# Iterate over data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m             \u001b[0;31m# get the inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    629\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 631\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrcvd_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_batch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    608\u001b[0m             \u001b[0;31m# need to call `.task_done()` because we don't use `.join()`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.6/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rlock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m                 \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mrecv_bytes\u001b[0;34m(self, maxlength)\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxlength\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmaxlength\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"negative maxlength\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbuf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bad_message_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"!i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxsize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mremaining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m             \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# transfer learning resnet18\n",
    "model_ft = resnet18()\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "model_ft.fc = nn.Linear(num_ftrs, num_of_classes)\n",
    "\n",
    "if use_gpu:\n",
    "    model_ft = torch.nn.DataParallel(model_ft)\n",
    "    model_ft.to(device)\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001,  momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=1, gamma=0.1)\n",
    "\n",
    "# train model\n",
    "model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=5)\n",
    "torch.save(model_ft, output_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
