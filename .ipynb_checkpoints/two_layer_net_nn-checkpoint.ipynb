{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from PIL import ImageOps\n",
    "import PIL\n",
    "import torch, torchvision\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset import *\n",
    "import random\n",
    "import math\n",
    "import seaborn\n",
    "from  matplotlib import pyplot\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 10       # The image size = 28 x 28 = 784\n",
    "hidden_size = 500      # The number of nodes at the hidden layer\n",
    "num_classes = 5       # The number of output classes. In this case, from 0 to 9\n",
    "num_epochs = 10         # The number of times entire dataset is trained\n",
    "batch_size = 256       # The size of input data took for one iteration\n",
    "learning_rate = 0.0001  # The speed of convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transform = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(200, scale=(1, 1), ratio=(1, 1)),\n",
    "        transforms.RandomRotation((-90,90)),\n",
    "        torchvision.transforms.RandomVerticalFlip(p=0.5),\n",
    "        torchvision.transforms.RandomHorizontalFlip(p=0.5),\n",
    "#         torchvision.transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0, hue=0),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.3019],\n",
    "                             std=[0.1909])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(Net, self).__init__()                    # Inherited from the parent class nn.Module\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)  # 1st Full-Connected Layer: 10 (input data) -> 500 (hidden node)\n",
    "        self.relu = nn.ReLU()                          # Non-Linear ReLU Layer: max(0,x)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size) # 2nd Full-Connected Layer: 500 (hidden node) -> 5 (output class)\n",
    "#         self.relu = nn.ReLU()                          # Non-Linear ReLU Layer: max(0,x)\n",
    "#         self.fc3 = nn.Linear(hidden_size, num_classes) # 3rd Full-Connected Layer: 500 (hidden node) -> 5 (output class)\n",
    "    \n",
    "    def forward(self, x):                              # Forward pass: stacking each layer together\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "#         out = self.relu(out)\n",
    "#         out = self.fc3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net(input_size, hidden_size, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainloader ready!\n",
      "testloader ready!\n"
     ]
    }
   ],
   "source": [
    "trainset = defectDataset_df(df = split_and_sample(method = 'hard',n_samples = 1995, non_pos_ratio=1), window_size = window_size,\n",
    "                                             transforms=data_transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset,\n",
    "                                             batch_size=batch_size, shuffle=True,\n",
    "                                             num_workers=8, drop_last=True)\n",
    "print(\"trainloader ready!\")\n",
    "\n",
    "testset = defectDataset_df(df = split_and_sample(df_train = pd.read_csv('/home/rliu/yolo2/v2_pytorch_yolo2/data/an_data/VOCdevkit/VOC2007/csv_labels/test.csv', sep=\" \"),\n",
    "                                                      method = 'hard',n_samples = 800), window_size = window_size, transforms=data_transform)\n",
    "testloader = torch.utils.data.DataLoader(testset,\n",
    "                                             batch_size=batch_size, shuffle=True,\n",
    "                                             num_workers=8)\n",
    "print(\"testloader ready!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU in use\n"
     ]
    }
   ],
   "source": [
    "use_gpu = torch.cuda.is_available()\n",
    "\n",
    "if use_gpu:\n",
    "    print(\"GPU in use\")\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "classes = [\"pos\",\"neg\",\"pos_o\",\"nuc\",\"non\"]\n",
    "num_of_classes = len(classes)\n",
    "\n",
    "model_uniform = torch.load('/home/rliu/defect_classifier/models/python/res34_600epo_uniform_01-07-18.model')\n",
    "model_uniform.eval()\n",
    "model_hard = torch.load('/home/rliu/defect_classifier/models/python/res34_600epo_hard_01-07-18.model')\n",
    "model_hard.eval()\n",
    "\n",
    "\n",
    "if use_gpu:\n",
    "#     model_uniform = torch.nn.DataParallel(model_uniform)\n",
    "    model_uniform.to(device)\n",
    "#     model_hard = torch.nn.DataParallel(model_hard)\n",
    "    model_hard.to(device)\n",
    "    net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9\n",
      "----------\n",
      "train Loss: 0.0011 Acc: 0.0000 batch_loss: 11.1480 correct: 0 batch_accuracy: 0.0000\n",
      "train Loss: 0.0022 Acc: 0.0000 batch_loss: 10.9080 correct: 0 batch_accuracy: 0.0000\n",
      "train Loss: 0.0033 Acc: 0.0000 batch_loss: 10.7185 correct: 0 batch_accuracy: 0.0000\n",
      "train Loss: 0.0043 Acc: 0.0000 batch_loss: 10.3903 correct: 0 batch_accuracy: 0.0000\n",
      "train Loss: 0.0053 Acc: 0.0000 batch_loss: 10.0797 correct: 0 batch_accuracy: 0.0000\n",
      "train Loss: 0.0063 Acc: 0.0000 batch_loss: 9.9035 correct: 0 batch_accuracy: 0.0000\n",
      "train Loss: 0.0073 Acc: 0.0000 batch_loss: 9.6065 correct: 0 batch_accuracy: 0.0000\n",
      "train Loss: 0.0082 Acc: 0.0000 batch_loss: 9.3802 correct: 0 batch_accuracy: 0.0000\n",
      "train Loss: 0.0091 Acc: 0.0000 batch_loss: 9.1168 correct: 0 batch_accuracy: 0.0000\n",
      "train Loss: 0.0100 Acc: 0.0000 batch_loss: 8.8565 correct: 0 batch_accuracy: 0.0000\n",
      "train Loss: 0.0109 Acc: 0.0000 batch_loss: 8.5703 correct: 0 batch_accuracy: 0.0000\n",
      "train Loss: 0.0117 Acc: 0.0000 batch_loss: 8.1454 correct: 0 batch_accuracy: 0.0000\n",
      "train Loss: 0.0125 Acc: 0.0000 batch_loss: 7.9641 correct: 0 batch_accuracy: 0.0000\n",
      "train Loss: 0.0133 Acc: 0.0000 batch_loss: 7.8179 correct: 0 batch_accuracy: 0.0000\n",
      "train Loss: 0.0140 Acc: 0.0000 batch_loss: 7.3400 correct: 0 batch_accuracy: 0.0000\n",
      "train Loss: 0.0148 Acc: 0.0000 batch_loss: 7.2389 correct: 0 batch_accuracy: 0.0000\n",
      "train Loss: 0.0155 Acc: 0.0000 batch_loss: 6.9418 correct: 0 batch_accuracy: 0.0000\n",
      "train Loss: 0.0161 Acc: 0.0000 batch_loss: 6.6689 correct: 0 batch_accuracy: 0.0000\n",
      "train Loss: 0.0168 Acc: 0.0000 batch_loss: 6.4460 correct: 0 batch_accuracy: 0.0000\n",
      "train Loss: 0.0174 Acc: 0.0000 batch_loss: 6.4982 correct: 0 batch_accuracy: 0.0000\n",
      "train Loss: 0.0180 Acc: 0.0000 batch_loss: 5.9345 correct: 0 batch_accuracy: 0.0000\n",
      "train Loss: 0.0186 Acc: 0.0001 batch_loss: 5.6254 correct: 1 batch_accuracy: 0.0039\n",
      "train Loss: 0.0191 Acc: 0.0001 batch_loss: 5.4973 correct: 0 batch_accuracy: 0.0000\n",
      "train Loss: 0.0197 Acc: 0.0001 batch_loss: 5.4448 correct: 0 batch_accuracy: 0.0000\n",
      "train Loss: 0.0202 Acc: 0.0002 batch_loss: 5.0771 correct: 1 batch_accuracy: 0.0039\n",
      "train Loss: 0.0207 Acc: 0.0005 batch_loss: 4.8053 correct: 3 batch_accuracy: 0.0117\n",
      "train Loss: 0.0211 Acc: 0.0008 batch_loss: 4.7332 correct: 3 batch_accuracy: 0.0117\n",
      "train Loss: 0.0216 Acc: 0.0013 batch_loss: 4.3085 correct: 5 batch_accuracy: 0.0195\n",
      "train Loss: 0.0220 Acc: 0.0020 batch_loss: 4.2459 correct: 7 batch_accuracy: 0.0273\n",
      "train Loss: 0.0224 Acc: 0.0025 batch_loss: 4.1311 correct: 5 batch_accuracy: 0.0195\n",
      "train Loss: 0.0228 Acc: 0.0037 batch_loss: 3.7293 correct: 12 batch_accuracy: 0.0469\n",
      "train Loss: 0.0232 Acc: 0.0049 batch_loss: 3.6981 correct: 12 batch_accuracy: 0.0469\n",
      "train Loss: 0.0235 Acc: 0.0064 batch_loss: 3.5983 correct: 15 batch_accuracy: 0.0586\n",
      "train Loss: 0.0239 Acc: 0.0081 batch_loss: 3.3478 correct: 17 batch_accuracy: 0.0664\n",
      "train Loss: 0.0242 Acc: 0.0092 batch_loss: 3.2867 correct: 11 batch_accuracy: 0.0430\n",
      "train Loss: 0.0245 Acc: 0.0109 batch_loss: 3.1656 correct: 17 batch_accuracy: 0.0664\n",
      "train Loss: 0.0248 Acc: 0.0130 batch_loss: 2.9718 correct: 21 batch_accuracy: 0.0820\n",
      "train Loss: 0.0251 Acc: 0.0150 batch_loss: 2.8623 correct: 20 batch_accuracy: 0.0781\n",
      "Accuracy of the network on the test images: 14.37500 %\n",
      "Accuracy of   pos :  0 %\n",
      "Accuracy of   neg : 15 %\n",
      "Accuracy of pos_o :  2 %\n",
      "Accuracy of   nuc :  9 %\n",
      "Accuracy of   non : 44 %\n",
      "class total:  [763.0, 771.0, 771.0, 765.0, 770.0]\n",
      "class correct:  [1.0, 122.0, 17.0, 71.0, 341.0]\n",
      "total:  3840\n",
      "correct:  552\n",
      "Epoch 1/9\n",
      "----------\n",
      "train Loss: 0.0003 Acc: 0.0026 batch_loss: 2.7750 correct: 26 batch_accuracy: 0.1016\n",
      "train Loss: 0.0005 Acc: 0.0059 batch_loss: 2.5502 correct: 33 batch_accuracy: 0.1289\n",
      "train Loss: 0.0008 Acc: 0.0097 batch_loss: 2.5003 correct: 38 batch_accuracy: 0.1484\n",
      "train Loss: 0.0010 Acc: 0.0147 batch_loss: 2.3185 correct: 50 batch_accuracy: 0.1953\n",
      "train Loss: 0.0012 Acc: 0.0214 batch_loss: 2.2151 correct: 66 batch_accuracy: 0.2578\n",
      "train Loss: 0.0014 Acc: 0.0289 batch_loss: 2.0414 correct: 75 batch_accuracy: 0.2930\n",
      "train Loss: 0.0016 Acc: 0.0374 batch_loss: 1.9774 correct: 85 batch_accuracy: 0.3320\n",
      "train Loss: 0.0018 Acc: 0.0473 batch_loss: 1.8041 correct: 99 batch_accuracy: 0.3867\n",
      "train Loss: 0.0020 Acc: 0.0562 batch_loss: 1.7573 correct: 89 batch_accuracy: 0.3477\n",
      "train Loss: 0.0022 Acc: 0.0660 batch_loss: 1.7185 correct: 97 batch_accuracy: 0.3789\n",
      "train Loss: 0.0023 Acc: 0.0769 batch_loss: 1.5769 correct: 109 batch_accuracy: 0.4258\n",
      "train Loss: 0.0025 Acc: 0.0882 batch_loss: 1.5935 correct: 113 batch_accuracy: 0.4414\n",
      "train Loss: 0.0026 Acc: 0.0998 batch_loss: 1.5412 correct: 116 batch_accuracy: 0.4531\n",
      "train Loss: 0.0028 Acc: 0.1137 batch_loss: 1.3765 correct: 138 batch_accuracy: 0.5391\n",
      "train Loss: 0.0029 Acc: 0.1285 batch_loss: 1.3287 correct: 148 batch_accuracy: 0.5781\n",
      "train Loss: 0.0030 Acc: 0.1453 batch_loss: 1.2227 correct: 167 batch_accuracy: 0.6523\n",
      "train Loss: 0.0032 Acc: 0.1617 batch_loss: 1.2219 correct: 164 batch_accuracy: 0.6406\n",
      "train Loss: 0.0033 Acc: 0.1780 batch_loss: 1.2203 correct: 163 batch_accuracy: 0.6367\n",
      "train Loss: 0.0034 Acc: 0.1958 batch_loss: 1.1080 correct: 177 batch_accuracy: 0.6914\n",
      "train Loss: 0.0035 Acc: 0.2153 batch_loss: 0.9924 correct: 195 batch_accuracy: 0.7617\n",
      "train Loss: 0.0036 Acc: 0.2353 batch_loss: 1.0074 correct: 199 batch_accuracy: 0.7773\n",
      "train Loss: 0.0037 Acc: 0.2567 batch_loss: 0.9240 correct: 214 batch_accuracy: 0.8359\n",
      "train Loss: 0.0038 Acc: 0.2785 batch_loss: 0.8821 correct: 217 batch_accuracy: 0.8477\n",
      "train Loss: 0.0039 Acc: 0.3004 batch_loss: 0.8035 correct: 218 batch_accuracy: 0.8516\n",
      "train Loss: 0.0039 Acc: 0.3230 batch_loss: 0.7922 correct: 226 batch_accuracy: 0.8828\n",
      "train Loss: 0.0040 Acc: 0.3465 batch_loss: 0.7454 correct: 234 batch_accuracy: 0.9141\n",
      "train Loss: 0.0041 Acc: 0.3696 batch_loss: 0.7517 correct: 231 batch_accuracy: 0.9023\n",
      "train Loss: 0.0042 Acc: 0.3927 batch_loss: 0.6939 correct: 230 batch_accuracy: 0.8984\n",
      "train Loss: 0.0042 Acc: 0.4155 batch_loss: 0.6702 correct: 228 batch_accuracy: 0.8906\n",
      "train Loss: 0.0043 Acc: 0.4393 batch_loss: 0.6203 correct: 237 batch_accuracy: 0.9258\n",
      "train Loss: 0.0043 Acc: 0.4631 batch_loss: 0.6178 correct: 237 batch_accuracy: 0.9258\n",
      "train Loss: 0.0044 Acc: 0.4872 batch_loss: 0.5535 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0045 Acc: 0.5113 batch_loss: 0.5483 correct: 240 batch_accuracy: 0.9375\n",
      "train Loss: 0.0045 Acc: 0.5354 batch_loss: 0.5107 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0046 Acc: 0.5597 batch_loss: 0.4936 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0046 Acc: 0.5841 batch_loss: 0.4926 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0047 Acc: 0.6077 batch_loss: 0.5045 correct: 236 batch_accuracy: 0.9219\n",
      "train Loss: 0.0047 Acc: 0.6318 batch_loss: 0.4513 correct: 240 batch_accuracy: 0.9375\n",
      "Accuracy of the network on the test images: 79.89583 %\n",
      "Accuracy of   pos : 84 %\n",
      "Accuracy of   neg : 88 %\n",
      "Accuracy of pos_o : 70 %\n",
      "Accuracy of   nuc : 71 %\n",
      "Accuracy of   non : 84 %\n",
      "class total:  [764.0, 764.0, 772.0, 772.0, 768.0]\n",
      "class correct:  [645.0, 678.0, 547.0, 550.0, 648.0]\n",
      "total:  3840\n",
      "correct:  3068\n",
      "Epoch 2/9\n",
      "----------\n",
      "train Loss: 0.0000 Acc: 0.0243 batch_loss: 0.4310 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0001 Acc: 0.0482 batch_loss: 0.4628 correct: 239 batch_accuracy: 0.9336\n",
      "train Loss: 0.0001 Acc: 0.0727 batch_loss: 0.4401 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0002 Acc: 0.0971 batch_loss: 0.4300 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0002 Acc: 0.1215 batch_loss: 0.4155 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0003 Acc: 0.1454 batch_loss: 0.4061 correct: 238 batch_accuracy: 0.9297\n",
      "train Loss: 0.0003 Acc: 0.1697 batch_loss: 0.3690 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0003 Acc: 0.1943 batch_loss: 0.3629 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0004 Acc: 0.2189 batch_loss: 0.3578 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0004 Acc: 0.2430 batch_loss: 0.3747 correct: 240 batch_accuracy: 0.9375\n",
      "train Loss: 0.0004 Acc: 0.2678 batch_loss: 0.3160 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0005 Acc: 0.2919 batch_loss: 0.3305 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0005 Acc: 0.3163 batch_loss: 0.3072 correct: 243 batch_accuracy: 0.9492\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0005 Acc: 0.3413 batch_loss: 0.2804 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0006 Acc: 0.3655 batch_loss: 0.3246 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0006 Acc: 0.3896 batch_loss: 0.3249 correct: 240 batch_accuracy: 0.9375\n",
      "train Loss: 0.0006 Acc: 0.4148 batch_loss: 0.2760 correct: 252 batch_accuracy: 0.9844\n",
      "train Loss: 0.0007 Acc: 0.4395 batch_loss: 0.3109 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0007 Acc: 0.4636 batch_loss: 0.2825 correct: 240 batch_accuracy: 0.9375\n",
      "train Loss: 0.0007 Acc: 0.4885 batch_loss: 0.2336 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0007 Acc: 0.5130 batch_loss: 0.2850 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0008 Acc: 0.5372 batch_loss: 0.3217 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0008 Acc: 0.5613 batch_loss: 0.3068 correct: 240 batch_accuracy: 0.9375\n",
      "train Loss: 0.0008 Acc: 0.5859 batch_loss: 0.2675 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0009 Acc: 0.6104 batch_loss: 0.2886 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0009 Acc: 0.6348 batch_loss: 0.2677 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0009 Acc: 0.6588 batch_loss: 0.3221 correct: 240 batch_accuracy: 0.9375\n",
      "train Loss: 0.0009 Acc: 0.6836 batch_loss: 0.2338 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0010 Acc: 0.7077 batch_loss: 0.2853 correct: 240 batch_accuracy: 0.9375\n",
      "train Loss: 0.0010 Acc: 0.7323 batch_loss: 0.2427 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0010 Acc: 0.7568 batch_loss: 0.2632 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0010 Acc: 0.7812 batch_loss: 0.2650 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0011 Acc: 0.8061 batch_loss: 0.2234 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0011 Acc: 0.8312 batch_loss: 0.2039 correct: 250 batch_accuracy: 0.9766\n",
      "train Loss: 0.0011 Acc: 0.8559 batch_loss: 0.2278 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0011 Acc: 0.8809 batch_loss: 0.2115 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0011 Acc: 0.9058 batch_loss: 0.2040 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0012 Acc: 0.9304 batch_loss: 0.2232 correct: 246 batch_accuracy: 0.9609\n",
      "Accuracy of the network on the test images: 82.31771 %\n",
      "Accuracy of   pos : 86 %\n",
      "Accuracy of   neg : 89 %\n",
      "Accuracy of pos_o : 73 %\n",
      "Accuracy of   nuc : 72 %\n",
      "Accuracy of   non : 88 %\n",
      "class total:  [770.0, 770.0, 772.0, 764.0, 764.0]\n",
      "class correct:  [667.0, 691.0, 568.0, 557.0, 678.0]\n",
      "total:  3840\n",
      "correct:  3161\n",
      "Epoch 3/9\n",
      "----------\n",
      "train Loss: 0.0000 Acc: 0.0244 batch_loss: 0.2246 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0000 Acc: 0.0488 batch_loss: 0.2151 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0001 Acc: 0.0728 batch_loss: 0.2859 correct: 239 batch_accuracy: 0.9336\n",
      "train Loss: 0.0001 Acc: 0.0978 batch_loss: 0.1974 correct: 250 batch_accuracy: 0.9766\n",
      "train Loss: 0.0001 Acc: 0.1227 batch_loss: 0.2069 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0001 Acc: 0.1471 batch_loss: 0.2572 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0002 Acc: 0.1715 batch_loss: 0.2127 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0002 Acc: 0.1959 batch_loss: 0.2357 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0002 Acc: 0.2201 batch_loss: 0.2465 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0002 Acc: 0.2449 batch_loss: 0.2055 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0003 Acc: 0.2694 batch_loss: 0.2147 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0003 Acc: 0.2945 batch_loss: 0.1708 correct: 251 batch_accuracy: 0.9805\n",
      "train Loss: 0.0003 Acc: 0.3193 batch_loss: 0.1956 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0003 Acc: 0.3442 batch_loss: 0.1682 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0003 Acc: 0.3685 batch_loss: 0.2568 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0004 Acc: 0.3928 batch_loss: 0.2490 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0004 Acc: 0.4174 batch_loss: 0.1994 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0004 Acc: 0.4420 batch_loss: 0.1858 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0004 Acc: 0.4665 batch_loss: 0.2176 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0004 Acc: 0.4913 batch_loss: 0.1777 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0005 Acc: 0.5160 batch_loss: 0.2024 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0005 Acc: 0.5411 batch_loss: 0.1507 correct: 250 batch_accuracy: 0.9766\n",
      "train Loss: 0.0005 Acc: 0.5655 batch_loss: 0.2349 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0005 Acc: 0.5901 batch_loss: 0.1807 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0005 Acc: 0.6144 batch_loss: 0.2030 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0006 Acc: 0.6390 batch_loss: 0.1944 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0006 Acc: 0.6629 batch_loss: 0.2106 correct: 238 batch_accuracy: 0.9297\n",
      "train Loss: 0.0006 Acc: 0.6875 batch_loss: 0.1638 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0006 Acc: 0.7121 batch_loss: 0.2098 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0006 Acc: 0.7370 batch_loss: 0.1531 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0006 Acc: 0.7620 batch_loss: 0.1541 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0007 Acc: 0.7863 batch_loss: 0.2071 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0007 Acc: 0.8111 batch_loss: 0.1589 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0007 Acc: 0.8359 batch_loss: 0.2164 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0007 Acc: 0.8605 batch_loss: 0.2031 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0007 Acc: 0.8850 batch_loss: 0.1932 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0008 Acc: 0.9093 batch_loss: 0.2127 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0008 Acc: 0.9342 batch_loss: 0.1355 correct: 249 batch_accuracy: 0.9727\n",
      "Accuracy of the network on the test images: 82.52604 %\n",
      "Accuracy of   pos : 86 %\n",
      "Accuracy of   neg : 89 %\n",
      "Accuracy of pos_o : 74 %\n",
      "Accuracy of   nuc : 73 %\n",
      "Accuracy of   non : 88 %\n",
      "class total:  [778.0, 770.0, 763.0, 766.0, 763.0]\n",
      "class correct:  [675.0, 687.0, 570.0, 562.0, 675.0]\n",
      "total:  3840\n",
      "correct:  3169\n",
      "Epoch 4/9\n",
      "----------\n",
      "train Loss: 0.0000 Acc: 0.0245 batch_loss: 0.1872 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0000 Acc: 0.0488 batch_loss: 0.2169 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0001 Acc: 0.0736 batch_loss: 0.1872 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0001 Acc: 0.0980 batch_loss: 0.1737 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0001 Acc: 0.1225 batch_loss: 0.2184 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0001 Acc: 0.1470 batch_loss: 0.1875 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0001 Acc: 0.1716 batch_loss: 0.1730 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0002 Acc: 0.1961 batch_loss: 0.1866 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0002 Acc: 0.2209 batch_loss: 0.1795 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0002 Acc: 0.2453 batch_loss: 0.2003 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0002 Acc: 0.2702 batch_loss: 0.1790 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0002 Acc: 0.2949 batch_loss: 0.1872 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0002 Acc: 0.3193 batch_loss: 0.1860 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0003 Acc: 0.3435 batch_loss: 0.1732 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0003 Acc: 0.3680 batch_loss: 0.1834 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0003 Acc: 0.3933 batch_loss: 0.1014 correct: 252 batch_accuracy: 0.9844\n",
      "train Loss: 0.0003 Acc: 0.4179 batch_loss: 0.1748 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0003 Acc: 0.4425 batch_loss: 0.1578 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0003 Acc: 0.4671 batch_loss: 0.1380 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0004 Acc: 0.4922 batch_loss: 0.1276 correct: 251 batch_accuracy: 0.9805\n",
      "train Loss: 0.0004 Acc: 0.5168 batch_loss: 0.1964 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0004 Acc: 0.5414 batch_loss: 0.1698 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0004 Acc: 0.5662 batch_loss: 0.1332 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0004 Acc: 0.5914 batch_loss: 0.1244 correct: 251 batch_accuracy: 0.9805\n",
      "train Loss: 0.0004 Acc: 0.6160 batch_loss: 0.1435 correct: 246 batch_accuracy: 0.9609\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0005 Acc: 0.6404 batch_loss: 0.2211 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0005 Acc: 0.6651 batch_loss: 0.1632 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0005 Acc: 0.6898 batch_loss: 0.1576 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0005 Acc: 0.7145 batch_loss: 0.1909 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0005 Acc: 0.7387 batch_loss: 0.1964 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0005 Acc: 0.7634 batch_loss: 0.1603 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0006 Acc: 0.7880 batch_loss: 0.2109 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0006 Acc: 0.8126 batch_loss: 0.1510 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0006 Acc: 0.8370 batch_loss: 0.1874 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0006 Acc: 0.8616 batch_loss: 0.1769 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0006 Acc: 0.8865 batch_loss: 0.1444 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0006 Acc: 0.9112 batch_loss: 0.1309 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0007 Acc: 0.9353 batch_loss: 0.1988 correct: 241 batch_accuracy: 0.9414\n",
      "Accuracy of the network on the test images: 82.39583 %\n",
      "Accuracy of   pos : 86 %\n",
      "Accuracy of   neg : 89 %\n",
      "Accuracy of pos_o : 74 %\n",
      "Accuracy of   nuc : 73 %\n",
      "Accuracy of   non : 88 %\n",
      "class total:  [762.0, 768.0, 763.0, 769.0, 778.0]\n",
      "class correct:  [658.0, 688.0, 567.0, 563.0, 688.0]\n",
      "total:  3840\n",
      "correct:  3164\n",
      "Epoch 5/9\n",
      "----------\n",
      "train Loss: 0.0000 Acc: 0.0247 batch_loss: 0.1497 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0000 Acc: 0.0493 batch_loss: 0.1706 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0000 Acc: 0.0742 batch_loss: 0.1632 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0001 Acc: 0.0992 batch_loss: 0.1127 correct: 250 batch_accuracy: 0.9766\n",
      "train Loss: 0.0001 Acc: 0.1246 batch_loss: 0.1081 correct: 253 batch_accuracy: 0.9883\n",
      "train Loss: 0.0001 Acc: 0.1490 batch_loss: 0.1904 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0001 Acc: 0.1738 batch_loss: 0.1273 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0001 Acc: 0.1986 batch_loss: 0.1637 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0001 Acc: 0.2235 batch_loss: 0.1434 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0001 Acc: 0.2487 batch_loss: 0.1288 correct: 252 batch_accuracy: 0.9844\n",
      "train Loss: 0.0002 Acc: 0.2731 batch_loss: 0.1831 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0002 Acc: 0.2981 batch_loss: 0.1259 correct: 250 batch_accuracy: 0.9766\n",
      "train Loss: 0.0002 Acc: 0.3225 batch_loss: 0.1879 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0002 Acc: 0.3465 batch_loss: 0.2136 correct: 239 batch_accuracy: 0.9336\n",
      "train Loss: 0.0002 Acc: 0.3714 batch_loss: 0.1393 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0002 Acc: 0.3960 batch_loss: 0.1570 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0003 Acc: 0.4210 batch_loss: 0.1333 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0003 Acc: 0.4457 batch_loss: 0.1465 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0003 Acc: 0.4702 batch_loss: 0.1697 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0003 Acc: 0.4944 batch_loss: 0.1998 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0003 Acc: 0.5192 batch_loss: 0.1724 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0003 Acc: 0.5440 batch_loss: 0.1275 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0004 Acc: 0.5683 batch_loss: 0.1878 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0004 Acc: 0.5927 batch_loss: 0.1755 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0004 Acc: 0.6176 batch_loss: 0.1056 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0004 Acc: 0.6419 batch_loss: 0.2027 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0004 Acc: 0.6666 batch_loss: 0.1660 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0004 Acc: 0.6914 batch_loss: 0.1188 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0005 Acc: 0.7162 batch_loss: 0.1278 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0005 Acc: 0.7409 batch_loss: 0.1633 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0005 Acc: 0.7656 batch_loss: 0.1495 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0005 Acc: 0.7905 batch_loss: 0.1468 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0005 Acc: 0.8147 batch_loss: 0.1903 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0005 Acc: 0.8392 batch_loss: 0.1737 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0006 Acc: 0.8637 batch_loss: 0.1777 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0006 Acc: 0.8885 batch_loss: 0.1283 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0006 Acc: 0.9131 batch_loss: 0.1641 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0006 Acc: 0.9379 batch_loss: 0.1297 correct: 248 batch_accuracy: 0.9688\n",
      "Accuracy of the network on the test images: 82.42188 %\n",
      "Accuracy of   pos : 86 %\n",
      "Accuracy of   neg : 89 %\n",
      "Accuracy of pos_o : 74 %\n",
      "Accuracy of   nuc : 73 %\n",
      "Accuracy of   non : 88 %\n",
      "class total:  [765.0, 772.0, 768.0, 768.0, 767.0]\n",
      "class correct:  [661.0, 694.0, 569.0, 562.0, 679.0]\n",
      "total:  3840\n",
      "correct:  3165\n",
      "Epoch 6/9\n",
      "----------\n",
      "train Loss: 0.0000 Acc: 0.0245 batch_loss: 0.1498 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0000 Acc: 0.0494 batch_loss: 0.1249 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0000 Acc: 0.0742 batch_loss: 0.1548 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0001 Acc: 0.0988 batch_loss: 0.1557 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0001 Acc: 0.1237 batch_loss: 0.1403 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0001 Acc: 0.1482 batch_loss: 0.1416 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0001 Acc: 0.1722 batch_loss: 0.1874 correct: 240 batch_accuracy: 0.9375\n",
      "train Loss: 0.0001 Acc: 0.1970 batch_loss: 0.1606 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0001 Acc: 0.2216 batch_loss: 0.1298 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0002 Acc: 0.2463 batch_loss: 0.1551 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0002 Acc: 0.2709 batch_loss: 0.1635 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0002 Acc: 0.2957 batch_loss: 0.1229 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0002 Acc: 0.3204 batch_loss: 0.1545 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0002 Acc: 0.3447 batch_loss: 0.2010 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0002 Acc: 0.3691 batch_loss: 0.1893 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0002 Acc: 0.3938 batch_loss: 0.1094 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0003 Acc: 0.4184 batch_loss: 0.1380 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0003 Acc: 0.4425 batch_loss: 0.1921 correct: 240 batch_accuracy: 0.9375\n",
      "train Loss: 0.0003 Acc: 0.4671 batch_loss: 0.1926 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0003 Acc: 0.4914 batch_loss: 0.1791 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0003 Acc: 0.5160 batch_loss: 0.1560 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0003 Acc: 0.5410 batch_loss: 0.1289 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0004 Acc: 0.5658 batch_loss: 0.1360 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0004 Acc: 0.5903 batch_loss: 0.1303 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0004 Acc: 0.6147 batch_loss: 0.1606 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0004 Acc: 0.6394 batch_loss: 0.1169 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0004 Acc: 0.6639 batch_loss: 0.1612 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0004 Acc: 0.6886 batch_loss: 0.1299 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0004 Acc: 0.7138 batch_loss: 0.1133 correct: 251 batch_accuracy: 0.9805\n",
      "train Loss: 0.0005 Acc: 0.7385 batch_loss: 0.1363 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0005 Acc: 0.7631 batch_loss: 0.1512 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0005 Acc: 0.7876 batch_loss: 0.1391 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0005 Acc: 0.8123 batch_loss: 0.1148 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0005 Acc: 0.8370 batch_loss: 0.1533 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0005 Acc: 0.8614 batch_loss: 0.1428 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0005 Acc: 0.8862 batch_loss: 0.1174 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0005 Acc: 0.9115 batch_loss: 0.0876 correct: 252 batch_accuracy: 0.9844\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0006 Acc: 0.9365 batch_loss: 0.0968 correct: 250 batch_accuracy: 0.9766\n",
      "Accuracy of the network on the test images: 82.31771 %\n",
      "Accuracy of   pos : 86 %\n",
      "Accuracy of   neg : 89 %\n",
      "Accuracy of pos_o : 74 %\n",
      "Accuracy of   nuc : 73 %\n",
      "Accuracy of   non : 88 %\n",
      "class total:  [765.0, 774.0, 771.0, 771.0, 759.0]\n",
      "class correct:  [658.0, 690.0, 571.0, 568.0, 674.0]\n",
      "total:  3840\n",
      "correct:  3161\n",
      "Epoch 7/9\n",
      "----------\n",
      "train Loss: 0.0000 Acc: 0.0249 batch_loss: 0.1486 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0000 Acc: 0.0497 batch_loss: 0.0963 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0000 Acc: 0.0741 batch_loss: 0.1556 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0001 Acc: 0.0985 batch_loss: 0.1747 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0001 Acc: 0.1230 batch_loss: 0.1388 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0001 Acc: 0.1479 batch_loss: 0.1275 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0001 Acc: 0.1726 batch_loss: 0.1323 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0001 Acc: 0.1972 batch_loss: 0.1584 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0001 Acc: 0.2215 batch_loss: 0.2027 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0002 Acc: 0.2456 batch_loss: 0.1807 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0002 Acc: 0.2701 batch_loss: 0.1403 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0002 Acc: 0.2940 batch_loss: 0.2288 correct: 239 batch_accuracy: 0.9336\n",
      "train Loss: 0.0002 Acc: 0.3188 batch_loss: 0.1468 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0002 Acc: 0.3442 batch_loss: 0.0767 correct: 253 batch_accuracy: 0.9883\n",
      "train Loss: 0.0002 Acc: 0.3687 batch_loss: 0.1539 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0002 Acc: 0.3927 batch_loss: 0.1914 correct: 239 batch_accuracy: 0.9336\n",
      "train Loss: 0.0003 Acc: 0.4176 batch_loss: 0.1144 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0003 Acc: 0.4423 batch_loss: 0.1424 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0003 Acc: 0.4675 batch_loss: 0.0707 correct: 251 batch_accuracy: 0.9805\n",
      "train Loss: 0.0003 Acc: 0.4919 batch_loss: 0.1750 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0003 Acc: 0.5170 batch_loss: 0.1112 correct: 250 batch_accuracy: 0.9766\n",
      "train Loss: 0.0003 Acc: 0.5417 batch_loss: 0.1144 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0003 Acc: 0.5666 batch_loss: 0.1129 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0003 Acc: 0.5913 batch_loss: 0.1297 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0004 Acc: 0.6161 batch_loss: 0.1344 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0004 Acc: 0.6409 batch_loss: 0.1503 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0004 Acc: 0.6662 batch_loss: 0.0982 correct: 252 batch_accuracy: 0.9844\n",
      "train Loss: 0.0004 Acc: 0.6909 batch_loss: 0.1092 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0004 Acc: 0.7156 batch_loss: 0.1260 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0004 Acc: 0.7401 batch_loss: 0.1267 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0004 Acc: 0.7644 batch_loss: 0.1741 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0005 Acc: 0.7890 batch_loss: 0.1483 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0005 Acc: 0.8130 batch_loss: 0.1730 correct: 240 batch_accuracy: 0.9375\n",
      "train Loss: 0.0005 Acc: 0.8372 batch_loss: 0.1734 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0005 Acc: 0.8619 batch_loss: 0.1495 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0005 Acc: 0.8864 batch_loss: 0.1156 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0005 Acc: 0.9111 batch_loss: 0.1295 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0005 Acc: 0.9354 batch_loss: 0.1678 correct: 243 batch_accuracy: 0.9492\n",
      "Accuracy of the network on the test images: 81.95312 %\n",
      "Accuracy of   pos : 85 %\n",
      "Accuracy of   neg : 89 %\n",
      "Accuracy of pos_o : 72 %\n",
      "Accuracy of   nuc : 73 %\n",
      "Accuracy of   non : 88 %\n",
      "class total:  [777.0, 764.0, 766.0, 770.0, 763.0]\n",
      "class correct:  [667.0, 682.0, 554.0, 566.0, 678.0]\n",
      "total:  3840\n",
      "correct:  3147\n",
      "Epoch 8/9\n",
      "----------\n",
      "train Loss: 0.0000 Acc: 0.0247 batch_loss: 0.1248 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0000 Acc: 0.0490 batch_loss: 0.1271 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0000 Acc: 0.0743 batch_loss: 0.0690 correct: 252 batch_accuracy: 0.9844\n",
      "train Loss: 0.0000 Acc: 0.0992 batch_loss: 0.1241 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0001 Acc: 0.1238 batch_loss: 0.1440 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0001 Acc: 0.1482 batch_loss: 0.1701 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0001 Acc: 0.1732 batch_loss: 0.1053 correct: 250 batch_accuracy: 0.9766\n",
      "train Loss: 0.0001 Acc: 0.1979 batch_loss: 0.1555 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0001 Acc: 0.2229 batch_loss: 0.1392 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0001 Acc: 0.2475 batch_loss: 0.1304 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0001 Acc: 0.2726 batch_loss: 0.1269 correct: 250 batch_accuracy: 0.9766\n",
      "train Loss: 0.0002 Acc: 0.2967 batch_loss: 0.1956 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0002 Acc: 0.3215 batch_loss: 0.1592 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0002 Acc: 0.3463 batch_loss: 0.1533 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0002 Acc: 0.3711 batch_loss: 0.1236 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0002 Acc: 0.3958 batch_loss: 0.1424 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0002 Acc: 0.4207 batch_loss: 0.1038 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0002 Acc: 0.4452 batch_loss: 0.1555 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0003 Acc: 0.4696 batch_loss: 0.1641 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0003 Acc: 0.4944 batch_loss: 0.1117 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0003 Acc: 0.5192 batch_loss: 0.1388 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0003 Acc: 0.5434 batch_loss: 0.1608 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0003 Acc: 0.5684 batch_loss: 0.0899 correct: 250 batch_accuracy: 0.9766\n",
      "train Loss: 0.0003 Acc: 0.5930 batch_loss: 0.1509 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0003 Acc: 0.6180 batch_loss: 0.1216 correct: 250 batch_accuracy: 0.9766\n",
      "train Loss: 0.0004 Acc: 0.6425 batch_loss: 0.1458 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0004 Acc: 0.6670 batch_loss: 0.1605 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0004 Acc: 0.6917 batch_loss: 0.0964 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0004 Acc: 0.7162 batch_loss: 0.1363 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0004 Acc: 0.7407 batch_loss: 0.1598 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0004 Acc: 0.7653 batch_loss: 0.1321 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0004 Acc: 0.7902 batch_loss: 0.1275 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0005 Acc: 0.8146 batch_loss: 0.1565 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0005 Acc: 0.8394 batch_loss: 0.1076 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0005 Acc: 0.8638 batch_loss: 0.1427 correct: 243 batch_accuracy: 0.9492\n",
      "train Loss: 0.0005 Acc: 0.8882 batch_loss: 0.1448 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0005 Acc: 0.9132 batch_loss: 0.1299 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0005 Acc: 0.9382 batch_loss: 0.1191 correct: 250 batch_accuracy: 0.9766\n",
      "Accuracy of the network on the test images: 82.60417 %\n",
      "Accuracy of   pos : 86 %\n",
      "Accuracy of   neg : 89 %\n",
      "Accuracy of pos_o : 74 %\n",
      "Accuracy of   nuc : 73 %\n",
      "Accuracy of   non : 89 %\n",
      "class total:  [773.0, 766.0, 766.0, 765.0, 770.0]\n",
      "class correct:  [668.0, 684.0, 567.0, 563.0, 690.0]\n",
      "total:  3840\n",
      "correct:  3172\n",
      "Epoch 9/9\n",
      "----------\n",
      "train Loss: 0.0000 Acc: 0.0247 batch_loss: 0.1334 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0000 Acc: 0.0487 batch_loss: 0.1735 correct: 240 batch_accuracy: 0.9375\n",
      "train Loss: 0.0000 Acc: 0.0734 batch_loss: 0.1327 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0001 Acc: 0.0982 batch_loss: 0.1539 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0001 Acc: 0.1230 batch_loss: 0.1031 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0001 Acc: 0.1480 batch_loss: 0.0987 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0001 Acc: 0.1727 batch_loss: 0.1300 correct: 247 batch_accuracy: 0.9648\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.0001 Acc: 0.1970 batch_loss: 0.1683 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0001 Acc: 0.2215 batch_loss: 0.1495 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0001 Acc: 0.2465 batch_loss: 0.0911 correct: 250 batch_accuracy: 0.9766\n",
      "train Loss: 0.0001 Acc: 0.2713 batch_loss: 0.1325 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0002 Acc: 0.2959 batch_loss: 0.1301 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0002 Acc: 0.3206 batch_loss: 0.1508 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0002 Acc: 0.3449 batch_loss: 0.1808 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0002 Acc: 0.3696 batch_loss: 0.1205 correct: 247 batch_accuracy: 0.9648\n",
      "train Loss: 0.0002 Acc: 0.3941 batch_loss: 0.1574 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0002 Acc: 0.4185 batch_loss: 0.1530 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0003 Acc: 0.4431 batch_loss: 0.1700 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0003 Acc: 0.4683 batch_loss: 0.0755 correct: 251 batch_accuracy: 0.9805\n",
      "train Loss: 0.0003 Acc: 0.4928 batch_loss: 0.1123 correct: 245 batch_accuracy: 0.9570\n",
      "train Loss: 0.0003 Acc: 0.5169 batch_loss: 0.2122 correct: 240 batch_accuracy: 0.9375\n",
      "train Loss: 0.0003 Acc: 0.5411 batch_loss: 0.1739 correct: 241 batch_accuracy: 0.9414\n",
      "train Loss: 0.0003 Acc: 0.5660 batch_loss: 0.1085 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0003 Acc: 0.5903 batch_loss: 0.1424 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0003 Acc: 0.6147 batch_loss: 0.1246 correct: 244 batch_accuracy: 0.9531\n",
      "train Loss: 0.0004 Acc: 0.6388 batch_loss: 0.2075 correct: 240 batch_accuracy: 0.9375\n",
      "train Loss: 0.0004 Acc: 0.6635 batch_loss: 0.1329 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0004 Acc: 0.6881 batch_loss: 0.1239 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0004 Acc: 0.7128 batch_loss: 0.1642 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0004 Acc: 0.7376 batch_loss: 0.1154 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0004 Acc: 0.7628 batch_loss: 0.1149 correct: 251 batch_accuracy: 0.9805\n",
      "train Loss: 0.0004 Acc: 0.7875 batch_loss: 0.1043 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0005 Acc: 0.8117 batch_loss: 0.1511 correct: 242 batch_accuracy: 0.9453\n",
      "train Loss: 0.0005 Acc: 0.8364 batch_loss: 0.1187 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0005 Acc: 0.8611 batch_loss: 0.1369 correct: 246 batch_accuracy: 0.9609\n",
      "train Loss: 0.0005 Acc: 0.8860 batch_loss: 0.0973 correct: 249 batch_accuracy: 0.9727\n",
      "train Loss: 0.0005 Acc: 0.9109 batch_loss: 0.1169 correct: 248 batch_accuracy: 0.9688\n",
      "train Loss: 0.0005 Acc: 0.9357 batch_loss: 0.1112 correct: 248 batch_accuracy: 0.9688\n",
      "Accuracy of the network on the test images: 82.29167 %\n",
      "Accuracy of   pos : 87 %\n",
      "Accuracy of   neg : 90 %\n",
      "Accuracy of pos_o : 73 %\n",
      "Accuracy of   nuc : 71 %\n",
      "Accuracy of   non : 89 %\n",
      "class total:  [765.0, 764.0, 764.0, 772.0, 775.0]\n",
      "class correct:  [666.0, 689.0, 562.0, 552.0, 691.0]\n",
      "total:  3840\n",
      "correct:  3160\n",
      "Training complete in 5m 53s\n",
      "Best val Acc: 0.000000\n"
     ]
    }
   ],
   "source": [
    "since = time.time()\n",
    "best_model_wts = net.state_dict()\n",
    "best_acc = 0.0\n",
    "for epoch in range(num_epochs):\n",
    "    print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "    print('-' * 10)\n",
    "    model_uniform.train(True)\n",
    "    model_hard.train(True)\n",
    "    net.train(True)\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    for data in trainloader:\n",
    "        \n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs_uniform = model_uniform(inputs)\n",
    "            outputs_hard = model_hard(inputs)\n",
    "        outputs_in = torch.cat((outputs_uniform, outputs_hard), dim=1)\n",
    "        outputs_out = net(outputs_in)\n",
    "        _, preds = torch.max(outputs_out.data, 1)\n",
    "        loss = criterion(outputs_out, labels)\n",
    "\n",
    "        optimizer.zero_grad()                             # Intialize the hidden weight to all zeros\n",
    "        loss.backward()                                   # Backward pass: compute the weight\n",
    "        optimizer.step()                                  # Optimizer: update the weights of hidden nodes\n",
    "\n",
    "#         if (i+1) % 100 == 0:                              # Logging\n",
    "#             print('Epoch [%d/%d], Step [%d/%d], Loss: %.4f'\n",
    "#                  %(epoch+1, num_epochs, i+1, len(train_dataset)//batch_size, loss.item()))\n",
    "\n",
    "        \n",
    "        # statistics\n",
    "        iter_loss = loss.item()\n",
    "        correct = torch.sum(preds == labels.data).item()\n",
    "        batch_accuracy = correct / batch_size\n",
    "        running_loss += loss.item()\n",
    "        running_corrects_tensor = torch.sum(preds == labels.data)\n",
    "        running_corrects += running_corrects_tensor.item()        \n",
    "        epoch_loss = running_loss / len(trainset)\n",
    "        epoch_acc = running_corrects / len(trainset)\n",
    "\n",
    "        print('{} Loss: {:.4f} Acc: {:.4f} batch_loss: {:.4f} correct: {:d} batch_accuracy: {:.4f}'.format(\n",
    "            \"train\", epoch_loss, epoch_acc, iter_loss, correct, batch_accuracy))\n",
    "        \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    class_correct = list(0. for i in range(5))\n",
    "    class_total = list(0. for i in range(5))    \n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs_uniform = model_uniform(inputs)\n",
    "            outputs_hard = model_hard(inputs)\n",
    "            outputs_in = torch.cat((outputs_uniform, outputs_hard), dim=1)\n",
    "            outputs_out = net(outputs_in)\n",
    "            _, predicted = torch.max(outputs_out.data, 1)\n",
    "            c = (predicted == labels).squeeze()\n",
    "            for i in range(batch_size):\n",
    "                if len(labels) == batch_size:\n",
    "                    label = labels[i]\n",
    "                    class_correct[label] += c[i].item()\n",
    "                    class_total[label] += 1\n",
    "                    correct += c[i].item()\n",
    "                    total += 1\n",
    "#             if len(labels) == batch_size:\n",
    "#                 total += labels.size(0)\n",
    "#                 correct += (predicted == labels).sum().item()\n",
    "    #         print(predicted)\n",
    "    #         print(labels)\n",
    "    #       print('processed: %d' % total)\n",
    "    #       print('correct: %d' % correct)\n",
    "        print('Accuracy of the network on the test images: %.5f %%' % (100 * correct / total))\n",
    "        for i in range(5):\n",
    "            print('Accuracy of %5s : %2d %%' % (classes[i], 100 * class_correct[i] / class_total[i]))\n",
    "        print('class total: ',class_total)\n",
    "        print('class correct: ',class_correct)\n",
    "        print('total: ', total)\n",
    "        print('correct: ', correct)\n",
    "time_elapsed = time.time() - since\n",
    "print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "    time_elapsed // 60, time_elapsed % 60))\n",
    "print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "# load best model weights\n",
    "net.load_state_dict(best_model_wts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 1, 200, 200])\n",
      "torch.Size([256, 5])\n",
      "torch.Size([256, 10])\n",
      "torch.Size([256, 5])\n"
     ]
    }
   ],
   "source": [
    "print(inputs.shape)\n",
    "print(outputs_uniform.shape)\n",
    "print(outputs_in.shape)\n",
    "print(outputs_out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU in use\n"
     ]
    }
   ],
   "source": [
    "use_gpu = torch.cuda.is_available()\n",
    "\n",
    "if use_gpu:\n",
    "    print(\"GPU in use\")\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "classes = [\"pos\",\"neg\",\"pos_o\",\"nuc\",\"non\"]\n",
    "num_of_classes = len(classes)\n",
    "\n",
    "model_uniform = torch.load('/home/rliu/defect_classifier/models/python/res34_600epo_uniform_01-07-18.model')\n",
    "model_uniform.eval()\n",
    "model_hard = torch.load('/home/rliu/defect_classifier/models/python/res34_600epo_hard_01-07-18.model')\n",
    "model_hard.eval()\n",
    "if use_gpu:\n",
    "#     model_uniform = torch.nn.DataParallel(model_uniform)\n",
    "    model_uniform.to(device)\n",
    "#     model_hard = torch.nn.DataParallel(model_hard)\n",
    "    model_hard.to(device)\n",
    "    \n",
    "    \n",
    "batch_size = 5\n",
    "testset = defectDataset_df(df = split_and_sample(df_train = pd.read_csv('/home/rliu/yolo2/v2_pytorch_yolo2/data/an_data/VOCdevkit/VOC2007/csv_labels/train.csv', sep=\" \"),\n",
    "                                                      method = 'hard',n_samples = 500), window_size = window_size, transforms=data_transform)\n",
    "testloader = torch.utils.data.DataLoader(testset,\n",
    "                                             batch_size=batch_size, shuffle=True,\n",
    "                                             num_workers=8)\n",
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# print images\n",
    "images, labels = images.to(device), labels.to(device)\n",
    "outputs_uniform = model_uniform(images)\n",
    "outputs_hard = model_hard(images)\n",
    "outputs = torch.cat((outputs_uniform, outputs_hard), dim=1)\n",
    "_, preds = torch.max(outputs.data, 1)\n",
    "loss = criterion(outputs, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-12.3108,   3.8134, -12.1610,  -8.9865, -18.6308],\n",
      "        [  4.1426, -12.6464, -16.8836, -13.2110, -13.5861],\n",
      "        [ -9.9046, -12.1545,  -9.0868,   2.3950, -12.2668],\n",
      "        [ -5.9917,   3.7852,  -9.3418, -10.6862, -11.3693],\n",
      "        [  4.1033,  -7.9563,  -6.8923, -13.0635,  -7.5087]], device='cuda:0',\n",
      "       grad_fn=<GatherBackward>)\n",
      "tensor([[-10.9020,   2.6503, -13.7712, -12.7975, -13.3193],\n",
      "        [  3.1850, -11.8032, -13.6199, -11.8008, -12.5677],\n",
      "        [-13.4012, -12.1915, -14.3676,   1.9575, -15.2399],\n",
      "        [ -7.2337,   2.6256, -18.3268, -10.4256,  -9.0024],\n",
      "        [  3.2153, -10.9220, -13.6908, -12.3731, -11.7074]], device='cuda:0',\n",
      "       grad_fn=<GatherBackward>)\n",
      "tensor(0.3425, device='cuda:0', grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(outputs_uniform)\n",
    "print(outputs_hard)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 0, 0, 3, 1])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.MNIST(root='./data',\n",
    "                           train=True,\n",
    "                           transform=transforms.ToTensor(),\n",
    "                           download=True)\n",
    "\n",
    "test_dataset = datasets.MNIST(root='./data',\n",
    "                           train=False,\n",
    "                           transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(Net, self).__init__()                    # Inherited from the parent class nn.Module\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)  # 1st Full-Connected Layer: 784 (input data) -> 500 (hidden node)\n",
    "        self.relu = nn.ReLU()                          # Non-Linear ReLU Layer: max(0,x)\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes) # 2nd Full-Connected Layer: 500 (hidden node) -> 10 (output class)\n",
    "    \n",
    "    def forward(self, x):                              # Forward pass: stacking each layer together\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net(input_size, hidden_size, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (fc1): Linear(in_features=784, out_features=500, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (fc2): Linear(in_features=500, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [100/600], Loss: 0.2542\n",
      "Epoch [1/5], Step [200/600], Loss: 0.1384\n",
      "Epoch [1/5], Step [300/600], Loss: 0.1731\n",
      "Epoch [1/5], Step [400/600], Loss: 0.1142\n",
      "Epoch [1/5], Step [500/600], Loss: 0.0950\n",
      "Epoch [1/5], Step [600/600], Loss: 0.1930\n",
      "Epoch [2/5], Step [100/600], Loss: 0.1513\n",
      "Epoch [2/5], Step [200/600], Loss: 0.1833\n",
      "Epoch [2/5], Step [300/600], Loss: 0.1233\n",
      "Epoch [2/5], Step [400/600], Loss: 0.1183\n",
      "Epoch [2/5], Step [500/600], Loss: 0.0871\n",
      "Epoch [2/5], Step [600/600], Loss: 0.0677\n",
      "Epoch [3/5], Step [100/600], Loss: 0.0196\n",
      "Epoch [3/5], Step [200/600], Loss: 0.0825\n",
      "Epoch [3/5], Step [300/600], Loss: 0.0880\n",
      "Epoch [3/5], Step [400/600], Loss: 0.0757\n",
      "Epoch [3/5], Step [500/600], Loss: 0.0220\n",
      "Epoch [3/5], Step [600/600], Loss: 0.0282\n",
      "Epoch [4/5], Step [100/600], Loss: 0.0166\n",
      "Epoch [4/5], Step [200/600], Loss: 0.0539\n",
      "Epoch [4/5], Step [300/600], Loss: 0.0231\n",
      "Epoch [4/5], Step [400/600], Loss: 0.0305\n",
      "Epoch [4/5], Step [500/600], Loss: 0.0996\n",
      "Epoch [4/5], Step [600/600], Loss: 0.0352\n",
      "Epoch [5/5], Step [100/600], Loss: 0.0392\n",
      "Epoch [5/5], Step [200/600], Loss: 0.0510\n",
      "Epoch [5/5], Step [300/600], Loss: 0.0487\n",
      "Epoch [5/5], Step [400/600], Loss: 0.0199\n",
      "Epoch [5/5], Step [500/600], Loss: 0.0501\n",
      "Epoch [5/5], Step [600/600], Loss: 0.0229\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):   # Load a batch of images with its (index, data, class)\n",
    "        images = Variable(images.view(-1, 28*28))         # Convert torch tensor to Variable: change image from a vector of size 784 to a matrix of 28 x 28\n",
    "        labels = Variable(labels)\n",
    "        \n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()                             # Intialize the hidden weight to all zeros\n",
    "        outputs = net(images)                             # Forward pass: compute the output class given a image\n",
    "        loss = criterion(outputs, labels)                 # Compute the loss: difference between the output class and the pre-given label\n",
    "        loss.backward()                                   # Backward pass: compute the weight\n",
    "        optimizer.step()                                  # Optimizer: update the weights of hidden nodes\n",
    "        \n",
    "        if (i+1) % 100 == 0:                              # Logging\n",
    "            print('Epoch [%d/%d], Step [%d/%d], Loss: %.4f'\n",
    "                 %(epoch+1, num_epochs, i+1, len(train_dataset)//batch_size, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22127796709537506"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    use_gpu = torch.cuda.is_available()\n",
    "\n",
    "    if use_gpu:\n",
    "        print(\"GPU in use\")\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    classes = [\"pos\",\"neg\",\"pos_o\",\"nuc\",\"non\"]\n",
    "    num_of_classes = len(classes)\n",
    "\n",
    "    model_uniform = torch.load('/home/rliu/defect_classifier/models/python/res34_600epo_uniform_01-07-18.model')\n",
    "    model_uniform.eval()\n",
    "    model_hard = torch.load('/home/rliu/defect_classifier/models/python/res34_600epo_uniform_01-07-18.model')\n",
    "    model_hard.eval()\n",
    "    if use_gpu:\n",
    "        model_uniform = torch.nn.DataParallel(uniform)\n",
    "        model_uniform.to(device)\n",
    "        model_uniform = torch.nn.DataParallel(uniform)\n",
    "        model_uniform.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10K test images: 97 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "for images, labels in test_loader:\n",
    "    images = Variable(images.view(-1, 28*28))\n",
    "    images, labels = images.to(device), labels.to(device)\n",
    "    outputs = net(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)  # Choose the best class from the output: The class with the best score\n",
    "    total += labels.size(0)                    # Increment the total count\n",
    "    correct += (predicted == labels).sum()     # Increment the correct count\n",
    "    \n",
    "print('Accuracy of the network on the 10K test images: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
